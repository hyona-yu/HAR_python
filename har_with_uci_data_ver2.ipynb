{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "har_with_uci_data_ver2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP60ayHCjia82Yg/5EWdi5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyona-yu/HAR_python/blob/master/har_with_uci_data_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fq-jEWK2Pow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBWOMSKF5Bbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVH8sr-Bzfdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2P1VSxm2Q8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0aac5671-a523-46bd-9134-08fa8e05913a"
      },
      "source": [
        "! git clone https://github.com/hyona-yu/Dataset.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dataset'...\n",
            "remote: Enumerating objects: 660, done.\u001b[K\n",
            "remote: Total 660 (delta 0), reused 0 (delta 0), pack-reused 660\u001b[K\n",
            "Receiving objects: 100% (660/660), 427.85 MiB | 23.97 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n",
            "Checking out files: 100% (626/626), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ykz9hZT2UCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'Dataset/UCI HAR Dataset/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77oqJNn6j_AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#time step 128\n",
        "signal = ['body_acc_x_', 'body_acc_y_','body_acc_z_','body_gyro_x_','body_gyro_y_','body_gyro_z_','total_acc_x_','total_acc_y_','total_acc_z_']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmrVibCUk0H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv = pd.DataFrame()\n",
        "for s in signal:\n",
        "  train_path = str(url + \"train/Inertial Signals/\"+ s + \"train.txt\")\n",
        "  train_csv = pd.concat([train_csv, pd.read_csv(train_path, sep ='\\s+', header = None)], axis = 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOSbmUnYlYbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "17688fae-316c-4079-d564-29680009dcbc"
      },
      "source": [
        "train_csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.010139</td>\n",
              "      <td>0.009276</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.010810</td>\n",
              "      <td>0.004045</td>\n",
              "      <td>0.004757</td>\n",
              "      <td>0.006214</td>\n",
              "      <td>0.003307</td>\n",
              "      <td>0.007572</td>\n",
              "      <td>0.005407</td>\n",
              "      <td>0.006221</td>\n",
              "      <td>0.006895</td>\n",
              "      <td>0.004610</td>\n",
              "      <td>0.007331</td>\n",
              "      <td>0.005078</td>\n",
              "      <td>0.005763</td>\n",
              "      <td>0.006693</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.008241</td>\n",
              "      <td>0.006506</td>\n",
              "      <td>0.006532</td>\n",
              "      <td>0.007422</td>\n",
              "      <td>0.005772</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.004623</td>\n",
              "      <td>0.004833</td>\n",
              "      <td>0.005499</td>\n",
              "      <td>0.004341</td>\n",
              "      <td>0.005098</td>\n",
              "      <td>0.004269</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.004520</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.003550</td>\n",
              "      <td>0.004234</td>\n",
              "      <td>0.004469</td>\n",
              "      <td>0.003573</td>\n",
              "      <td>0.005136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101472</td>\n",
              "      <td>0.101226</td>\n",
              "      <td>0.102653</td>\n",
              "      <td>0.101608</td>\n",
              "      <td>0.100634</td>\n",
              "      <td>0.096142</td>\n",
              "      <td>0.090326</td>\n",
              "      <td>0.089905</td>\n",
              "      <td>0.093117</td>\n",
              "      <td>0.095741</td>\n",
              "      <td>0.094250</td>\n",
              "      <td>0.094481</td>\n",
              "      <td>0.097755</td>\n",
              "      <td>0.099002</td>\n",
              "      <td>0.098523</td>\n",
              "      <td>0.095429</td>\n",
              "      <td>0.094212</td>\n",
              "      <td>0.097735</td>\n",
              "      <td>0.102188</td>\n",
              "      <td>0.103457</td>\n",
              "      <td>0.099610</td>\n",
              "      <td>0.097589</td>\n",
              "      <td>0.098616</td>\n",
              "      <td>0.097882</td>\n",
              "      <td>0.096877</td>\n",
              "      <td>0.097010</td>\n",
              "      <td>0.097582</td>\n",
              "      <td>0.097073</td>\n",
              "      <td>0.097425</td>\n",
              "      <td>0.099341</td>\n",
              "      <td>0.100058</td>\n",
              "      <td>0.098564</td>\n",
              "      <td>0.093177</td>\n",
              "      <td>0.088742</td>\n",
              "      <td>0.090505</td>\n",
              "      <td>0.094843</td>\n",
              "      <td>0.098350</td>\n",
              "      <td>0.100385</td>\n",
              "      <td>0.099874</td>\n",
              "      <td>0.094987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.004550</td>\n",
              "      <td>0.002879</td>\n",
              "      <td>0.002247</td>\n",
              "      <td>0.003305</td>\n",
              "      <td>0.002416</td>\n",
              "      <td>0.001619</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>-0.000363</td>\n",
              "      <td>-0.000487</td>\n",
              "      <td>-0.000356</td>\n",
              "      <td>-0.000229</td>\n",
              "      <td>-0.000131</td>\n",
              "      <td>-0.000441</td>\n",
              "      <td>-0.001565</td>\n",
              "      <td>-0.000929</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>-0.001236</td>\n",
              "      <td>-0.000911</td>\n",
              "      <td>-0.000435</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000751</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.001328</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.002743</td>\n",
              "      <td>0.001330</td>\n",
              "      <td>-0.000367</td>\n",
              "      <td>-0.000722</td>\n",
              "      <td>-0.001904</td>\n",
              "      <td>-0.004294</td>\n",
              "      <td>-0.000025</td>\n",
              "      <td>0.005251</td>\n",
              "      <td>0.002490</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>-0.000693</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097527</td>\n",
              "      <td>0.097369</td>\n",
              "      <td>0.098893</td>\n",
              "      <td>0.100536</td>\n",
              "      <td>0.098083</td>\n",
              "      <td>0.097308</td>\n",
              "      <td>0.101762</td>\n",
              "      <td>0.105788</td>\n",
              "      <td>0.104529</td>\n",
              "      <td>0.101473</td>\n",
              "      <td>0.096284</td>\n",
              "      <td>0.087116</td>\n",
              "      <td>0.088206</td>\n",
              "      <td>0.096796</td>\n",
              "      <td>0.096812</td>\n",
              "      <td>0.098964</td>\n",
              "      <td>0.104573</td>\n",
              "      <td>0.103425</td>\n",
              "      <td>0.100734</td>\n",
              "      <td>0.097965</td>\n",
              "      <td>0.099716</td>\n",
              "      <td>0.104411</td>\n",
              "      <td>0.103337</td>\n",
              "      <td>0.103670</td>\n",
              "      <td>0.103047</td>\n",
              "      <td>0.099247</td>\n",
              "      <td>0.100684</td>\n",
              "      <td>0.100973</td>\n",
              "      <td>0.097971</td>\n",
              "      <td>0.095684</td>\n",
              "      <td>0.094537</td>\n",
              "      <td>0.098759</td>\n",
              "      <td>0.101977</td>\n",
              "      <td>0.095360</td>\n",
              "      <td>0.089466</td>\n",
              "      <td>0.095126</td>\n",
              "      <td>0.099496</td>\n",
              "      <td>0.093535</td>\n",
              "      <td>0.089035</td>\n",
              "      <td>0.090612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003531</td>\n",
              "      <td>0.002285</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>-0.003738</td>\n",
              "      <td>-0.006706</td>\n",
              "      <td>-0.003148</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>-0.000946</td>\n",
              "      <td>-0.006476</td>\n",
              "      <td>-0.003423</td>\n",
              "      <td>-0.000610</td>\n",
              "      <td>-0.002929</td>\n",
              "      <td>-0.001796</td>\n",
              "      <td>0.000956</td>\n",
              "      <td>0.002311</td>\n",
              "      <td>0.002538</td>\n",
              "      <td>0.001180</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>-0.001506</td>\n",
              "      <td>-0.002105</td>\n",
              "      <td>-0.001494</td>\n",
              "      <td>0.002181</td>\n",
              "      <td>0.002876</td>\n",
              "      <td>0.000871</td>\n",
              "      <td>-0.000392</td>\n",
              "      <td>-0.000569</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>-0.001176</td>\n",
              "      <td>-0.001957</td>\n",
              "      <td>-0.000471</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>0.004829</td>\n",
              "      <td>0.003380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093599</td>\n",
              "      <td>0.089887</td>\n",
              "      <td>0.083149</td>\n",
              "      <td>0.085446</td>\n",
              "      <td>0.089210</td>\n",
              "      <td>0.092701</td>\n",
              "      <td>0.095387</td>\n",
              "      <td>0.093006</td>\n",
              "      <td>0.089667</td>\n",
              "      <td>0.085096</td>\n",
              "      <td>0.084867</td>\n",
              "      <td>0.090206</td>\n",
              "      <td>0.091938</td>\n",
              "      <td>0.094822</td>\n",
              "      <td>0.096023</td>\n",
              "      <td>0.093216</td>\n",
              "      <td>0.096160</td>\n",
              "      <td>0.096263</td>\n",
              "      <td>0.093678</td>\n",
              "      <td>0.096380</td>\n",
              "      <td>0.093724</td>\n",
              "      <td>0.087680</td>\n",
              "      <td>0.085679</td>\n",
              "      <td>0.086568</td>\n",
              "      <td>0.090691</td>\n",
              "      <td>0.092891</td>\n",
              "      <td>0.093875</td>\n",
              "      <td>0.094094</td>\n",
              "      <td>0.087741</td>\n",
              "      <td>0.082867</td>\n",
              "      <td>0.085343</td>\n",
              "      <td>0.087155</td>\n",
              "      <td>0.084546</td>\n",
              "      <td>0.082166</td>\n",
              "      <td>0.081972</td>\n",
              "      <td>0.081413</td>\n",
              "      <td>0.081936</td>\n",
              "      <td>0.083011</td>\n",
              "      <td>0.082334</td>\n",
              "      <td>0.081487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.001772</td>\n",
              "      <td>-0.001311</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>-0.000355</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.001109</td>\n",
              "      <td>-0.003149</td>\n",
              "      <td>-0.008882</td>\n",
              "      <td>-0.010483</td>\n",
              "      <td>-0.004482</td>\n",
              "      <td>0.004528</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>0.002929</td>\n",
              "      <td>-0.004487</td>\n",
              "      <td>-0.004717</td>\n",
              "      <td>-0.001637</td>\n",
              "      <td>-0.000097</td>\n",
              "      <td>0.001614</td>\n",
              "      <td>0.002619</td>\n",
              "      <td>0.004765</td>\n",
              "      <td>0.005851</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>0.002138</td>\n",
              "      <td>0.003519</td>\n",
              "      <td>0.002715</td>\n",
              "      <td>0.002370</td>\n",
              "      <td>0.003299</td>\n",
              "      <td>0.002357</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.002201</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>0.002706</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>-0.000949</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.004952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082965</td>\n",
              "      <td>0.081726</td>\n",
              "      <td>0.085902</td>\n",
              "      <td>0.088833</td>\n",
              "      <td>0.086746</td>\n",
              "      <td>0.084692</td>\n",
              "      <td>0.082640</td>\n",
              "      <td>0.084150</td>\n",
              "      <td>0.085247</td>\n",
              "      <td>0.083578</td>\n",
              "      <td>0.083925</td>\n",
              "      <td>0.087735</td>\n",
              "      <td>0.092079</td>\n",
              "      <td>0.090971</td>\n",
              "      <td>0.088221</td>\n",
              "      <td>0.087130</td>\n",
              "      <td>0.084942</td>\n",
              "      <td>0.082944</td>\n",
              "      <td>0.079419</td>\n",
              "      <td>0.076888</td>\n",
              "      <td>0.080105</td>\n",
              "      <td>0.084625</td>\n",
              "      <td>0.087186</td>\n",
              "      <td>0.087998</td>\n",
              "      <td>0.087082</td>\n",
              "      <td>0.085528</td>\n",
              "      <td>0.085230</td>\n",
              "      <td>0.088954</td>\n",
              "      <td>0.093179</td>\n",
              "      <td>0.091213</td>\n",
              "      <td>0.088112</td>\n",
              "      <td>0.087322</td>\n",
              "      <td>0.083738</td>\n",
              "      <td>0.082701</td>\n",
              "      <td>0.084490</td>\n",
              "      <td>0.082785</td>\n",
              "      <td>0.084084</td>\n",
              "      <td>0.085761</td>\n",
              "      <td>0.083275</td>\n",
              "      <td>0.081404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000087</td>\n",
              "      <td>-0.000272</td>\n",
              "      <td>0.001022</td>\n",
              "      <td>0.003126</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>0.001933</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>0.002247</td>\n",
              "      <td>0.002175</td>\n",
              "      <td>0.001750</td>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>0.001911</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.001347</td>\n",
              "      <td>-0.000384</td>\n",
              "      <td>-0.000135</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>0.001470</td>\n",
              "      <td>0.001644</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.001683</td>\n",
              "      <td>-0.001165</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>-0.001546</td>\n",
              "      <td>-0.003518</td>\n",
              "      <td>-0.003204</td>\n",
              "      <td>-0.002376</td>\n",
              "      <td>-0.001825</td>\n",
              "      <td>-0.001754</td>\n",
              "      <td>-0.002504</td>\n",
              "      <td>-0.002612</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084108</td>\n",
              "      <td>0.083109</td>\n",
              "      <td>0.080163</td>\n",
              "      <td>0.076622</td>\n",
              "      <td>0.078279</td>\n",
              "      <td>0.084254</td>\n",
              "      <td>0.085648</td>\n",
              "      <td>0.081490</td>\n",
              "      <td>0.084675</td>\n",
              "      <td>0.088211</td>\n",
              "      <td>0.086471</td>\n",
              "      <td>0.087503</td>\n",
              "      <td>0.082953</td>\n",
              "      <td>0.079125</td>\n",
              "      <td>0.084738</td>\n",
              "      <td>0.087178</td>\n",
              "      <td>0.085370</td>\n",
              "      <td>0.084911</td>\n",
              "      <td>0.090154</td>\n",
              "      <td>0.093388</td>\n",
              "      <td>0.083022</td>\n",
              "      <td>0.074595</td>\n",
              "      <td>0.079912</td>\n",
              "      <td>0.085177</td>\n",
              "      <td>0.082895</td>\n",
              "      <td>0.084075</td>\n",
              "      <td>0.085648</td>\n",
              "      <td>0.082100</td>\n",
              "      <td>0.086196</td>\n",
              "      <td>0.089715</td>\n",
              "      <td>0.088028</td>\n",
              "      <td>0.090312</td>\n",
              "      <td>0.088713</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.086522</td>\n",
              "      <td>0.081640</td>\n",
              "      <td>0.079652</td>\n",
              "      <td>0.081329</td>\n",
              "      <td>0.085397</td>\n",
              "      <td>0.088816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7347</th>\n",
              "      <td>0.388873</td>\n",
              "      <td>0.618763</td>\n",
              "      <td>0.774067</td>\n",
              "      <td>0.586568</td>\n",
              "      <td>0.217007</td>\n",
              "      <td>-0.027330</td>\n",
              "      <td>-0.171294</td>\n",
              "      <td>-0.218988</td>\n",
              "      <td>-0.137680</td>\n",
              "      <td>0.033094</td>\n",
              "      <td>0.134138</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.029367</td>\n",
              "      <td>-0.031832</td>\n",
              "      <td>-0.178822</td>\n",
              "      <td>-0.245202</td>\n",
              "      <td>-0.283081</td>\n",
              "      <td>-0.272425</td>\n",
              "      <td>-0.203703</td>\n",
              "      <td>-0.181702</td>\n",
              "      <td>-0.178996</td>\n",
              "      <td>-0.180241</td>\n",
              "      <td>-0.119776</td>\n",
              "      <td>-0.041093</td>\n",
              "      <td>-0.046574</td>\n",
              "      <td>-0.071318</td>\n",
              "      <td>-0.089548</td>\n",
              "      <td>-0.049388</td>\n",
              "      <td>0.073998</td>\n",
              "      <td>0.206127</td>\n",
              "      <td>0.262677</td>\n",
              "      <td>0.215333</td>\n",
              "      <td>0.229796</td>\n",
              "      <td>0.361772</td>\n",
              "      <td>0.520258</td>\n",
              "      <td>0.650501</td>\n",
              "      <td>0.629610</td>\n",
              "      <td>0.483332</td>\n",
              "      <td>0.310894</td>\n",
              "      <td>0.146430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.217494</td>\n",
              "      <td>-0.188283</td>\n",
              "      <td>-0.189874</td>\n",
              "      <td>-0.196000</td>\n",
              "      <td>-0.211880</td>\n",
              "      <td>-0.234426</td>\n",
              "      <td>-0.228991</td>\n",
              "      <td>-0.207820</td>\n",
              "      <td>-0.172275</td>\n",
              "      <td>-0.137235</td>\n",
              "      <td>-0.115258</td>\n",
              "      <td>-0.107192</td>\n",
              "      <td>-0.121015</td>\n",
              "      <td>-0.162484</td>\n",
              "      <td>-0.239210</td>\n",
              "      <td>-0.349252</td>\n",
              "      <td>-0.439382</td>\n",
              "      <td>-0.448371</td>\n",
              "      <td>-0.417402</td>\n",
              "      <td>-0.366171</td>\n",
              "      <td>-0.260467</td>\n",
              "      <td>-0.178167</td>\n",
              "      <td>-0.166824</td>\n",
              "      <td>-0.163785</td>\n",
              "      <td>-0.130286</td>\n",
              "      <td>-0.064277</td>\n",
              "      <td>-0.036914</td>\n",
              "      <td>-0.075391</td>\n",
              "      <td>-0.100396</td>\n",
              "      <td>-0.116673</td>\n",
              "      <td>-0.115192</td>\n",
              "      <td>-0.086700</td>\n",
              "      <td>-0.101805</td>\n",
              "      <td>-0.095273</td>\n",
              "      <td>-0.029541</td>\n",
              "      <td>0.026907</td>\n",
              "      <td>0.069472</td>\n",
              "      <td>0.086288</td>\n",
              "      <td>0.099188</td>\n",
              "      <td>0.129060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7348</th>\n",
              "      <td>0.711864</td>\n",
              "      <td>0.709237</td>\n",
              "      <td>0.321368</td>\n",
              "      <td>-0.028921</td>\n",
              "      <td>-0.208107</td>\n",
              "      <td>-0.192802</td>\n",
              "      <td>-0.066754</td>\n",
              "      <td>-0.042285</td>\n",
              "      <td>0.058089</td>\n",
              "      <td>0.106855</td>\n",
              "      <td>-0.038674</td>\n",
              "      <td>-0.105272</td>\n",
              "      <td>-0.134513</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.136471</td>\n",
              "      <td>-0.171105</td>\n",
              "      <td>-0.116432</td>\n",
              "      <td>-0.126822</td>\n",
              "      <td>-0.129641</td>\n",
              "      <td>-0.142410</td>\n",
              "      <td>-0.255536</td>\n",
              "      <td>-0.259922</td>\n",
              "      <td>-0.212128</td>\n",
              "      <td>-0.133162</td>\n",
              "      <td>-0.036709</td>\n",
              "      <td>-0.035769</td>\n",
              "      <td>-0.053730</td>\n",
              "      <td>-0.071545</td>\n",
              "      <td>-0.040989</td>\n",
              "      <td>0.013037</td>\n",
              "      <td>0.025262</td>\n",
              "      <td>0.038054</td>\n",
              "      <td>0.017321</td>\n",
              "      <td>0.014981</td>\n",
              "      <td>0.041400</td>\n",
              "      <td>0.059505</td>\n",
              "      <td>0.114644</td>\n",
              "      <td>0.194145</td>\n",
              "      <td>0.317047</td>\n",
              "      <td>0.424087</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.145436</td>\n",
              "      <td>-0.135170</td>\n",
              "      <td>-0.117926</td>\n",
              "      <td>-0.123752</td>\n",
              "      <td>-0.157530</td>\n",
              "      <td>-0.199548</td>\n",
              "      <td>-0.212682</td>\n",
              "      <td>-0.183082</td>\n",
              "      <td>-0.170469</td>\n",
              "      <td>-0.166963</td>\n",
              "      <td>-0.133398</td>\n",
              "      <td>-0.098018</td>\n",
              "      <td>-0.067463</td>\n",
              "      <td>-0.070818</td>\n",
              "      <td>-0.116851</td>\n",
              "      <td>-0.216332</td>\n",
              "      <td>-0.331846</td>\n",
              "      <td>-0.290569</td>\n",
              "      <td>-0.216240</td>\n",
              "      <td>-0.269364</td>\n",
              "      <td>-0.252643</td>\n",
              "      <td>-0.210474</td>\n",
              "      <td>-0.232017</td>\n",
              "      <td>-0.175126</td>\n",
              "      <td>-0.094612</td>\n",
              "      <td>-0.005053</td>\n",
              "      <td>0.073006</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>0.035498</td>\n",
              "      <td>0.050375</td>\n",
              "      <td>0.028204</td>\n",
              "      <td>0.045156</td>\n",
              "      <td>0.058035</td>\n",
              "      <td>0.064945</td>\n",
              "      <td>0.089264</td>\n",
              "      <td>0.108987</td>\n",
              "      <td>0.150238</td>\n",
              "      <td>0.199324</td>\n",
              "      <td>0.236369</td>\n",
              "      <td>0.253029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7349</th>\n",
              "      <td>-0.226717</td>\n",
              "      <td>-0.177817</td>\n",
              "      <td>-0.150869</td>\n",
              "      <td>-0.132237</td>\n",
              "      <td>-0.068338</td>\n",
              "      <td>0.007874</td>\n",
              "      <td>0.096481</td>\n",
              "      <td>0.205834</td>\n",
              "      <td>0.441342</td>\n",
              "      <td>0.662930</td>\n",
              "      <td>0.516996</td>\n",
              "      <td>0.163970</td>\n",
              "      <td>-0.111588</td>\n",
              "      <td>-0.242033</td>\n",
              "      <td>-0.161571</td>\n",
              "      <td>-0.057781</td>\n",
              "      <td>0.057996</td>\n",
              "      <td>0.230109</td>\n",
              "      <td>0.114135</td>\n",
              "      <td>-0.067563</td>\n",
              "      <td>-0.048464</td>\n",
              "      <td>-0.126804</td>\n",
              "      <td>-0.205752</td>\n",
              "      <td>-0.222148</td>\n",
              "      <td>-0.245844</td>\n",
              "      <td>-0.211233</td>\n",
              "      <td>-0.236905</td>\n",
              "      <td>-0.237512</td>\n",
              "      <td>-0.210507</td>\n",
              "      <td>-0.204754</td>\n",
              "      <td>-0.104595</td>\n",
              "      <td>-0.045143</td>\n",
              "      <td>-0.029798</td>\n",
              "      <td>-0.010249</td>\n",
              "      <td>0.012481</td>\n",
              "      <td>0.118657</td>\n",
              "      <td>0.196060</td>\n",
              "      <td>0.241251</td>\n",
              "      <td>0.300500</td>\n",
              "      <td>0.376790</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086958</td>\n",
              "      <td>-0.089363</td>\n",
              "      <td>-0.096627</td>\n",
              "      <td>-0.107349</td>\n",
              "      <td>-0.133789</td>\n",
              "      <td>-0.151909</td>\n",
              "      <td>-0.146643</td>\n",
              "      <td>-0.145323</td>\n",
              "      <td>-0.144709</td>\n",
              "      <td>-0.139999</td>\n",
              "      <td>-0.140984</td>\n",
              "      <td>-0.151710</td>\n",
              "      <td>-0.165605</td>\n",
              "      <td>-0.160335</td>\n",
              "      <td>-0.149881</td>\n",
              "      <td>-0.164953</td>\n",
              "      <td>-0.230757</td>\n",
              "      <td>-0.327586</td>\n",
              "      <td>-0.363994</td>\n",
              "      <td>-0.368852</td>\n",
              "      <td>-0.410020</td>\n",
              "      <td>-0.406715</td>\n",
              "      <td>-0.388785</td>\n",
              "      <td>-0.402327</td>\n",
              "      <td>-0.318985</td>\n",
              "      <td>-0.184458</td>\n",
              "      <td>-0.102218</td>\n",
              "      <td>-0.011336</td>\n",
              "      <td>0.034239</td>\n",
              "      <td>-0.043995</td>\n",
              "      <td>-0.117974</td>\n",
              "      <td>-0.080109</td>\n",
              "      <td>-0.015432</td>\n",
              "      <td>0.031859</td>\n",
              "      <td>0.072452</td>\n",
              "      <td>0.065696</td>\n",
              "      <td>0.079038</td>\n",
              "      <td>0.111295</td>\n",
              "      <td>0.126302</td>\n",
              "      <td>0.188621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7350</th>\n",
              "      <td>-0.064806</td>\n",
              "      <td>-0.079933</td>\n",
              "      <td>-0.068350</td>\n",
              "      <td>-0.038477</td>\n",
              "      <td>-0.028679</td>\n",
              "      <td>0.018335</td>\n",
              "      <td>0.077571</td>\n",
              "      <td>0.253580</td>\n",
              "      <td>0.507805</td>\n",
              "      <td>0.583999</td>\n",
              "      <td>0.466749</td>\n",
              "      <td>0.233940</td>\n",
              "      <td>-0.056077</td>\n",
              "      <td>-0.163528</td>\n",
              "      <td>-0.037607</td>\n",
              "      <td>-0.006132</td>\n",
              "      <td>-0.031113</td>\n",
              "      <td>0.022096</td>\n",
              "      <td>-0.039334</td>\n",
              "      <td>-0.070132</td>\n",
              "      <td>-0.042110</td>\n",
              "      <td>-0.097888</td>\n",
              "      <td>-0.112671</td>\n",
              "      <td>-0.166334</td>\n",
              "      <td>-0.205544</td>\n",
              "      <td>-0.161619</td>\n",
              "      <td>-0.172629</td>\n",
              "      <td>-0.161423</td>\n",
              "      <td>-0.156584</td>\n",
              "      <td>-0.161717</td>\n",
              "      <td>-0.100413</td>\n",
              "      <td>-0.039997</td>\n",
              "      <td>-0.009242</td>\n",
              "      <td>-0.057404</td>\n",
              "      <td>-0.092720</td>\n",
              "      <td>-0.028126</td>\n",
              "      <td>0.050525</td>\n",
              "      <td>0.152816</td>\n",
              "      <td>0.236484</td>\n",
              "      <td>0.245565</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.116897</td>\n",
              "      <td>-0.103137</td>\n",
              "      <td>-0.090091</td>\n",
              "      <td>-0.113315</td>\n",
              "      <td>-0.124259</td>\n",
              "      <td>-0.169151</td>\n",
              "      <td>-0.189740</td>\n",
              "      <td>-0.156570</td>\n",
              "      <td>-0.138032</td>\n",
              "      <td>-0.142260</td>\n",
              "      <td>-0.156863</td>\n",
              "      <td>-0.161927</td>\n",
              "      <td>-0.168393</td>\n",
              "      <td>-0.170999</td>\n",
              "      <td>-0.183511</td>\n",
              "      <td>-0.251072</td>\n",
              "      <td>-0.304773</td>\n",
              "      <td>-0.286929</td>\n",
              "      <td>-0.271133</td>\n",
              "      <td>-0.318102</td>\n",
              "      <td>-0.361370</td>\n",
              "      <td>-0.358647</td>\n",
              "      <td>-0.344486</td>\n",
              "      <td>-0.307890</td>\n",
              "      <td>-0.274540</td>\n",
              "      <td>-0.224581</td>\n",
              "      <td>-0.093530</td>\n",
              "      <td>0.017510</td>\n",
              "      <td>0.012284</td>\n",
              "      <td>-0.036033</td>\n",
              "      <td>-0.032441</td>\n",
              "      <td>-0.001154</td>\n",
              "      <td>0.028541</td>\n",
              "      <td>0.052355</td>\n",
              "      <td>0.040251</td>\n",
              "      <td>0.060450</td>\n",
              "      <td>0.108725</td>\n",
              "      <td>0.128925</td>\n",
              "      <td>0.172251</td>\n",
              "      <td>0.210071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7351</th>\n",
              "      <td>-0.194471</td>\n",
              "      <td>-0.173802</td>\n",
              "      <td>-0.127545</td>\n",
              "      <td>-0.108369</td>\n",
              "      <td>-0.121152</td>\n",
              "      <td>-0.074004</td>\n",
              "      <td>-0.002135</td>\n",
              "      <td>0.177865</td>\n",
              "      <td>0.516936</td>\n",
              "      <td>0.701378</td>\n",
              "      <td>0.523162</td>\n",
              "      <td>0.198638</td>\n",
              "      <td>-0.033735</td>\n",
              "      <td>-0.125064</td>\n",
              "      <td>-0.081785</td>\n",
              "      <td>-0.049427</td>\n",
              "      <td>-0.037120</td>\n",
              "      <td>0.032376</td>\n",
              "      <td>-0.010414</td>\n",
              "      <td>-0.075065</td>\n",
              "      <td>-0.088306</td>\n",
              "      <td>-0.154105</td>\n",
              "      <td>-0.138289</td>\n",
              "      <td>-0.141416</td>\n",
              "      <td>-0.190921</td>\n",
              "      <td>-0.165662</td>\n",
              "      <td>-0.197339</td>\n",
              "      <td>-0.233312</td>\n",
              "      <td>-0.234903</td>\n",
              "      <td>-0.198456</td>\n",
              "      <td>-0.069192</td>\n",
              "      <td>0.004701</td>\n",
              "      <td>0.006175</td>\n",
              "      <td>-0.018244</td>\n",
              "      <td>-0.041329</td>\n",
              "      <td>0.014147</td>\n",
              "      <td>0.102656</td>\n",
              "      <td>0.199744</td>\n",
              "      <td>0.261994</td>\n",
              "      <td>0.266400</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.138260</td>\n",
              "      <td>-0.099591</td>\n",
              "      <td>-0.077675</td>\n",
              "      <td>-0.092547</td>\n",
              "      <td>-0.090676</td>\n",
              "      <td>-0.122148</td>\n",
              "      <td>-0.150857</td>\n",
              "      <td>-0.157814</td>\n",
              "      <td>-0.177368</td>\n",
              "      <td>-0.175800</td>\n",
              "      <td>-0.178127</td>\n",
              "      <td>-0.200512</td>\n",
              "      <td>-0.221387</td>\n",
              "      <td>-0.227013</td>\n",
              "      <td>-0.214444</td>\n",
              "      <td>-0.215596</td>\n",
              "      <td>-0.225710</td>\n",
              "      <td>-0.227692</td>\n",
              "      <td>-0.212477</td>\n",
              "      <td>-0.180903</td>\n",
              "      <td>-0.166418</td>\n",
              "      <td>-0.155898</td>\n",
              "      <td>-0.143926</td>\n",
              "      <td>-0.178004</td>\n",
              "      <td>-0.236032</td>\n",
              "      <td>-0.277397</td>\n",
              "      <td>-0.340383</td>\n",
              "      <td>-0.401423</td>\n",
              "      <td>-0.404786</td>\n",
              "      <td>-0.414488</td>\n",
              "      <td>-0.429072</td>\n",
              "      <td>-0.392275</td>\n",
              "      <td>-0.344507</td>\n",
              "      <td>-0.281695</td>\n",
              "      <td>-0.223023</td>\n",
              "      <td>-0.205803</td>\n",
              "      <td>-0.180733</td>\n",
              "      <td>-0.156105</td>\n",
              "      <td>-0.122798</td>\n",
              "      <td>-0.083572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7352 rows × 1152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       125       126       127\n",
              "0     0.000181  0.010139  0.009276  ...  0.100385  0.099874  0.094987\n",
              "1     0.001094  0.004550  0.002879  ...  0.093535  0.089035  0.090612\n",
              "2     0.003531  0.002285 -0.000420  ...  0.083011  0.082334  0.081487\n",
              "3    -0.001772 -0.001311  0.000388  ...  0.085761  0.083275  0.081404\n",
              "4     0.000087 -0.000272  0.001022  ...  0.081329  0.085397  0.088816\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "7347  0.388873  0.618763  0.774067  ...  0.086288  0.099188  0.129060\n",
              "7348  0.711864  0.709237  0.321368  ...  0.199324  0.236369  0.253029\n",
              "7349 -0.226717 -0.177817 -0.150869  ...  0.111295  0.126302  0.188621\n",
              "7350 -0.064806 -0.079933 -0.068350  ...  0.128925  0.172251  0.210071\n",
              "7351 -0.194471 -0.173802 -0.127545  ... -0.156105 -0.122798 -0.083572\n",
              "\n",
              "[7352 rows x 1152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqXrcvLumEus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_csv = pd.DataFrame()\n",
        "for s in signal:\n",
        "  test_path = str(url + \"test/Inertial Signals/\"+ s + \"test.txt\")\n",
        "  test_csv = pd.concat([test_csv, pd.read_csv(test_path, sep ='\\s+', header = None)], axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM6MFTqLmLTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "c8aba8d7-3537-4299-bcfe-bbda759d309d"
      },
      "source": [
        "test_csv"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011653</td>\n",
              "      <td>0.013109</td>\n",
              "      <td>0.011269</td>\n",
              "      <td>0.027831</td>\n",
              "      <td>0.002318</td>\n",
              "      <td>-0.018965</td>\n",
              "      <td>-0.061920</td>\n",
              "      <td>-0.094248</td>\n",
              "      <td>-0.079534</td>\n",
              "      <td>-0.070084</td>\n",
              "      <td>-0.019152</td>\n",
              "      <td>-0.002267</td>\n",
              "      <td>-0.030111</td>\n",
              "      <td>-0.011910</td>\n",
              "      <td>-0.015542</td>\n",
              "      <td>-0.016666</td>\n",
              "      <td>-0.006630</td>\n",
              "      <td>-0.023481</td>\n",
              "      <td>-0.017628</td>\n",
              "      <td>-0.021150</td>\n",
              "      <td>-0.032659</td>\n",
              "      <td>-0.022478</td>\n",
              "      <td>-0.010197</td>\n",
              "      <td>-0.003120</td>\n",
              "      <td>-0.016496</td>\n",
              "      <td>-0.020442</td>\n",
              "      <td>-0.027568</td>\n",
              "      <td>-0.055032</td>\n",
              "      <td>-0.057480</td>\n",
              "      <td>-0.047096</td>\n",
              "      <td>-0.028362</td>\n",
              "      <td>-0.017185</td>\n",
              "      <td>-0.007376</td>\n",
              "      <td>0.024779</td>\n",
              "      <td>0.023929</td>\n",
              "      <td>0.021248</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>-0.035119</td>\n",
              "      <td>-0.010733</td>\n",
              "      <td>0.023672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160443</td>\n",
              "      <td>0.151523</td>\n",
              "      <td>0.147972</td>\n",
              "      <td>0.154167</td>\n",
              "      <td>0.153757</td>\n",
              "      <td>0.151731</td>\n",
              "      <td>0.146116</td>\n",
              "      <td>0.143020</td>\n",
              "      <td>0.143608</td>\n",
              "      <td>0.144273</td>\n",
              "      <td>0.149575</td>\n",
              "      <td>0.150313</td>\n",
              "      <td>0.149967</td>\n",
              "      <td>0.150430</td>\n",
              "      <td>0.148942</td>\n",
              "      <td>0.149977</td>\n",
              "      <td>0.147962</td>\n",
              "      <td>0.148390</td>\n",
              "      <td>0.150847</td>\n",
              "      <td>0.150729</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.151450</td>\n",
              "      <td>0.153751</td>\n",
              "      <td>0.158655</td>\n",
              "      <td>0.158038</td>\n",
              "      <td>0.158718</td>\n",
              "      <td>0.158712</td>\n",
              "      <td>0.159610</td>\n",
              "      <td>0.161821</td>\n",
              "      <td>0.158132</td>\n",
              "      <td>0.155110</td>\n",
              "      <td>0.153346</td>\n",
              "      <td>0.149289</td>\n",
              "      <td>0.147401</td>\n",
              "      <td>0.146905</td>\n",
              "      <td>0.145261</td>\n",
              "      <td>0.143904</td>\n",
              "      <td>0.144395</td>\n",
              "      <td>0.144703</td>\n",
              "      <td>0.145494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009280</td>\n",
              "      <td>0.004930</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.009214</td>\n",
              "      <td>0.016156</td>\n",
              "      <td>0.014079</td>\n",
              "      <td>0.013105</td>\n",
              "      <td>0.021247</td>\n",
              "      <td>0.026823</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>0.037886</td>\n",
              "      <td>0.026463</td>\n",
              "      <td>-0.021441</td>\n",
              "      <td>-0.060568</td>\n",
              "      <td>-0.024725</td>\n",
              "      <td>0.020272</td>\n",
              "      <td>-0.001934</td>\n",
              "      <td>-0.008907</td>\n",
              "      <td>0.009538</td>\n",
              "      <td>-0.004332</td>\n",
              "      <td>-0.001864</td>\n",
              "      <td>0.004955</td>\n",
              "      <td>-0.005336</td>\n",
              "      <td>0.002001</td>\n",
              "      <td>-0.001708</td>\n",
              "      <td>-0.006463</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>-0.003640</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>-0.001442</td>\n",
              "      <td>-0.005959</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>0.002381</td>\n",
              "      <td>0.001828</td>\n",
              "      <td>-0.001456</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>-0.000570</td>\n",
              "      <td>0.002605</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>...</td>\n",
              "      <td>0.124839</td>\n",
              "      <td>0.125669</td>\n",
              "      <td>0.126854</td>\n",
              "      <td>0.133731</td>\n",
              "      <td>0.140218</td>\n",
              "      <td>0.134717</td>\n",
              "      <td>0.125654</td>\n",
              "      <td>0.119328</td>\n",
              "      <td>0.119537</td>\n",
              "      <td>0.122430</td>\n",
              "      <td>0.120289</td>\n",
              "      <td>0.121756</td>\n",
              "      <td>0.128699</td>\n",
              "      <td>0.132581</td>\n",
              "      <td>0.131261</td>\n",
              "      <td>0.129647</td>\n",
              "      <td>0.133942</td>\n",
              "      <td>0.137049</td>\n",
              "      <td>0.135974</td>\n",
              "      <td>0.138160</td>\n",
              "      <td>0.138747</td>\n",
              "      <td>0.134309</td>\n",
              "      <td>0.127496</td>\n",
              "      <td>0.122937</td>\n",
              "      <td>0.125959</td>\n",
              "      <td>0.129914</td>\n",
              "      <td>0.131720</td>\n",
              "      <td>0.133536</td>\n",
              "      <td>0.134832</td>\n",
              "      <td>0.135538</td>\n",
              "      <td>0.133731</td>\n",
              "      <td>0.132851</td>\n",
              "      <td>0.132054</td>\n",
              "      <td>0.132224</td>\n",
              "      <td>0.139767</td>\n",
              "      <td>0.147877</td>\n",
              "      <td>0.153025</td>\n",
              "      <td>0.152788</td>\n",
              "      <td>0.139843</td>\n",
              "      <td>0.121314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005732</td>\n",
              "      <td>0.007066</td>\n",
              "      <td>0.005110</td>\n",
              "      <td>0.002434</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.001382</td>\n",
              "      <td>0.001930</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.002535</td>\n",
              "      <td>-0.000113</td>\n",
              "      <td>0.000473</td>\n",
              "      <td>0.002405</td>\n",
              "      <td>0.001630</td>\n",
              "      <td>0.002221</td>\n",
              "      <td>0.002135</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.002337</td>\n",
              "      <td>0.004713</td>\n",
              "      <td>0.004801</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>0.003253</td>\n",
              "      <td>0.000918</td>\n",
              "      <td>-0.000773</td>\n",
              "      <td>0.000259</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000772</td>\n",
              "      <td>0.004269</td>\n",
              "      <td>0.007619</td>\n",
              "      <td>0.004565</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000717</td>\n",
              "      <td>-0.000957</td>\n",
              "      <td>-0.003173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141447</td>\n",
              "      <td>0.138268</td>\n",
              "      <td>0.136213</td>\n",
              "      <td>0.135355</td>\n",
              "      <td>0.136989</td>\n",
              "      <td>0.139679</td>\n",
              "      <td>0.143010</td>\n",
              "      <td>0.146465</td>\n",
              "      <td>0.144218</td>\n",
              "      <td>0.143410</td>\n",
              "      <td>0.143945</td>\n",
              "      <td>0.142914</td>\n",
              "      <td>0.146899</td>\n",
              "      <td>0.150695</td>\n",
              "      <td>0.150838</td>\n",
              "      <td>0.147119</td>\n",
              "      <td>0.142718</td>\n",
              "      <td>0.136946</td>\n",
              "      <td>0.129181</td>\n",
              "      <td>0.134041</td>\n",
              "      <td>0.139226</td>\n",
              "      <td>0.134179</td>\n",
              "      <td>0.133947</td>\n",
              "      <td>0.131320</td>\n",
              "      <td>0.125988</td>\n",
              "      <td>0.125503</td>\n",
              "      <td>0.124250</td>\n",
              "      <td>0.124186</td>\n",
              "      <td>0.124420</td>\n",
              "      <td>0.126557</td>\n",
              "      <td>0.131392</td>\n",
              "      <td>0.132404</td>\n",
              "      <td>0.134938</td>\n",
              "      <td>0.137589</td>\n",
              "      <td>0.134431</td>\n",
              "      <td>0.133174</td>\n",
              "      <td>0.133712</td>\n",
              "      <td>0.132678</td>\n",
              "      <td>0.132694</td>\n",
              "      <td>0.132117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000452</td>\n",
              "      <td>0.000604</td>\n",
              "      <td>-0.002485</td>\n",
              "      <td>-0.004562</td>\n",
              "      <td>-0.006002</td>\n",
              "      <td>-0.006382</td>\n",
              "      <td>-0.005276</td>\n",
              "      <td>-0.001489</td>\n",
              "      <td>0.005153</td>\n",
              "      <td>0.004951</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>-0.003597</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>-0.006113</td>\n",
              "      <td>-0.007007</td>\n",
              "      <td>-0.006515</td>\n",
              "      <td>-0.005303</td>\n",
              "      <td>-0.005497</td>\n",
              "      <td>-0.004017</td>\n",
              "      <td>-0.001901</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>-0.002360</td>\n",
              "      <td>-0.007317</td>\n",
              "      <td>-0.003625</td>\n",
              "      <td>-0.000644</td>\n",
              "      <td>-0.001341</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>-0.003763</td>\n",
              "      <td>-0.005992</td>\n",
              "      <td>-0.004094</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>0.003458</td>\n",
              "      <td>0.003703</td>\n",
              "      <td>-0.000745</td>\n",
              "      <td>-0.003801</td>\n",
              "      <td>-0.002695</td>\n",
              "      <td>-0.000235</td>\n",
              "      <td>-0.000247</td>\n",
              "      <td>-0.000706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116925</td>\n",
              "      <td>0.124498</td>\n",
              "      <td>0.131239</td>\n",
              "      <td>0.124867</td>\n",
              "      <td>0.123530</td>\n",
              "      <td>0.126676</td>\n",
              "      <td>0.126094</td>\n",
              "      <td>0.128428</td>\n",
              "      <td>0.128808</td>\n",
              "      <td>0.129597</td>\n",
              "      <td>0.133210</td>\n",
              "      <td>0.131184</td>\n",
              "      <td>0.128958</td>\n",
              "      <td>0.129109</td>\n",
              "      <td>0.129185</td>\n",
              "      <td>0.133316</td>\n",
              "      <td>0.137717</td>\n",
              "      <td>0.137781</td>\n",
              "      <td>0.132310</td>\n",
              "      <td>0.121513</td>\n",
              "      <td>0.120037</td>\n",
              "      <td>0.132227</td>\n",
              "      <td>0.139081</td>\n",
              "      <td>0.135362</td>\n",
              "      <td>0.129449</td>\n",
              "      <td>0.126648</td>\n",
              "      <td>0.127680</td>\n",
              "      <td>0.128090</td>\n",
              "      <td>0.127752</td>\n",
              "      <td>0.127270</td>\n",
              "      <td>0.126040</td>\n",
              "      <td>0.124815</td>\n",
              "      <td>0.125353</td>\n",
              "      <td>0.126463</td>\n",
              "      <td>0.121757</td>\n",
              "      <td>0.117611</td>\n",
              "      <td>0.118865</td>\n",
              "      <td>0.116060</td>\n",
              "      <td>0.110997</td>\n",
              "      <td>0.111912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.004362</td>\n",
              "      <td>-0.002765</td>\n",
              "      <td>-0.004905</td>\n",
              "      <td>-0.004682</td>\n",
              "      <td>-0.000267</td>\n",
              "      <td>0.004135</td>\n",
              "      <td>0.005626</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>-0.001542</td>\n",
              "      <td>0.003020</td>\n",
              "      <td>0.007453</td>\n",
              "      <td>0.008221</td>\n",
              "      <td>0.004644</td>\n",
              "      <td>0.000727</td>\n",
              "      <td>-0.001039</td>\n",
              "      <td>-0.004051</td>\n",
              "      <td>-0.006519</td>\n",
              "      <td>-0.004500</td>\n",
              "      <td>-0.001682</td>\n",
              "      <td>-0.002965</td>\n",
              "      <td>-0.002603</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>-0.003978</td>\n",
              "      <td>-0.005538</td>\n",
              "      <td>-0.005916</td>\n",
              "      <td>-0.003250</td>\n",
              "      <td>-0.001155</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.001719</td>\n",
              "      <td>-0.000121</td>\n",
              "      <td>-0.003209</td>\n",
              "      <td>-0.005932</td>\n",
              "      <td>-0.005502</td>\n",
              "      <td>-0.003120</td>\n",
              "      <td>-0.001452</td>\n",
              "      <td>-0.000775</td>\n",
              "      <td>-0.001839</td>\n",
              "      <td>-0.003113</td>\n",
              "      <td>-0.003741</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112746</td>\n",
              "      <td>0.115978</td>\n",
              "      <td>0.115545</td>\n",
              "      <td>0.111981</td>\n",
              "      <td>0.114324</td>\n",
              "      <td>0.112818</td>\n",
              "      <td>0.111041</td>\n",
              "      <td>0.113719</td>\n",
              "      <td>0.112479</td>\n",
              "      <td>0.115182</td>\n",
              "      <td>0.123094</td>\n",
              "      <td>0.127987</td>\n",
              "      <td>0.126593</td>\n",
              "      <td>0.120257</td>\n",
              "      <td>0.117611</td>\n",
              "      <td>0.118280</td>\n",
              "      <td>0.119715</td>\n",
              "      <td>0.121267</td>\n",
              "      <td>0.117990</td>\n",
              "      <td>0.116020</td>\n",
              "      <td>0.119529</td>\n",
              "      <td>0.121717</td>\n",
              "      <td>0.119389</td>\n",
              "      <td>0.114924</td>\n",
              "      <td>0.113130</td>\n",
              "      <td>0.113738</td>\n",
              "      <td>0.114183</td>\n",
              "      <td>0.115353</td>\n",
              "      <td>0.121068</td>\n",
              "      <td>0.129294</td>\n",
              "      <td>0.129091</td>\n",
              "      <td>0.125772</td>\n",
              "      <td>0.126042</td>\n",
              "      <td>0.121086</td>\n",
              "      <td>0.118511</td>\n",
              "      <td>0.125458</td>\n",
              "      <td>0.129365</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>0.122510</td>\n",
              "      <td>0.122760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2942</th>\n",
              "      <td>0.107662</td>\n",
              "      <td>0.124079</td>\n",
              "      <td>0.183420</td>\n",
              "      <td>0.289247</td>\n",
              "      <td>0.393799</td>\n",
              "      <td>0.446456</td>\n",
              "      <td>0.436931</td>\n",
              "      <td>0.363053</td>\n",
              "      <td>0.279962</td>\n",
              "      <td>0.152701</td>\n",
              "      <td>-0.036629</td>\n",
              "      <td>-0.138744</td>\n",
              "      <td>-0.124348</td>\n",
              "      <td>-0.077908</td>\n",
              "      <td>-0.042914</td>\n",
              "      <td>-0.028672</td>\n",
              "      <td>-0.041073</td>\n",
              "      <td>-0.101596</td>\n",
              "      <td>-0.175614</td>\n",
              "      <td>-0.241283</td>\n",
              "      <td>-0.269875</td>\n",
              "      <td>-0.243626</td>\n",
              "      <td>-0.207789</td>\n",
              "      <td>-0.148244</td>\n",
              "      <td>-0.090001</td>\n",
              "      <td>-0.049235</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.138663</td>\n",
              "      <td>-0.185296</td>\n",
              "      <td>-0.172049</td>\n",
              "      <td>-0.144030</td>\n",
              "      <td>-0.066441</td>\n",
              "      <td>-0.020091</td>\n",
              "      <td>0.018717</td>\n",
              "      <td>0.098879</td>\n",
              "      <td>0.160090</td>\n",
              "      <td>0.220325</td>\n",
              "      <td>0.297836</td>\n",
              "      <td>0.380437</td>\n",
              "      <td>0.499878</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.254714</td>\n",
              "      <td>-0.204254</td>\n",
              "      <td>-0.129771</td>\n",
              "      <td>-0.111090</td>\n",
              "      <td>-0.121199</td>\n",
              "      <td>-0.125646</td>\n",
              "      <td>-0.128441</td>\n",
              "      <td>-0.115726</td>\n",
              "      <td>-0.095156</td>\n",
              "      <td>-0.084208</td>\n",
              "      <td>-0.069504</td>\n",
              "      <td>-0.045775</td>\n",
              "      <td>-0.031137</td>\n",
              "      <td>-0.018302</td>\n",
              "      <td>0.012571</td>\n",
              "      <td>0.027987</td>\n",
              "      <td>0.011513</td>\n",
              "      <td>-0.017839</td>\n",
              "      <td>-0.071446</td>\n",
              "      <td>-0.123978</td>\n",
              "      <td>-0.168950</td>\n",
              "      <td>-0.236523</td>\n",
              "      <td>-0.246141</td>\n",
              "      <td>-0.164307</td>\n",
              "      <td>-0.015036</td>\n",
              "      <td>0.164701</td>\n",
              "      <td>0.100606</td>\n",
              "      <td>-0.185764</td>\n",
              "      <td>-0.319634</td>\n",
              "      <td>-0.352433</td>\n",
              "      <td>-0.386247</td>\n",
              "      <td>-0.358017</td>\n",
              "      <td>-0.328768</td>\n",
              "      <td>-0.343722</td>\n",
              "      <td>-0.408588</td>\n",
              "      <td>-0.402184</td>\n",
              "      <td>-0.351453</td>\n",
              "      <td>-0.330635</td>\n",
              "      <td>-0.254794</td>\n",
              "      <td>-0.229436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>-0.042392</td>\n",
              "      <td>-0.017244</td>\n",
              "      <td>0.015269</td>\n",
              "      <td>0.064482</td>\n",
              "      <td>0.086802</td>\n",
              "      <td>0.084482</td>\n",
              "      <td>0.101578</td>\n",
              "      <td>0.130484</td>\n",
              "      <td>0.208370</td>\n",
              "      <td>0.310620</td>\n",
              "      <td>0.406040</td>\n",
              "      <td>0.510686</td>\n",
              "      <td>0.522362</td>\n",
              "      <td>0.445744</td>\n",
              "      <td>0.316129</td>\n",
              "      <td>0.046526</td>\n",
              "      <td>-0.187785</td>\n",
              "      <td>-0.196544</td>\n",
              "      <td>-0.105807</td>\n",
              "      <td>-0.019565</td>\n",
              "      <td>0.024195</td>\n",
              "      <td>0.005535</td>\n",
              "      <td>-0.044931</td>\n",
              "      <td>-0.134279</td>\n",
              "      <td>-0.207694</td>\n",
              "      <td>-0.226039</td>\n",
              "      <td>-0.260966</td>\n",
              "      <td>-0.294753</td>\n",
              "      <td>-0.272075</td>\n",
              "      <td>-0.215169</td>\n",
              "      <td>-0.136506</td>\n",
              "      <td>-0.084216</td>\n",
              "      <td>-0.108601</td>\n",
              "      <td>-0.147826</td>\n",
              "      <td>-0.173658</td>\n",
              "      <td>-0.189847</td>\n",
              "      <td>-0.158803</td>\n",
              "      <td>-0.129845</td>\n",
              "      <td>-0.119675</td>\n",
              "      <td>-0.094032</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.584616</td>\n",
              "      <td>-0.685853</td>\n",
              "      <td>-0.560922</td>\n",
              "      <td>-0.405545</td>\n",
              "      <td>-0.304131</td>\n",
              "      <td>-0.258593</td>\n",
              "      <td>-0.285550</td>\n",
              "      <td>-0.261728</td>\n",
              "      <td>-0.225564</td>\n",
              "      <td>-0.240838</td>\n",
              "      <td>-0.197783</td>\n",
              "      <td>-0.159723</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.118271</td>\n",
              "      <td>-0.162589</td>\n",
              "      <td>-0.216840</td>\n",
              "      <td>-0.221901</td>\n",
              "      <td>-0.205019</td>\n",
              "      <td>-0.135016</td>\n",
              "      <td>-0.064633</td>\n",
              "      <td>-0.049858</td>\n",
              "      <td>-0.054309</td>\n",
              "      <td>-0.024496</td>\n",
              "      <td>-0.012791</td>\n",
              "      <td>-0.051537</td>\n",
              "      <td>-0.055480</td>\n",
              "      <td>-0.057272</td>\n",
              "      <td>-0.096431</td>\n",
              "      <td>-0.181300</td>\n",
              "      <td>-0.298825</td>\n",
              "      <td>-0.303917</td>\n",
              "      <td>-0.239700</td>\n",
              "      <td>-0.231936</td>\n",
              "      <td>-0.227728</td>\n",
              "      <td>-0.193037</td>\n",
              "      <td>-0.151306</td>\n",
              "      <td>-0.191359</td>\n",
              "      <td>-0.355499</td>\n",
              "      <td>-0.500135</td>\n",
              "      <td>-0.489756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2944</th>\n",
              "      <td>-0.147647</td>\n",
              "      <td>-0.169903</td>\n",
              "      <td>-0.168698</td>\n",
              "      <td>-0.138600</td>\n",
              "      <td>-0.144781</td>\n",
              "      <td>-0.072979</td>\n",
              "      <td>-0.040348</td>\n",
              "      <td>-0.023016</td>\n",
              "      <td>-0.025176</td>\n",
              "      <td>-0.074406</td>\n",
              "      <td>-0.061624</td>\n",
              "      <td>-0.049845</td>\n",
              "      <td>-0.008522</td>\n",
              "      <td>0.056958</td>\n",
              "      <td>0.060986</td>\n",
              "      <td>0.063136</td>\n",
              "      <td>0.082882</td>\n",
              "      <td>0.142853</td>\n",
              "      <td>0.208545</td>\n",
              "      <td>0.218749</td>\n",
              "      <td>0.262933</td>\n",
              "      <td>0.402883</td>\n",
              "      <td>0.501852</td>\n",
              "      <td>0.419210</td>\n",
              "      <td>0.321831</td>\n",
              "      <td>0.302616</td>\n",
              "      <td>0.184098</td>\n",
              "      <td>0.024618</td>\n",
              "      <td>-0.054377</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>-0.102033</td>\n",
              "      <td>-0.102809</td>\n",
              "      <td>-0.118916</td>\n",
              "      <td>-0.147251</td>\n",
              "      <td>-0.204772</td>\n",
              "      <td>-0.250798</td>\n",
              "      <td>-0.262371</td>\n",
              "      <td>-0.253296</td>\n",
              "      <td>-0.215968</td>\n",
              "      <td>-0.141196</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443611</td>\n",
              "      <td>-0.509548</td>\n",
              "      <td>-0.478118</td>\n",
              "      <td>-0.486231</td>\n",
              "      <td>-0.560368</td>\n",
              "      <td>-0.597858</td>\n",
              "      <td>-0.520692</td>\n",
              "      <td>-0.370584</td>\n",
              "      <td>-0.254734</td>\n",
              "      <td>-0.225487</td>\n",
              "      <td>-0.260446</td>\n",
              "      <td>-0.265528</td>\n",
              "      <td>-0.234353</td>\n",
              "      <td>-0.222743</td>\n",
              "      <td>-0.213553</td>\n",
              "      <td>-0.192937</td>\n",
              "      <td>-0.168708</td>\n",
              "      <td>-0.157731</td>\n",
              "      <td>-0.162184</td>\n",
              "      <td>-0.153456</td>\n",
              "      <td>-0.151518</td>\n",
              "      <td>-0.167772</td>\n",
              "      <td>-0.166744</td>\n",
              "      <td>-0.156651</td>\n",
              "      <td>-0.144423</td>\n",
              "      <td>-0.118029</td>\n",
              "      <td>-0.074986</td>\n",
              "      <td>-0.015655</td>\n",
              "      <td>0.016309</td>\n",
              "      <td>0.010407</td>\n",
              "      <td>0.001781</td>\n",
              "      <td>-0.021745</td>\n",
              "      <td>-0.079452</td>\n",
              "      <td>-0.175389</td>\n",
              "      <td>-0.267170</td>\n",
              "      <td>-0.291177</td>\n",
              "      <td>-0.294972</td>\n",
              "      <td>-0.272397</td>\n",
              "      <td>-0.067734</td>\n",
              "      <td>0.137826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945</th>\n",
              "      <td>0.071227</td>\n",
              "      <td>-0.088665</td>\n",
              "      <td>-0.070675</td>\n",
              "      <td>-0.116887</td>\n",
              "      <td>-0.214117</td>\n",
              "      <td>-0.219928</td>\n",
              "      <td>-0.275024</td>\n",
              "      <td>-0.229062</td>\n",
              "      <td>-0.245309</td>\n",
              "      <td>-0.242260</td>\n",
              "      <td>-0.171929</td>\n",
              "      <td>-0.224164</td>\n",
              "      <td>-0.156860</td>\n",
              "      <td>-0.114452</td>\n",
              "      <td>-0.123983</td>\n",
              "      <td>-0.047481</td>\n",
              "      <td>-0.034829</td>\n",
              "      <td>0.019015</td>\n",
              "      <td>0.053397</td>\n",
              "      <td>0.064815</td>\n",
              "      <td>0.102783</td>\n",
              "      <td>0.076054</td>\n",
              "      <td>0.111585</td>\n",
              "      <td>0.175587</td>\n",
              "      <td>0.272484</td>\n",
              "      <td>0.428963</td>\n",
              "      <td>0.493073</td>\n",
              "      <td>0.472147</td>\n",
              "      <td>0.416553</td>\n",
              "      <td>0.346866</td>\n",
              "      <td>0.184038</td>\n",
              "      <td>-0.033835</td>\n",
              "      <td>-0.113676</td>\n",
              "      <td>-0.096133</td>\n",
              "      <td>-0.058507</td>\n",
              "      <td>-0.048071</td>\n",
              "      <td>-0.077782</td>\n",
              "      <td>-0.116294</td>\n",
              "      <td>-0.181632</td>\n",
              "      <td>-0.222995</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.230776</td>\n",
              "      <td>-0.218813</td>\n",
              "      <td>-0.238183</td>\n",
              "      <td>-0.303088</td>\n",
              "      <td>-0.376093</td>\n",
              "      <td>-0.425958</td>\n",
              "      <td>-0.419466</td>\n",
              "      <td>-0.473214</td>\n",
              "      <td>-0.621301</td>\n",
              "      <td>-0.683392</td>\n",
              "      <td>-0.526206</td>\n",
              "      <td>-0.283650</td>\n",
              "      <td>-0.224468</td>\n",
              "      <td>-0.282644</td>\n",
              "      <td>-0.264898</td>\n",
              "      <td>-0.239692</td>\n",
              "      <td>-0.227675</td>\n",
              "      <td>-0.203244</td>\n",
              "      <td>-0.220293</td>\n",
              "      <td>-0.229015</td>\n",
              "      <td>-0.190494</td>\n",
              "      <td>-0.136629</td>\n",
              "      <td>-0.095722</td>\n",
              "      <td>-0.105208</td>\n",
              "      <td>-0.127424</td>\n",
              "      <td>-0.133253</td>\n",
              "      <td>-0.165599</td>\n",
              "      <td>-0.197638</td>\n",
              "      <td>-0.199778</td>\n",
              "      <td>-0.187415</td>\n",
              "      <td>-0.156169</td>\n",
              "      <td>-0.128266</td>\n",
              "      <td>-0.083245</td>\n",
              "      <td>-0.015681</td>\n",
              "      <td>-0.017426</td>\n",
              "      <td>-0.038509</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>-0.003512</td>\n",
              "      <td>-0.111786</td>\n",
              "      <td>-0.276068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>-0.193642</td>\n",
              "      <td>-0.064987</td>\n",
              "      <td>-0.097122</td>\n",
              "      <td>-0.055735</td>\n",
              "      <td>0.041101</td>\n",
              "      <td>-0.069489</td>\n",
              "      <td>-0.104058</td>\n",
              "      <td>-0.149939</td>\n",
              "      <td>-0.268934</td>\n",
              "      <td>-0.273483</td>\n",
              "      <td>-0.321686</td>\n",
              "      <td>-0.304652</td>\n",
              "      <td>-0.244038</td>\n",
              "      <td>-0.267188</td>\n",
              "      <td>-0.202978</td>\n",
              "      <td>-0.151805</td>\n",
              "      <td>-0.117989</td>\n",
              "      <td>-0.056056</td>\n",
              "      <td>-0.033551</td>\n",
              "      <td>0.023934</td>\n",
              "      <td>0.025335</td>\n",
              "      <td>0.002137</td>\n",
              "      <td>0.062426</td>\n",
              "      <td>0.092002</td>\n",
              "      <td>0.103503</td>\n",
              "      <td>0.134829</td>\n",
              "      <td>0.144563</td>\n",
              "      <td>0.181288</td>\n",
              "      <td>0.276287</td>\n",
              "      <td>0.366257</td>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.518920</td>\n",
              "      <td>0.511258</td>\n",
              "      <td>0.430766</td>\n",
              "      <td>0.225377</td>\n",
              "      <td>-0.097748</td>\n",
              "      <td>-0.197081</td>\n",
              "      <td>-0.093032</td>\n",
              "      <td>-0.098751</td>\n",
              "      <td>-0.092378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.239171</td>\n",
              "      <td>-0.290206</td>\n",
              "      <td>-0.303726</td>\n",
              "      <td>-0.307908</td>\n",
              "      <td>-0.292706</td>\n",
              "      <td>-0.256507</td>\n",
              "      <td>-0.243051</td>\n",
              "      <td>-0.246092</td>\n",
              "      <td>-0.294946</td>\n",
              "      <td>-0.371723</td>\n",
              "      <td>-0.402845</td>\n",
              "      <td>-0.437000</td>\n",
              "      <td>-0.562383</td>\n",
              "      <td>-0.702058</td>\n",
              "      <td>-0.670948</td>\n",
              "      <td>-0.469834</td>\n",
              "      <td>-0.276469</td>\n",
              "      <td>-0.214648</td>\n",
              "      <td>-0.277310</td>\n",
              "      <td>-0.304957</td>\n",
              "      <td>-0.270843</td>\n",
              "      <td>-0.284196</td>\n",
              "      <td>-0.264903</td>\n",
              "      <td>-0.230607</td>\n",
              "      <td>-0.227316</td>\n",
              "      <td>-0.170396</td>\n",
              "      <td>-0.146518</td>\n",
              "      <td>-0.136173</td>\n",
              "      <td>-0.103573</td>\n",
              "      <td>-0.129311</td>\n",
              "      <td>-0.123657</td>\n",
              "      <td>-0.134904</td>\n",
              "      <td>-0.186747</td>\n",
              "      <td>-0.158777</td>\n",
              "      <td>-0.123668</td>\n",
              "      <td>-0.092933</td>\n",
              "      <td>-0.063138</td>\n",
              "      <td>-0.072539</td>\n",
              "      <td>-0.050975</td>\n",
              "      <td>-0.028925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2947 rows × 1152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       125       126       127\n",
              "0     0.011653  0.013109  0.011269  ...  0.144395  0.144703  0.145494\n",
              "1     0.009280  0.004930  0.003954  ...  0.152788  0.139843  0.121314\n",
              "2     0.005732  0.007066  0.005110  ...  0.132678  0.132694  0.132117\n",
              "3     0.000452  0.000604 -0.002485  ...  0.116060  0.110997  0.111912\n",
              "4    -0.004362 -0.002765 -0.004905  ...  0.125895  0.122510  0.122760\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "2942  0.107662  0.124079  0.183420  ... -0.330635 -0.254794 -0.229436\n",
              "2943 -0.042392 -0.017244  0.015269  ... -0.355499 -0.500135 -0.489756\n",
              "2944 -0.147647 -0.169903 -0.168698  ... -0.272397 -0.067734  0.137826\n",
              "2945  0.071227 -0.088665 -0.070675  ... -0.003512 -0.111786 -0.276068\n",
              "2946 -0.193642 -0.064987 -0.097122  ... -0.072539 -0.050975 -0.028925\n",
              "\n",
              "[2947 rows x 1152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybJr00SL2VKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = pd.read_csv(url + 'train/y_train.txt', header = None, names= ['label'])\n",
        "test_y =pd.read_csv(url + 'test/y_test.txt', header =None, names= ['label'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkyywIenKI4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_y)):\n",
        "  if train_y.loc[i,'label'] >=7 :\n",
        "    train_csv.drop(i, inplace =True)\n",
        "    train_y.drop(i, inplace = True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSdh3XUtnHmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_y)):\n",
        "  if test_y.loc[i,'label'] >=7 :\n",
        "    test_csv.drop(i, inplace =True)\n",
        "    test_y.drop(i, inplace = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "affPrcutm8Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D = np.array(train_csv).reshape(train_csv.shape[0], 128, -1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-CfxEUqn6SD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29cbd3aa-49bd-417c-910f-770a65b14d07"
      },
      "source": [
        "train_D.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 128, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx0uklb3qXuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D = np.array(test_csv).reshape(test_csv.shape[0],128,-1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aG7orNwqbZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D = torch.FloatTensor(test_D)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzmjnIAEP5FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(train_y)\n",
        "train_L = encoder.transform(train_y).toarray()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akjZ4UzFUK79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_L = encoder.transform(test_y).toarray()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuOs53QqDYc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D = torch.FloatTensor(train_D)\n",
        "train_L = torch.FloatTensor(np.array(train_L))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz6BcuUtDZuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_D, train_L), batch_size = 100, shuffle= False, drop_last = True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_AV-tEL49gz",
        "colab_type": "text"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuZDS9Mk47iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "d3095462-5104-4339-b222-3db517108034"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42, decision_function_shape='ova')\n",
        "params = {\n",
        "    'C' : [0.5,1,10]\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(train_csv, train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ova', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={'C': [0.5, 1, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrPPB1yk48rc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc8ad2a3-0902-47a1-fa0c-3f65e28e036b"
      },
      "source": [
        "pred = cv.predict(test_csv)\n",
        "\n",
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM : 0.8982015609093994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCflkIRP4-sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f13e7df8-7c21-4834-cb3f-5ad1b543225d"
      },
      "source": [
        "print(classification_report(pred, test_y)) #support는 정밀도의 평균? "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.91      0.94       520\n",
            "           2       0.92      0.90      0.91       480\n",
            "           3       0.89      0.90      0.89       418\n",
            "           4       0.77      0.84      0.80       452\n",
            "           5       0.84      0.83      0.84       540\n",
            "           6       1.00      1.00      1.00       537\n",
            "\n",
            "    accuracy                           0.90      2947\n",
            "   macro avg       0.90      0.90      0.90      2947\n",
            "weighted avg       0.90      0.90      0.90      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7SRc9s5Wyc",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwSh4fmDTks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "# filter 수 늘리는게 중요? kernel size 크게,\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 5, stride= 1), torch.nn.MaxPool1d(kernel_size= 1), \n",
        "                                          torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,64, kernel_size= 3, stride= 1, padding =0),\n",
        "                                          torch.nn.MaxPool1d(kernel_size= 1, stride = 1, padding = 0), \n",
        "                                          torch.nn.ReLU())\n",
        "        self.f1 = torch.nn.Flatten()\n",
        "        self.layer3 = torch.nn.Linear(192 , output_size, bias = True) #(input_size - kernel_size + 2*padding_size)/stride + 1\n",
        "        #self.tanh = torch.nn.Tanh()\n",
        "        torch.nn.init.kaiming_uniform(self.layer3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        #print(out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWQ0Z_DzDW3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fc0164f1-4234-42c6-dfe4-e99449ec5d6d"
      },
      "source": [
        "model = CNN(train_D.shape[1], train_L.shape[1]).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP6vk6SpDbE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "db54da3c-e691-469b-e828-a4e07747a4dd"
      },
      "source": [
        "running_loss =0\n",
        "for e in range(1001):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    #print(x.shape)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if (e+1) % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-488-332ccd219d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-486-2df454e95d64>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_gJTnBDDc5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  pred=  model(test_D.to(device))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZWBknl5Qf6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uug_TSIQ-X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHcrpBY1-Qvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(pred).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atdZhnKEDf1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b39b3c2a-104c-41a6-b0e4-39b4a4d3e37c"
      },
      "source": [
        "acc = [np.argmax(pred_lstm.cpu()[i])== np.argmax(test_L[i]) for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN :  0.7960638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LADqBC0Dn0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(np.round(pred.cpu()), np.array(test_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeO21c_qSI-V",
        "colab_type": "text"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDyG3iQPsDVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77y55FdPrP2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#step size : 128\n",
        "#input = (batch_size, time_steps, input_size)\n",
        "#rnn( input_size, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lds535bNSJ7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "  def __init__(self, n_class, bi):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(9, 32)\n",
        "    #self.lstm2 = torch.nn.LSTM(32, 32)\n",
        "    self.l1 = torch.nn.Linear(128*32, n_class)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.shape)\n",
        "    #x = x.permute(1,0,2)# 축 바꾸기. 전치행렬처럼\n",
        "    #print(x.shape)\n",
        "    out, hidden = self.lstm(x)\n",
        "    #out, _  = self.lstm2(out, hidden)\n",
        "    #out, _ = self.lstm2(out, hidden)\n",
        "    #print(out.shape)\n",
        "    out = self.tanh(out)\n",
        "    out = self.dropout(out)\n",
        "    out = out.contiguous().view(-1, 128*32)\n",
        "    #print(out.shape)\n",
        "    out = self.l1(out)\n",
        "    #out = self.softmax(out)\n",
        "    return out\n",
        "#소프트맥스 지말고 탄젠트나써라"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTIChXTDSMJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(train_L.shape[1], False).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZTXZ_kuOZfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bb72acb-27fb-49bb-b205-2784d1921c7e"
      },
      "source": [
        "train_L.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA2XCtwRSNDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSOcIVeWSPUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b9b94980-98c0-44cf-b943-8a860a3781a9"
      },
      "source": [
        "running_loss =0\n",
        "for e in range(201):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 10 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] loss : 0.078\n",
            "[10] loss : 0.424\n",
            "[20] loss : 0.231\n",
            "[30] loss : 0.177\n",
            "[40] loss : 0.163\n",
            "[50] loss : 0.137\n",
            "[60] loss : 0.129\n",
            "[70] loss : 0.117\n",
            "[80] loss : 0.113\n",
            "[90] loss : 0.112\n",
            "[100] loss : 0.103\n",
            "[110] loss : 0.102\n",
            "[120] loss : 0.097\n",
            "[130] loss : 0.094\n",
            "[140] loss : 0.093\n",
            "[150] loss : 0.086\n",
            "[160] loss : 0.086\n",
            "[170] loss : 0.084\n",
            "[180] loss : 0.080\n",
            "[190] loss : 0.079\n",
            "[200] loss : 0.078\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA9gSys-mwjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOXGGJ0TSQhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  pred_lstm = model(test_D.to(device))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5za2568nTSmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_lstm.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsVCdynT2KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_L.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a41DwJzSUxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029a55fe-2d23-48eb-a67c-48a28eba05c2"
      },
      "source": [
        "acc = [np.argmax(pred_lstm.cpu()[i])== np.argmax(test_L[i]) for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM :  0.9290804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2BMeuelfln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(classification_report(np.round(pred_lstm.cpu()), np.array(test_y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcT-pgfbaFkV",
        "colab_type": "text"
      },
      "source": [
        "#CNN + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjbRYRA0aHZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "# filter 수 늘리는게 중요? kernel size 크게,\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 5, stride= 1), torch.nn.MaxPool1d(kernel_size= 1), \n",
        "                                          torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,64, kernel_size= 3, stride= 1, padding =0),\n",
        "                                          torch.nn.MaxPool1d(kernel_size= 1, stride = 1, padding = 0), \n",
        "                                          torch.nn.ReLU())\n",
        "        self.f1 = torch.nn.Flatten()\n",
        "        self.layer3 = torch.nn.Linear(192 , output_size, bias = True) #(input_size - kernel_size + 2*padding_size)/stride + 1\n",
        "        #self.tanh = torch.nn.Tanh()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        torch.nn.init.kaiming_uniform(self.layer3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.f1(out)\n",
        "        #print(out.shape)\n",
        "        model = self.layer3(out)\n",
        "        model = self.tanh(model)\n",
        "        #model = self.tanh(model)\n",
        "        return out, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItFXyLfXav8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f4c5f602-79f1-4124-a9a4-8e8a56253cd0"
      },
      "source": [
        "model = CNN(train_D.shape[1], train_L.shape[1]).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2htLFNy6aUKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c79d2bff-eff9-4757-98d2-2cf888383028"
      },
      "source": [
        "running_loss = 0\n",
        "new_train = []\n",
        "epoch =1001\n",
        "for e in range(epoch + 1):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    #print(x.shape)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    new_x, h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if e == epoch:\n",
        "        new_train.extend(new_x.cpu().detach().numpy())\n",
        "\n",
        "  if (e+1) % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "  \n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[99] loss : 0.273\n",
            "[199] loss : 0.210\n",
            "[299] loss : 0.180\n",
            "[399] loss : 0.151\n",
            "[499] loss : 0.121\n",
            "[599] loss : 0.126\n",
            "[699] loss : 0.103\n",
            "[799] loss : 0.089\n",
            "[899] loss : 0.087\n",
            "[999] loss : 0.074\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu-8utTmkH3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVMOTtbsa8X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(new_train).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap4EcbtGwdRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73KEDDgXqlDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_csv.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nspK7nYUaR1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "407baacf-7342-4a69-ce86-35eedf111711"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42, C = 0.5, kernel = 'linear')\n",
        "params = {\n",
        "    #'decision_function_shape' : [ 'ovr', 'ova'],\n",
        "    #'C' : [0.5,1,10], 'kernel':['rbf','linear']\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(np.array(new_train), train_y[:-52])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=0.5, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='linear', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ5XV-O892j6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81929509-86de-4f6a-db1e-4dbb0fe9db27"
      },
      "source": [
        "cv.best_params_# 0.5, ovr, linear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ9lwGE7pn-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  new_test, _=  model(test_D.to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVqz8d0jtTl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c00ddc-c83b-40d3-ce5a-3a77e4b75c03"
      },
      "source": [
        "new_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2947, 192])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoB9GL44-u7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for_test = new_test.cpu()#np.resize(new_test.cpu(), (2947, 64*3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOCo4PSeptjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = cv.predict(for_test)#(new_test.cpu().reshape(2947, 128*3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdVeFpxotdWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab24f4cc-91e2-44ce-dccb-d8f3a46ebe62"
      },
      "source": [
        "np.array(pred).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6cPtNfutbH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea8d8c97-6ed7-4359-d240-dbb49c26ee84"
      },
      "source": [
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG4k3NtV7gmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "14c54bcd-ddad-43dc-c21a-2b813a26e5a3"
      },
      "source": [
        "print(classification_report(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.85      0.90       557\n",
            "           2       0.89      0.94      0.91       444\n",
            "           3       0.92      0.95      0.94       405\n",
            "           4       0.75      0.79      0.77       465\n",
            "           5       0.83      0.82      0.82       539\n",
            "           6       1.00      1.00      1.00       537\n",
            "\n",
            "    accuracy                           0.89      2947\n",
            "   macro avg       0.89      0.89      0.89      2947\n",
            "weighted avg       0.89      0.89      0.89      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ZRoDhnpym2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aede0d2c-b264-437b-8e24-11ebe5892317"
      },
      "source": [
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"CNN_SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN_SVM : 0.8903970139124533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2kdJcT55RNq",
        "colab_type": "text"
      },
      "source": [
        "#LSTM + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq-LUp6P5QqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "  def __init__(self, n_class, bi):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(9, 32)\n",
        "    #self.lstm2 = torch.nn.LSTM(32, 32)\n",
        "    self.l1 = torch.nn.Linear(128*32, n_class)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.shape)\n",
        "    #x = x.permute(1,0,2)# 축 바꾸기. 전치행렬처럼\n",
        "    #print(x.shape)\n",
        "    out, hidden = self.lstm(x)\n",
        "    #out, _  = self.lstm2(out, hidden)\n",
        "    #print(out.shape)\n",
        "    out = self.tanh(out)\n",
        "    #out = self.dropout(out)\n",
        "    out = out.contiguous().view(-1, 128*32)\n",
        "    #print(out.shape)\n",
        "    model = self.l1(out)\n",
        "    #out = self.softmax(out)\n",
        "    return out, model\n",
        "#소프트맥스 지말고 탄젠트나써라"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m35grDGwm5a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(train_L.shape[1], False).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-HWeR6Mm89O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePSqa53ynCac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cc73028b-05c9-4317-bbcd-ad13e4a3d9c6"
      },
      "source": [
        "running_loss = 0\n",
        "epoch = 200\n",
        "new_train = []\n",
        "for e in range(epoch+1):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    new_t, h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss  += loss.item()\n",
        "    if e == epoch:\n",
        "      new_train.extend(new_t.cpu().detach().numpy())\n",
        "  if (e) % 10 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss = 0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] loss : 0.078\n",
            "[10] loss : 0.394\n",
            "[20] loss : 0.211\n",
            "[30] loss : 0.161\n",
            "[40] loss : 0.133\n",
            "[50] loss : 0.124\n",
            "[60] loss : 0.114\n",
            "[70] loss : 0.108\n",
            "[80] loss : 0.096\n",
            "[90] loss : 0.099\n",
            "[100] loss : 0.089\n",
            "[110] loss : 0.087\n",
            "[120] loss : 0.080\n",
            "[130] loss : 0.074\n",
            "[140] loss : 0.078\n",
            "[150] loss : 0.073\n",
            "[160] loss : 0.069\n",
            "[170] loss : 0.071\n",
            "[180] loss : 0.068\n",
            "[190] loss : 0.066\n",
            "[200] loss : 0.062\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRILBebx3cPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9025d8d-16bc-47d2-b0df-2245a6f3ae4b"
      },
      "source": [
        "np.array(new_train).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7300, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5HeyG0Cn1S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_train = np.resize(new_train, (7400,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-zN557L2bY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2925de3c-c62a-45b6-eadc-bc56834f1e4f"
      },
      "source": [
        "new_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.01777264,  0.06048835, -0.01753551, ..., -0.04283169,\n",
              "         0.04891417,  0.04133761], dtype=float32),\n",
              " array([ 0.00207993,  0.0313543 , -0.00095009, ..., -0.03336694,\n",
              "         0.04389487,  0.04810051], dtype=float32),\n",
              " array([-0.00654274,  0.01649543,  0.00906717, ..., -0.02660595,\n",
              "         0.04047364,  0.04541314], dtype=float32),\n",
              " array([-0.01196849,  0.0085832 ,  0.01459578, ..., -0.023973  ,\n",
              "         0.04107356,  0.03982279], dtype=float32),\n",
              " array([-0.01465636,  0.00432397,  0.01668845, ..., -0.02235164,\n",
              "         0.04303858,  0.03312483], dtype=float32),\n",
              " array([-0.0169461 ,  0.00208852,  0.01784271, ..., -0.02072057,\n",
              "         0.04537154,  0.0259371 ], dtype=float32),\n",
              " array([-0.01811997,  0.00089237,  0.01792175, ..., -0.01787638,\n",
              "         0.04674875,  0.01804803], dtype=float32),\n",
              " array([-1.8954560e-02,  6.4177955e-05,  1.8106893e-02, ...,\n",
              "        -1.4892922e-02,  4.7903009e-02,  1.0539680e-02], dtype=float32),\n",
              " array([-0.01878494, -0.00055484,  0.01760163, ..., -0.01244983,\n",
              "         0.04916226,  0.00409086], dtype=float32),\n",
              " array([-0.01889117, -0.00086215,  0.01741363, ..., -0.01101422,\n",
              "         0.05101197,  0.00035158], dtype=float32),\n",
              " array([-0.01773359, -0.00126414,  0.01654334, ..., -0.00956932,\n",
              "         0.05181666, -0.00421245], dtype=float32),\n",
              " array([-0.01667747, -0.00141971,  0.01614876, ..., -0.00767226,\n",
              "         0.05215353, -0.00797577], dtype=float32),\n",
              " array([-0.01565308, -0.00161944,  0.01590328, ..., -0.00623955,\n",
              "         0.05242914, -0.01115304], dtype=float32),\n",
              " array([-0.01461147, -0.00187906,  0.01571152, ..., -0.00536362,\n",
              "         0.05282274, -0.0132243 ], dtype=float32),\n",
              " array([-0.01082085, -0.00241164,  0.0144896 , ...,  0.00065551,\n",
              "         0.04411895, -0.02329224], dtype=float32),\n",
              " array([-0.0107017 , -0.00218536,  0.01517317, ...,  0.00471123,\n",
              "         0.03754711, -0.02853633], dtype=float32),\n",
              " array([-0.01055404, -0.0022394 ,  0.01546999, ...,  0.00610884,\n",
              "         0.03699731, -0.03087305], dtype=float32),\n",
              " array([-0.01053775, -0.00227095,  0.01555042, ...,  0.00665882,\n",
              "         0.0383719 , -0.03028532], dtype=float32),\n",
              " array([-0.01093375, -0.00236956,  0.01552263, ...,  0.00704952,\n",
              "         0.03776545, -0.02800775], dtype=float32),\n",
              " array([-0.01121341, -0.00255934,  0.01494739, ...,  0.00706592,\n",
              "         0.0371289 , -0.02512474], dtype=float32),\n",
              " array([-0.01123625, -0.00289946,  0.01414247, ...,  0.00656075,\n",
              "         0.03656126, -0.02214298], dtype=float32),\n",
              " array([-0.01058628, -0.00325196,  0.01297921, ...,  0.00592778,\n",
              "         0.03479171, -0.0192393 ], dtype=float32),\n",
              " array([-0.00967856, -0.00358988,  0.01194745, ...,  0.00490094,\n",
              "         0.03337292, -0.01671731], dtype=float32),\n",
              " array([-0.0091044 , -0.00369556,  0.01128868, ...,  0.00433502,\n",
              "         0.03223377, -0.0141747 ], dtype=float32),\n",
              " array([-0.00810577, -0.00385467,  0.01071283, ...,  0.00371982,\n",
              "         0.03055341, -0.01199111], dtype=float32),\n",
              " array([-0.0080273 , -0.00375594,  0.0106504 , ...,  0.00299735,\n",
              "         0.02917388, -0.01029979], dtype=float32),\n",
              " array([-0.0079818 , -0.0039272 ,  0.01035926, ...,  0.00239077,\n",
              "         0.0283074 , -0.00876449], dtype=float32),\n",
              " array([-1.9006552e-02,  5.0785868e-05,  1.6543074e-02, ...,\n",
              "        -2.7935069e-02,  4.0493421e-02,  2.4620881e-02], dtype=float32),\n",
              " array([-0.01935062, -0.00382567,  0.00784748, ..., -0.03669652,\n",
              "         0.03107825,  0.02584974], dtype=float32),\n",
              " array([-1.0295483e-02, -6.3180015e-03, -9.1983740e-05, ...,\n",
              "        -3.0659901e-02,  2.8275881e-02,  2.0088119e-02], dtype=float32),\n",
              " array([-0.00672313, -0.00636304, -0.00098781, ..., -0.02908498,\n",
              "         0.01985267,  0.01712516], dtype=float32),\n",
              " array([-3.7455994e-03, -6.0567944e-03, -1.2166728e-05, ...,\n",
              "        -2.4590258e-02,  2.0292429e-02,  1.0201634e-02], dtype=float32),\n",
              " array([-0.01502171,  0.00164871,  0.01065229, ..., -0.02260791,\n",
              "         0.02214904,  0.00831381], dtype=float32),\n",
              " array([-0.02309306, -0.00110144,  0.00417648, ..., -0.02241194,\n",
              "         0.02256496,  0.00814357], dtype=float32),\n",
              " array([-0.00754856, -0.00591576, -0.00856448, ..., -0.02292949,\n",
              "         0.02266619,  0.00893009], dtype=float32),\n",
              " array([-0.00535746, -0.0057762 , -0.00793741, ..., -0.02345351,\n",
              "         0.02250325,  0.01049069], dtype=float32),\n",
              " array([-0.00251242, -0.00553967, -0.00565239, ..., -0.02394308,\n",
              "         0.02197557,  0.01292474], dtype=float32),\n",
              " array([-0.00129517, -0.00506093, -0.00279199, ..., -0.02382803,\n",
              "         0.0218253 ,  0.01454878], dtype=float32),\n",
              " array([-0.00377572, -0.00422883,  0.00076925, ..., -0.0181177 ,\n",
              "         0.02821396, -0.00038014], dtype=float32),\n",
              " array([-0.00622605, -0.00410179,  0.00244688, ..., -0.01537914,\n",
              "         0.03152736,  0.00465569], dtype=float32),\n",
              " array([-0.0045878 , -0.00488059,  0.00131955, ..., -0.01529966,\n",
              "         0.03113288,  0.01054259], dtype=float32),\n",
              " array([-0.00292399, -0.00487632,  0.00091512, ..., -0.0162555 ,\n",
              "         0.03026773,  0.01512917], dtype=float32),\n",
              " array([-0.0035174 , -0.00451401,  0.00199212, ..., -0.01703854,\n",
              "         0.02947473,  0.01779365], dtype=float32),\n",
              " array([-0.00384236, -0.00427404,  0.00286584, ..., -0.01735215,\n",
              "         0.02929075,  0.018971  ], dtype=float32),\n",
              " array([-0.00446795, -0.00386486,  0.00350364, ..., -0.01800549,\n",
              "         0.02872084,  0.02154784], dtype=float32),\n",
              " array([-0.00532722, -0.00354853,  0.00407772, ..., -0.01871778,\n",
              "         0.02803473,  0.02334596], dtype=float32),\n",
              " array([-0.0061984 , -0.00342768,  0.0042938 , ..., -0.0189379 ,\n",
              "         0.02777239,  0.02377563], dtype=float32),\n",
              " array([-0.00661365, -0.00346553,  0.00418453, ..., -0.01883834,\n",
              "         0.027898  ,  0.02369858], dtype=float32),\n",
              " array([-0.00648913, -0.00342479,  0.00411281, ..., -0.01892105,\n",
              "         0.02777352,  0.02488211], dtype=float32),\n",
              " array([-0.00766016, -0.00313299,  0.00481057, ..., -0.01885475,\n",
              "         0.02785806,  0.02495255], dtype=float32),\n",
              " array([-0.00692331, -0.00326098,  0.00436188, ..., -0.01893848,\n",
              "         0.02764325,  0.02600292], dtype=float32),\n",
              " array([ 0.00643483, -0.0031253 , -0.00050694, ..., -0.02698461,\n",
              "         0.01765115,  0.03716214], dtype=float32),\n",
              " array([ 0.00166962, -0.00148036,  0.00302902, ..., -0.0267843 ,\n",
              "         0.01420815,  0.0319812 ], dtype=float32),\n",
              " array([-0.00600243, -0.00029503,  0.00819696, ..., -0.02474856,\n",
              "         0.01352964,  0.03099182], dtype=float32),\n",
              " array([-0.00840654, -0.0005999 ,  0.00913454, ..., -0.02310242,\n",
              "         0.0135921 ,  0.03131622], dtype=float32),\n",
              " array([-0.00997153, -0.00107312,  0.00896805, ..., -0.02201217,\n",
              "         0.01370927,  0.03240865], dtype=float32),\n",
              " array([-0.00992623, -0.00169901,  0.00796924, ..., -0.02115774,\n",
              "         0.01389779,  0.03372869], dtype=float32),\n",
              " array([-0.00976766, -0.0021808 ,  0.00750883, ..., -0.02054617,\n",
              "         0.01410823,  0.03529699], dtype=float32),\n",
              " array([-0.00942319, -0.0024704 ,  0.00724872, ..., -0.02009843,\n",
              "         0.01417463,  0.03688267], dtype=float32),\n",
              " array([-0.00860075, -0.00272535,  0.00702336, ..., -0.01967019,\n",
              "         0.01419723,  0.03829509], dtype=float32),\n",
              " array([-0.00842362, -0.00258647,  0.00700615, ..., -0.01923104,\n",
              "         0.01421746,  0.03957865], dtype=float32),\n",
              " array([-0.00818467, -0.00252465,  0.00728794, ..., -0.01882602,\n",
              "         0.01422336,  0.0407274 ], dtype=float32),\n",
              " array([-0.00789134, -0.00267436,  0.007501  , ..., -0.01839796,\n",
              "         0.0142455 ,  0.04184174], dtype=float32),\n",
              " array([-0.00727311, -0.00280377,  0.00758149, ..., -0.01790306,\n",
              "         0.0143821 ,  0.04292403], dtype=float32),\n",
              " array([ 0.04679888,  0.01068476,  0.01654443, ..., -0.01644403,\n",
              "         0.01589992,  0.04404677], dtype=float32),\n",
              " array([-0.00676575,  0.01422562, -0.01686616, ..., -0.01625956,\n",
              "         0.01652062,  0.04656035], dtype=float32),\n",
              " array([ 0.00213957,  0.00505516, -0.03448971, ..., -0.01832712,\n",
              "         0.01103572,  0.03977729], dtype=float32),\n",
              " array([ 0.00821673, -0.00175326, -0.03066398, ..., -0.01590475,\n",
              "         0.01066938,  0.0383727 ], dtype=float32),\n",
              " array([ 0.00037061,  0.00283408, -0.0064762 , ..., -0.01343163,\n",
              "         0.01225264,  0.04069374], dtype=float32),\n",
              " array([ 0.01929234, -0.00898453, -0.02154012, ..., -0.01301361,\n",
              "         0.01134176,  0.040576  ], dtype=float32),\n",
              " array([ 0.01862589, -0.00952781, -0.01629336, ..., -0.01205278,\n",
              "         0.00838548,  0.03258216], dtype=float32),\n",
              " array([ 0.01379977,  0.00294889,  0.01114568, ..., -0.00926078,\n",
              "         0.007231  ,  0.02930732], dtype=float32),\n",
              " array([-0.00565224, -0.00523563, -0.00429556, ..., -0.00673724,\n",
              "         0.00691865,  0.02827836], dtype=float32),\n",
              " array([ 0.0060061 , -0.01168711, -0.0170818 , ..., -0.00462076,\n",
              "         0.0069245 ,  0.02797364], dtype=float32),\n",
              " array([ 0.00834547, -0.01201741, -0.01470972, ..., -0.00281159,\n",
              "         0.00702426,  0.02792912], dtype=float32),\n",
              " array([ 0.00906976, -0.01133499, -0.00895542, ..., -0.00124187,\n",
              "         0.00708223,  0.02804043], dtype=float32),\n",
              " array([ 0.00904289, -0.01056533, -0.00387946, ...,  0.00010138,\n",
              "         0.00703243,  0.02827959], dtype=float32),\n",
              " array([ 0.00700678, -0.00968861,  0.00042599, ...,  0.00127709,\n",
              "         0.00690497,  0.02878577], dtype=float32),\n",
              " array([ 0.01161619, -0.00326082,  0.00538345, ...,  0.01018809,\n",
              "        -0.01023201, -0.11856913], dtype=float32),\n",
              " array([ 0.02008956,  0.00519164,  0.01807206, ...,  0.01927145,\n",
              "        -0.01591058, -0.07276987], dtype=float32),\n",
              " array([-0.03892326,  0.01440505,  0.02913079, ...,  0.02145558,\n",
              "        -0.01747731, -0.06415836], dtype=float32),\n",
              " array([-0.04517314,  0.01274402,  0.00489504, ...,  0.01974612,\n",
              "        -0.042843  ,  0.02687974], dtype=float32),\n",
              " array([ 0.02848271,  0.0176792 , -0.03586566, ...,  0.01709012,\n",
              "        -0.03466517, -0.03326348], dtype=float32),\n",
              " array([-0.01205789,  0.01728965,  0.02290974, ...,  0.01640954,\n",
              "        -0.00962233, -0.02373672], dtype=float32),\n",
              " array([ 0.02082963,  0.01847375, -0.01165662, ...,  0.01790008,\n",
              "        -0.00424576, -0.04836525], dtype=float32),\n",
              " array([-0.01922322,  0.02943448,  0.01983435, ...,  0.02325283,\n",
              "        -0.01479718, -0.01640189], dtype=float32),\n",
              " array([ 0.00876256,  0.0245035 , -0.00327712, ...,  0.01821197,\n",
              "        -0.00563999, -0.03583499], dtype=float32),\n",
              " array([-0.00610024,  0.01276063,  0.01847427, ...,  0.02137563,\n",
              "        -0.01620162, -0.02309408], dtype=float32),\n",
              " array([-0.02738872,  0.01015945,  0.06661185, ...,  0.02228078,\n",
              "        -0.03660392,  0.00503886], dtype=float32),\n",
              " array([-0.06679649, -0.00138111,  0.05569547, ...,  0.0200078 ,\n",
              "        -0.06049053,  0.02374323], dtype=float32),\n",
              " array([-0.02072626, -0.01581741,  0.01616376, ...,  0.00667678,\n",
              "        -0.03815851, -0.03721171], dtype=float32),\n",
              " array([-0.04990171, -0.02289626,  0.06853417, ..., -0.00452224,\n",
              "         0.0197488 , -0.00681083], dtype=float32),\n",
              " array([-0.02958709, -0.04919563,  0.02596896, ...,  0.00917079,\n",
              "         0.00583752, -0.02140422], dtype=float32),\n",
              " array([-0.05498433, -0.03710799,  0.04194931, ...,  0.00745539,\n",
              "        -0.00480616, -0.02652588], dtype=float32),\n",
              " array([-0.05878512, -0.01012004,  0.04080886, ..., -0.00058308,\n",
              "        -0.00816345, -0.03453787], dtype=float32),\n",
              " array([-0.03379489, -0.01078862,  0.00677504, ...,  0.00627641,\n",
              "        -0.05819222,  0.01037669], dtype=float32),\n",
              " array([ 0.01451071,  0.00668878, -0.0229073 , ..., -0.01105448,\n",
              "        -0.0734596 , -0.01413996], dtype=float32),\n",
              " array([-0.03186807,  0.00796081,  0.01576093, ..., -0.03164127,\n",
              "        -0.04545115, -0.04399617], dtype=float32),\n",
              " array([-0.01360895,  0.00065177,  0.00848876, ..., -0.03171125,\n",
              "        -0.03300308, -0.03164219], dtype=float32),\n",
              " array([-0.01630014, -0.00902992,  0.03337251, ..., -0.05118833,\n",
              "         0.01830311, -0.02558057], dtype=float32),\n",
              " array([-0.00614112,  0.09426337, -0.03631211, ...,  0.01403592,\n",
              "         0.00232071, -0.0332908 ], dtype=float32),\n",
              " array([-0.02507729,  0.03515726,  0.00980015, ...,  0.01821038,\n",
              "        -0.02123217, -0.03098102], dtype=float32),\n",
              " array([-0.03381083,  0.0221847 ,  0.0318171 , ...,  0.0203342 ,\n",
              "        -0.04589869, -0.0194422 ], dtype=float32),\n",
              " array([-0.0177651 ,  0.00480612,  0.00573989, ...,  0.00958408,\n",
              "        -0.0696574 , -0.00907321], dtype=float32),\n",
              " array([-0.01938492, -0.00946889,  0.01836436, ..., -0.00138617,\n",
              "        -0.00278889, -0.0121818 ], dtype=float32),\n",
              " array([ 0.0040224 ,  0.01127088,  0.04984703, ..., -0.01906474,\n",
              "         0.03763068,  0.01875843], dtype=float32),\n",
              " array([ 0.04193852,  0.00479028,  0.00085227, ..., -0.00961079,\n",
              "         0.00715531,  0.01457697], dtype=float32),\n",
              " array([-0.01347787,  0.00052914,  0.02579737, ..., -0.00269968,\n",
              "        -0.01811196,  0.0143065 ], dtype=float32),\n",
              " array([-0.01891847,  0.00534324,  0.03364845, ...,  0.00435108,\n",
              "        -0.041076  ,  0.01777578], dtype=float32),\n",
              " array([ 0.01487639, -0.00954223,  0.00950845, ...,  0.00574309,\n",
              "        -0.06215406,  0.0203675 ], dtype=float32),\n",
              " array([ 0.0164925 , -0.02041828, -0.00060741, ...,  0.00533195,\n",
              "        -0.03330602, -0.00520333], dtype=float32),\n",
              " array([ 0.04643099, -0.02168923, -0.02657535, ...,  0.00889135,\n",
              "        -0.02529412, -0.00064926], dtype=float32),\n",
              " array([ 0.01440965, -0.01668012,  0.00516642, ...,  0.01030391,\n",
              "        -0.0308936 ,  0.00827383], dtype=float32),\n",
              " array([ 2.9354809e-02, -2.5900772e-05,  2.1376276e-02, ...,\n",
              "         1.0314987e-02, -5.2393742e-02,  1.9227706e-02], dtype=float32),\n",
              " array([ 0.04442343, -0.01205226,  0.01116902, ...,  0.00658658,\n",
              "        -0.0361466 ,  0.00760526], dtype=float32),\n",
              " array([ 0.04481041, -0.02115605,  0.0322788 , ..., -0.00171399,\n",
              "         0.01959375,  0.02422126], dtype=float32),\n",
              " array([ 0.02575623, -0.00301436,  0.03950308, ..., -0.00486238,\n",
              "         0.03013448,  0.04061887], dtype=float32),\n",
              " array([ 0.06298227, -0.01881566,  0.01357004, ...,  0.00082611,\n",
              "         0.00256028,  0.03451843], dtype=float32),\n",
              " array([ 0.02068719, -0.03171933,  0.04215057, ...,  0.00517556,\n",
              "        -0.01528818,  0.02596821], dtype=float32),\n",
              " array([ 0.01090101, -0.0241309 ,  0.04329516, ...,  0.00681595,\n",
              "        -0.02695452,  0.01653462], dtype=float32),\n",
              " array([ 0.00706901, -0.0249004 ,  0.02933191, ...,  0.00946342,\n",
              "        -0.03679387,  0.01135798], dtype=float32),\n",
              " array([ 0.02196801, -0.03393325,  0.01593671, ...,  0.00986662,\n",
              "        -0.05889015,  0.01369108], dtype=float32),\n",
              " array([ 0.05239184, -0.0300324 , -0.00746296, ...,  0.00324514,\n",
              "        -0.06553224,  0.00662747], dtype=float32),\n",
              " array([ 0.0480238 , -0.02566447,  0.02788273, ..., -0.00322   ,\n",
              "        -0.00528183, -0.0086689 ], dtype=float32),\n",
              " array([ 0.04494968,  0.00084616,  0.04834444, ..., -0.00826958,\n",
              "         0.03101495,  0.01657335], dtype=float32),\n",
              " array([-0.00168406,  0.00545954,  0.03346253, ...,  0.00532624,\n",
              "        -0.01356435,  0.02274605], dtype=float32),\n",
              " array([-0.01948746,  0.0027341 ,  0.0220219 , ...,  0.00694521,\n",
              "        -0.02003163,  0.01621193], dtype=float32),\n",
              " array([-0.03040405,  0.00423637,  0.01159309, ...,  0.00724654,\n",
              "        -0.02485099,  0.01346228], dtype=float32),\n",
              " array([-0.06158994, -0.00440534, -0.01377919, ...,  0.008157  ,\n",
              "        -0.02635798,  0.01422023], dtype=float32),\n",
              " array([-0.07088481, -0.01004155, -0.01888506, ...,  0.00797875,\n",
              "        -0.03621158,  0.01649905], dtype=float32),\n",
              " array([-0.06276113, -0.00839829, -0.01994568, ...,  0.0096582 ,\n",
              "        -0.03791711,  0.01375277], dtype=float32),\n",
              " array([-0.06429364, -0.00505567, -0.02871141, ...,  0.00946387,\n",
              "        -0.03603832,  0.01500699], dtype=float32),\n",
              " array([-0.06778286, -0.0012582 , -0.02545108, ...,  0.01050786,\n",
              "        -0.03533512,  0.01517837], dtype=float32),\n",
              " array([-0.06238416,  0.00088089, -0.02112865, ...,  0.00839628,\n",
              "        -0.02551851,  0.01234888], dtype=float32),\n",
              " array([-0.04983411,  0.01446029, -0.02830149, ...,  0.01328235,\n",
              "        -0.0254051 ,  0.02126053], dtype=float32),\n",
              " array([ 0.0602337 ,  0.00826805, -0.12638617, ...,  0.01504693,\n",
              "        -0.03288149,  0.02621542], dtype=float32),\n",
              " array([ 0.05863751, -0.00455722, -0.09518079, ...,  0.01045285,\n",
              "        -0.02756093,  0.02026775], dtype=float32),\n",
              " array([ 0.04079111,  0.0101405 , -0.03445434, ..., -0.00017995,\n",
              "        -0.02450613,  0.01288913], dtype=float32),\n",
              " array([ 0.05855598,  0.00403071, -0.06269941, ...,  0.00691224,\n",
              "        -0.03932565,  0.0185229 ], dtype=float32),\n",
              " array([ 0.05867291, -0.00752211, -0.02405882, ...,  0.00700291,\n",
              "        -0.02034732,  0.01702798], dtype=float32),\n",
              " array([ 0.02352133, -0.0119545 ,  0.03785488, ...,  0.0059631 ,\n",
              "        -0.05776486,  0.02163569], dtype=float32),\n",
              " array([ 0.05065153, -0.02698942, -0.01631069, ...,  0.00712842,\n",
              "        -0.06821474,  0.01624386], dtype=float32),\n",
              " array([ 0.01055715, -0.03322343,  0.00277948, ...,  0.00454132,\n",
              "        -0.07508314,  0.00987515], dtype=float32),\n",
              " array([ 0.0387442 ,  0.00106071, -0.02165449, ...,  0.00536833,\n",
              "        -0.08452585,  0.0092041 ], dtype=float32),\n",
              " array([ 0.01009947, -0.00353176,  0.00731948, ..., -0.00166619,\n",
              "        -0.03280634, -0.01068241], dtype=float32),\n",
              " array([ 0.00115206, -0.01779292,  0.00675088, ..., -0.00606343,\n",
              "         0.02270814,  0.00795783], dtype=float32),\n",
              " array([ 0.04849347, -0.02957025, -0.01808674, ..., -0.00413159,\n",
              "         0.0171072 ,  0.01367905], dtype=float32),\n",
              " array([ 0.0547781 , -0.00393231,  0.05328937, ..., -0.01138237,\n",
              "         0.03005253,  0.02233491], dtype=float32),\n",
              " array([ 0.0188535 ,  0.01321129,  0.04003973, ..., -0.00478758,\n",
              "         0.02306314,  0.02134777], dtype=float32),\n",
              " array([-0.00025854,  0.02978151, -0.0011244 , ..., -0.00228723,\n",
              "         0.01988843,  0.01492378], dtype=float32),\n",
              " array([-0.02557106,  0.0118621 , -0.00764648, ..., -0.00624898,\n",
              "        -0.01459546,  0.0150191 ], dtype=float32),\n",
              " array([-0.03720138, -0.02172695, -0.00946237, ..., -0.00245959,\n",
              "        -0.04375992,  0.0162123 ], dtype=float32),\n",
              " array([-0.03281366, -0.02262705,  0.01131096, ...,  0.00609002,\n",
              "        -0.05743997,  0.01421475], dtype=float32),\n",
              " array([-0.04664709, -0.02066263,  0.0183688 , ...,  0.00721568,\n",
              "        -0.0642837 ,  0.01603592], dtype=float32),\n",
              " array([-0.06178067, -0.06232249, -0.02618444, ...,  0.01389804,\n",
              "        -0.04657048, -0.01665547], dtype=float32),\n",
              " array([-0.0867441 , -0.0494023 , -0.00883974, ...,  0.01566811,\n",
              "        -0.05114614, -0.01669026], dtype=float32),\n",
              " array([-0.04625037, -0.07318374, -0.04787466, ...,  0.01655767,\n",
              "        -0.05021704, -0.01788251], dtype=float32),\n",
              " array([ 0.05063497, -0.06877553, -0.1314411 , ...,  0.01520516,\n",
              "        -0.05564123, -0.01077013], dtype=float32),\n",
              " array([ 0.00200664, -0.01509201, -0.07830656, ...,  0.01646445,\n",
              "         0.01867436, -0.00509486], dtype=float32),\n",
              " array([-0.02068788,  0.01364203, -0.04916102, ...,  0.01235053,\n",
              "         0.04310774,  0.02142702], dtype=float32),\n",
              " array([ 0.00362703,  0.01197308, -0.06113748, ...,  0.0062626 ,\n",
              "         0.03811438,  0.0250719 ], dtype=float32),\n",
              " array([ 0.00493752,  0.01237465, -0.06382618, ...,  0.00171913,\n",
              "         0.02822567,  0.02205258], dtype=float32),\n",
              " array([-0.03113574,  0.01336095, -0.02700995, ...,  0.00468491,\n",
              "         0.0063507 ,  0.01940299], dtype=float32),\n",
              " array([-0.02617878,  0.02655772,  0.00505449, ...,  0.00426622,\n",
              "        -0.02956638,  0.02592943], dtype=float32),\n",
              " array([-0.05861291,  0.01991008,  0.03003637, ...,  0.00287784,\n",
              "        -0.040569  ,  0.01661189], dtype=float32),\n",
              " array([-0.07536424,  0.01328136,  0.01875982, ...,  0.00266105,\n",
              "        -0.05537999,  0.01566323], dtype=float32),\n",
              " array([-0.09828999,  0.00518689, -0.00339635, ...,  0.0067504 ,\n",
              "        -0.06670009,  0.01833302], dtype=float32),\n",
              " array([-0.01406426, -0.01583706, -0.08012792, ...,  0.00709822,\n",
              "        -0.00168825, -0.00152098], dtype=float32),\n",
              " array([-0.00697806, -0.02136316, -0.06792905, ...,  0.00522996,\n",
              "         0.03715045,  0.017898  ], dtype=float32),\n",
              " array([ 0.02066132, -0.01526529, -0.06281187, ...,  0.00950837,\n",
              "         0.02538414,  0.01811265], dtype=float32),\n",
              " array([ 0.00441483, -0.00850503, -0.02810005, ...,  0.01189735,\n",
              "        -0.00377972,  0.02453357], dtype=float32),\n",
              " array([ 0.01495736,  0.00916876,  0.01016362, ...,  0.00845218,\n",
              "        -0.03506151,  0.02716907], dtype=float32),\n",
              " array([ 0.00340931,  0.0151333 ,  0.01589072, ...,  0.01015889,\n",
              "        -0.05025968,  0.02084975], dtype=float32),\n",
              " array([-0.04124158,  0.00178197, -0.00665761, ...,  0.01198776,\n",
              "        -0.0616875 ,  0.01961507], dtype=float32),\n",
              " array([ 0.04337038, -0.00948036, -0.05037489, ...,  0.01287473,\n",
              "        -0.06351425,  0.00836693], dtype=float32),\n",
              " array([ 0.0641495 , -0.00721096, -0.05421583, ...,  0.01379167,\n",
              "        -0.06089621,  0.0008552 ], dtype=float32),\n",
              " array([ 0.0063665 , -0.01556748, -0.01805383, ...,  0.01847039,\n",
              "        -0.00607731, -0.00877252], dtype=float32),\n",
              " array([-0.00445364, -0.02177811, -0.00253577, ...,  0.02209422,\n",
              "         0.02188675,  0.00840498], dtype=float32),\n",
              " array([-0.00689048, -0.02449188,  0.00594959, ...,  0.02016218,\n",
              "         0.02767911,  0.01913414], dtype=float32),\n",
              " array([-0.00767735, -0.02409604,  0.01071538, ...,  0.01532376,\n",
              "         0.02654533,  0.02429918], dtype=float32),\n",
              " array([-0.00677127, -0.0224973 ,  0.01247981, ...,  0.00974841,\n",
              "         0.02467768,  0.02489311], dtype=float32),\n",
              " array([-0.0054683 , -0.02015412,  0.01288812, ...,  0.00613421,\n",
              "         0.02126879,  0.02259369], dtype=float32),\n",
              " array([-0.00356536, -0.01822901,  0.01284869, ...,  0.00413558,\n",
              "         0.0196194 ,  0.01879361], dtype=float32),\n",
              " array([-0.00123995, -0.01610617,  0.01253121, ...,  0.00336673,\n",
              "         0.01938312,  0.01476842], dtype=float32),\n",
              " array([ 0.00066151, -0.0138201 ,  0.01257795, ...,  0.00273541,\n",
              "         0.0221941 ,  0.01140809], dtype=float32),\n",
              " array([ 0.00120897, -0.01173789,  0.0131388 , ...,  0.00321971,\n",
              "         0.02150242,  0.00867924], dtype=float32),\n",
              " array([ 0.0022659 , -0.01011984,  0.0131795 , ...,  0.0035324 ,\n",
              "         0.0212638 ,  0.00596234], dtype=float32),\n",
              " array([ 0.00228601, -0.00866855,  0.0134565 , ...,  0.00340223,\n",
              "         0.02171987,  0.0035514 ], dtype=float32),\n",
              " array([ 0.00224398, -0.00766835,  0.01365435, ...,  0.00358168,\n",
              "         0.02205646,  0.00189964], dtype=float32),\n",
              " array([ 0.00122906, -0.00664758,  0.01412088, ...,  0.00464614,\n",
              "         0.01930873,  0.00067615], dtype=float32),\n",
              " array([ 0.00518663, -0.00661804,  0.01247366, ...,  0.00533193,\n",
              "         0.0134138 , -0.00106834], dtype=float32),\n",
              " array([ 0.00412693, -0.00580749,  0.01363788, ...,  0.00574786,\n",
              "         0.00855507, -0.00310511], dtype=float32),\n",
              " array([ 0.00138673, -0.00483789,  0.0152801 , ...,  0.00624746,\n",
              "         0.00625141, -0.00462617], dtype=float32),\n",
              " array([ 0.00039145, -0.00447118,  0.01544322, ...,  0.00651758,\n",
              "         0.00562835, -0.00522986], dtype=float32),\n",
              " array([-0.00096223, -0.00407814,  0.01552221, ...,  0.00673544,\n",
              "         0.00304451, -0.0048402 ], dtype=float32),\n",
              " array([-0.00152598, -0.00391811,  0.01480287, ...,  0.00675166,\n",
              "        -0.00080153, -0.00423552], dtype=float32),\n",
              " array([-0.00228996, -0.00374561,  0.01453816, ...,  0.00685974,\n",
              "        -0.00396389, -0.00361474], dtype=float32),\n",
              " array([-0.00269159, -0.00363448,  0.01410949, ...,  0.00651563,\n",
              "        -0.00578884, -0.0031416 ], dtype=float32),\n",
              " array([-0.00327136, -0.00359038,  0.01386627, ...,  0.00615827,\n",
              "        -0.00790452, -0.00227011], dtype=float32),\n",
              " array([-0.00317989, -0.00370755,  0.01345137, ...,  0.00590351,\n",
              "        -0.01039217, -0.00131593], dtype=float32),\n",
              " array([-0.03470486,  0.06610446,  0.01854754, ...,  0.01763124,\n",
              "         0.0171406 , -0.04339504], dtype=float32),\n",
              " array([-0.03539442,  0.01446272,  0.00771941, ...,  0.01484062,\n",
              "         0.01010672, -0.0477828 ], dtype=float32),\n",
              " array([-0.04161166, -0.00162247,  0.0051819 , ..., -0.00982259,\n",
              "         0.05003611,  0.00708697], dtype=float32),\n",
              " array([-0.03296573, -0.01170297, -0.00387736, ..., -0.02934568,\n",
              "         0.04305375,  0.01629496], dtype=float32),\n",
              " array([-0.02597176, -0.01335489, -0.0058759 , ..., -0.02564675,\n",
              "         0.03830598,  0.01388143], dtype=float32),\n",
              " array([-0.0219924 , -0.01216856, -0.00364601, ..., -0.01844949,\n",
              "         0.03596463,  0.00790207], dtype=float32),\n",
              " array([-0.01863957, -0.01077348, -0.00041251, ..., -0.01356038,\n",
              "         0.03466367,  0.00350684], dtype=float32),\n",
              " array([-0.0165396 , -0.00953125,  0.00290775, ..., -0.01117225,\n",
              "         0.03391757,  0.00040075], dtype=float32),\n",
              " array([-0.0145429 , -0.00866886,  0.00549759, ..., -0.01111919,\n",
              "         0.0330975 , -0.00023017], dtype=float32),\n",
              " array([-1.29905855e-02, -7.96949212e-03,  7.51688192e-03, ...,\n",
              "        -1.22113228e-02,  3.22971269e-02, -6.37296689e-05], dtype=float32),\n",
              " array([-0.01205555, -0.00738326,  0.00937838, ..., -0.01366957,\n",
              "         0.03162144,  0.00085026], dtype=float32),\n",
              " array([-0.01107776, -0.00707937,  0.01071965, ..., -0.01556052,\n",
              "         0.03067279,  0.00304329], dtype=float32),\n",
              " array([-0.00965957, -0.00680485,  0.01128193, ..., -0.0168762 ,\n",
              "         0.02993988,  0.00434439], dtype=float32),\n",
              " array([-0.0057673 , -0.00669791,  0.01053492, ..., -0.02414152,\n",
              "         0.02258646,  0.01861825], dtype=float32),\n",
              " array([ 0.00319334, -0.00655991,  0.00866061, ..., -0.02696964,\n",
              "         0.01907202,  0.01782575], dtype=float32),\n",
              " array([-0.00181106, -0.0043816 ,  0.01347369, ..., -0.02696867,\n",
              "         0.01837478,  0.01797929], dtype=float32),\n",
              " array([-0.00419855, -0.0037968 ,  0.01578291, ..., -0.02615226,\n",
              "         0.0183385 ,  0.01867936], dtype=float32),\n",
              " array([-0.00468758, -0.00385872,  0.01597812, ..., -0.02554095,\n",
              "         0.01825747,  0.02049888], dtype=float32),\n",
              " array([-0.00578043, -0.00380735,  0.01563472, ..., -0.02488433,\n",
              "         0.01822493,  0.02207861], dtype=float32),\n",
              " array([-0.00601752, -0.00408806,  0.01484745, ..., -0.02451454,\n",
              "         0.01807989,  0.02421814], dtype=float32),\n",
              " array([-0.00545583, -0.00439717,  0.0138579 , ..., -0.02385726,\n",
              "         0.0182552 ,  0.02555814], dtype=float32),\n",
              " array([-0.0050594 , -0.00442394,  0.01299909, ..., -0.02359223,\n",
              "         0.0180678 ,  0.02784291], dtype=float32),\n",
              " array([-0.00456767, -0.00417523,  0.01219949, ..., -0.02323223,\n",
              "         0.01789968,  0.02955428], dtype=float32),\n",
              " array([-0.00497324, -0.00391022,  0.0121547 , ..., -0.02291231,\n",
              "         0.01783725,  0.03121205], dtype=float32),\n",
              " array([-0.00352421, -0.0041889 ,  0.01130756, ..., -0.0226783 ,\n",
              "         0.01779072,  0.0328341 ], dtype=float32),\n",
              " array([ 0.01174557, -0.00620629,  0.00526822, ..., -0.01034755,\n",
              "         0.03019503, -0.01590593], dtype=float32),\n",
              " array([ 0.002489  , -0.00354411,  0.01172427, ..., -0.00568056,\n",
              "         0.03755644, -0.00507335], dtype=float32),\n",
              " array([-0.00078774, -0.0027393 ,  0.01428031, ..., -0.00666277,\n",
              "         0.03774241,  0.00208702], dtype=float32),\n",
              " array([-0.00308649, -0.00263978,  0.0145982 , ..., -0.0088162 ,\n",
              "         0.03681773,  0.00722555], dtype=float32),\n",
              " array([-0.0040798 , -0.00315215,  0.01360217, ..., -0.01078518,\n",
              "         0.03538176,  0.01105774], dtype=float32),\n",
              " array([-0.00442615, -0.00337964,  0.01241635, ..., -0.01193781,\n",
              "         0.03482865,  0.01047877], dtype=float32),\n",
              " array([-0.0050577 , -0.00333952,  0.01169489, ..., -0.01263634,\n",
              "         0.03430084,  0.01137041], dtype=float32),\n",
              " array([-0.00487551, -0.00347413,  0.01095261, ..., -0.01333902,\n",
              "         0.03394193,  0.01156841], dtype=float32),\n",
              " array([-0.00370722, -0.00362163,  0.01009386, ..., -0.01344992,\n",
              "         0.03403121,  0.00997313], dtype=float32),\n",
              " array([-0.00402286, -0.00357755,  0.01036537, ..., -0.0131518 ,\n",
              "         0.03432486,  0.0081878 ], dtype=float32),\n",
              " array([-0.00335472, -0.00369821,  0.01010684, ..., -0.01277987,\n",
              "         0.03484926,  0.00616489], dtype=float32),\n",
              " array([-0.00363327, -0.0036806 ,  0.01024875, ..., -0.01293971,\n",
              "         0.03533909,  0.00607807], dtype=float32),\n",
              " array([ 0.00678074, -0.01024688,  0.00485534, ...,  0.00731089,\n",
              "         0.0119662 , -0.00030206], dtype=float32),\n",
              " array([-0.00044958, -0.00342145,  0.0248833 , ...,  0.01233217,\n",
              "        -0.0093146 ,  0.03150843], dtype=float32),\n",
              " array([-0.01142645, -0.00864473,  0.01632187, ...,  0.01144492,\n",
              "        -0.01913658,  0.02381087], dtype=float32),\n",
              " array([-0.00234926, -0.01201538,  0.00432032, ...,  0.01153228,\n",
              "        -0.01950402,  0.00692298], dtype=float32),\n",
              " array([ 0.00111422, -0.01097597,  0.00119696, ...,  0.01243195,\n",
              "        -0.01590482,  0.00914394], dtype=float32),\n",
              " array([ 0.00680726, -0.00954291,  0.00072024, ...,  0.01312058,\n",
              "        -0.01294786,  0.01935584], dtype=float32),\n",
              " array([ 0.002826  , -0.00703889,  0.0055546 , ...,  0.01349559,\n",
              "        -0.01429015,  0.03440417], dtype=float32),\n",
              " array([ 0.00321629, -0.00624658,  0.00698619, ...,  0.01328518,\n",
              "        -0.01441835,  0.03562854], dtype=float32),\n",
              " array([ 3.5913101e-06, -5.0456799e-03,  9.2966203e-03, ...,\n",
              "         1.2931047e-02, -3.4853563e-02,  8.8175721e-02], dtype=float32),\n",
              " array([-0.00262523, -0.00465388,  0.01030671, ...,  0.0116024 ,\n",
              "        -0.04547622,  0.07548068], dtype=float32),\n",
              " array([-0.01174762, -0.002715  ,  0.01364891, ...,  0.01155458,\n",
              "        -0.05287554,  0.07521763], dtype=float32),\n",
              " array([ 0.02100659, -0.01215918, -0.01026835, ...,  0.00754151,\n",
              "        -0.0036355 ,  0.01704689], dtype=float32),\n",
              " array([ 0.02543295, -0.00972656, -0.01620298, ...,  0.01303216,\n",
              "         0.03002858, -0.00746717], dtype=float32),\n",
              " array([ 0.05033125,  0.00214384, -0.02304446, ...,  0.01664131,\n",
              "         0.04591587, -0.04131826], dtype=float32),\n",
              " array([ 0.03113947, -0.00142963, -0.00153546, ...,  0.01911949,\n",
              "         0.04901329, -0.05214499], dtype=float32),\n",
              " array([-0.00579764, -0.0014706 ,  0.01975006, ...,  0.02172909,\n",
              "         0.00750716, -0.01683259], dtype=float32),\n",
              " array([-0.01506267,  0.00656221,  0.04116513, ...,  0.01627604,\n",
              "        -0.02147246, -0.01784248], dtype=float32),\n",
              " array([-0.01909696,  0.0059673 ,  0.02900012, ...,  0.01321102,\n",
              "        -0.04825788, -0.01229207], dtype=float32),\n",
              " array([-0.02873593, -0.00271554,  0.01170674, ...,  0.00571214,\n",
              "        -0.06586958, -0.01995811], dtype=float32),\n",
              " array([-0.00842918, -0.00500034, -0.00466893, ...,  0.0050276 ,\n",
              "        -0.08361733, -0.01009306], dtype=float32),\n",
              " array([ 0.03152172, -0.01187784, -0.02018664, ...,  0.00334679,\n",
              "        -0.10492665,  0.01451211], dtype=float32),\n",
              " array([ 0.02518569, -0.02420088, -0.00851621, ..., -0.01435586,\n",
              "        -0.09934484, -0.03109653], dtype=float32),\n",
              " array([ 0.02627172, -0.01301123,  0.0252621 , ..., -0.029499  ,\n",
              "        -0.05486381, -0.05040441], dtype=float32),\n",
              " array([ 0.0218298 , -0.00647267,  0.02028813, ..., -0.03021371,\n",
              "        -0.01486334, -0.04283927], dtype=float32),\n",
              " array([ 0.05853847, -0.00891834, -0.01306153, ..., -0.02459705,\n",
              "         0.00183337, -0.03861382], dtype=float32),\n",
              " array([ 0.03644976, -0.00465877,  0.02889944, ..., -0.01193947,\n",
              "        -0.03778903, -0.01237678], dtype=float32),\n",
              " array([ 0.01874864, -0.00327605,  0.06647533, ..., -0.01022662,\n",
              "        -0.07439935,  0.00352689], dtype=float32),\n",
              " array([-0.00413252, -0.00168124,  0.05214246, ..., -0.0159534 ,\n",
              "        -0.09781615,  0.00995137], dtype=float32),\n",
              " array([-0.03615721, -0.01212815,  0.03064866, ..., -0.01721157,\n",
              "        -0.1120063 ,  0.01202671], dtype=float32),\n",
              " array([-0.00100429, -0.02342612, -0.00173625, ..., -0.01078691,\n",
              "        -0.12188689,  0.01908915], dtype=float32),\n",
              " array([ 0.01545542, -0.00709785, -0.00073329, ..., -0.00923889,\n",
              "        -0.12460092,  0.02943564], dtype=float32),\n",
              " array([-0.00083214, -0.00706778,  0.01664929, ..., -0.02443311,\n",
              "        -0.09272027,  0.00949421], dtype=float32),\n",
              " array([-0.00494926,  0.00253653,  0.03756764, ..., -0.02771663,\n",
              "        -0.05208942,  0.01905571], dtype=float32),\n",
              " array([-0.00982573,  0.00018202,  0.01550653, ..., -0.02670454,\n",
              "        -0.0234703 ,  0.04100911], dtype=float32),\n",
              " array([ 0.0278357 ,  0.00153917, -0.01934575, ..., -0.02696661,\n",
              "        -0.00960413,  0.05757377], dtype=float32),\n",
              " array([ 0.01573795, -0.01122774,  0.00760636, ..., -0.01540616,\n",
              "        -0.02598198,  0.06978975], dtype=float32),\n",
              " array([-0.02818233, -0.01902311,  0.03606929, ..., -0.00892015,\n",
              "        -0.05684426,  0.07257254], dtype=float32),\n",
              " array([-0.04056064, -0.00451148,  0.03960373, ..., -0.00580311,\n",
              "        -0.0719634 ,  0.06704406], dtype=float32),\n",
              " array([-0.05618778, -0.00249629,  0.02879499, ..., -0.00221354,\n",
              "        -0.07451091,  0.05704078], dtype=float32),\n",
              " array([-0.01597956, -0.00286606, -0.00315473, ...,  0.00166831,\n",
              "        -0.07544663,  0.0497942 ], dtype=float32),\n",
              " array([-0.02865904, -0.00354275,  0.0115371 , ...,  0.00340149,\n",
              "        -0.08142821,  0.04590548], dtype=float32),\n",
              " array([-0.00537104, -0.01153987, -0.00279464, ...,  0.00155364,\n",
              "        -0.08260538,  0.03521844], dtype=float32),\n",
              " array([-0.00658242, -0.01063115,  0.01610766, ..., -0.00014881,\n",
              "        -0.06441908,  0.01427248], dtype=float32),\n",
              " array([ 0.01258882,  0.0049271 ,  0.04185929, ..., -0.00162345,\n",
              "        -0.0336291 ,  0.00460209], dtype=float32),\n",
              " array([-0.01696026,  0.01264487,  0.02570031, ..., -0.00135458,\n",
              "         0.0010076 ,  0.01625661], dtype=float32),\n",
              " array([-0.0461566 ,  0.00718699,  0.00080424, ...,  0.01073219,\n",
              "        -0.04852653,  0.03453835], dtype=float32),\n",
              " array([-0.04506167, -0.00178918, -0.00676062, ...,  0.00543284,\n",
              "        -0.05605397,  0.02749662], dtype=float32),\n",
              " array([-0.05079536, -0.00204894, -0.02846557, ...,  0.00632368,\n",
              "        -0.06948922,  0.02767498], dtype=float32),\n",
              " array([-0.04021709, -0.01181064, -0.04259447, ...,  0.00509528,\n",
              "        -0.07566923,  0.02306532], dtype=float32),\n",
              " array([-0.02495644, -0.01412116, -0.0375418 , ...,  0.00572719,\n",
              "        -0.07658985,  0.01554989], dtype=float32),\n",
              " array([ 0.03250824, -0.01277744, -0.05347114, ...,  0.00727859,\n",
              "        -0.07883187,  0.01162716], dtype=float32),\n",
              " array([ 0.02940367, -0.00764569, -0.02104398, ...,  0.00672433,\n",
              "        -0.08695699,  0.01134007], dtype=float32),\n",
              " array([ 0.01776483, -0.01762309, -0.0082258 , ...,  0.00742936,\n",
              "        -0.07374632, -0.00241706], dtype=float32),\n",
              " array([ 0.01581548, -0.0070987 ,  0.02912988, ...,  0.00728012,\n",
              "        -0.02091902, -0.0150781 ], dtype=float32),\n",
              " array([0.01421993, 0.00770993, 0.02338857, ..., 0.01204705, 0.00299334,\n",
              "        0.00093527], dtype=float32),\n",
              " array([ 0.05534874,  0.00265939, -0.02716285, ...,  0.01501675,\n",
              "        -0.00119271,  0.01343155], dtype=float32),\n",
              " array([ 0.03246184, -0.00713262,  0.04764446, ...,  0.01139337,\n",
              "        -0.04849212,  0.02257547], dtype=float32),\n",
              " array([-0.00855725, -0.00537374,  0.0982516 , ...,  0.00451086,\n",
              "        -0.05070543,  0.0113123 ], dtype=float32),\n",
              " array([-0.05789492, -0.01424284,  0.07196766, ...,  0.00748163,\n",
              "        -0.06437038,  0.01061143], dtype=float32),\n",
              " array([-0.09038007, -0.02442976,  0.04861974, ...,  0.00595547,\n",
              "        -0.07707419,  0.00986431], dtype=float32),\n",
              " array([-0.10773835, -0.01743407,  0.03479382, ...,  0.00694475,\n",
              "        -0.07558393,  0.00173625], dtype=float32),\n",
              " array([-0.11431579, -0.03424206, -0.00361588, ...,  0.01299556,\n",
              "        -0.03658738, -0.0165483 ], dtype=float32),\n",
              " array([-0.1066581 , -0.02749022, -0.03063885, ...,  0.02009523,\n",
              "        -0.01478309, -0.00765423], dtype=float32),\n",
              " array([ 0.04429996,  0.06240359, -0.08284859, ..., -0.04462046,\n",
              "        -0.02793408, -0.03783324], dtype=float32),\n",
              " array([-0.00508167,  0.02226654, -0.02228254, ..., -0.01001372,\n",
              "        -0.02860596, -0.05688958], dtype=float32),\n",
              " array([-0.01186483,  0.00889247,  0.01428425, ..., -0.00202772,\n",
              "        -0.01804027, -0.09110872], dtype=float32),\n",
              " array([-0.01066119, -0.00388651,  0.01853682, ...,  0.00904274,\n",
              "        -0.03301414, -0.07572132], dtype=float32),\n",
              " array([-0.00957   ,  0.00300787,  0.01952189, ...,  0.01045437,\n",
              "        -0.04332959, -0.06050486], dtype=float32),\n",
              " array([ 0.02999606,  0.00373991, -0.00913759, ...,  0.00799995,\n",
              "        -0.05707059, -0.03642015], dtype=float32),\n",
              " array([ 0.03325139,  0.00708579, -0.01326476, ...,  0.00947469,\n",
              "        -0.05063065, -0.04168326], dtype=float32),\n",
              " array([-0.00558633,  0.00470456, -0.00074283, ...,  0.01001288,\n",
              "        -0.05783811, -0.02983009], dtype=float32),\n",
              " array([ 0.0054561 ,  0.00395165, -0.00951973, ...,  0.01139344,\n",
              "        -0.05319638, -0.02659895], dtype=float32),\n",
              " array([ 0.01984866,  0.00689569, -0.01275895, ...,  0.00902782,\n",
              "        -0.06535091, -0.01147428], dtype=float32),\n",
              " array([ 0.01133304,  0.00899236, -0.0119085 , ...,  0.00767936,\n",
              "        -0.064176  , -0.00635793], dtype=float32),\n",
              " array([ 0.01794399,  0.0088339 , -0.012466  , ...,  0.00623096,\n",
              "        -0.06869689,  0.0002286 ], dtype=float32),\n",
              " array([ 0.0035946 ,  0.00419033, -0.0061569 , ...,  0.00446261,\n",
              "        -0.0669475 ,  0.00517468], dtype=float32),\n",
              " array([-5.3342707e-03, -7.4717300e-03, -3.6061931e-05, ...,\n",
              "         5.4538916e-03, -5.7360899e-02, -4.1890563e-03], dtype=float32),\n",
              " array([-0.00531603, -0.01867021,  0.00261504, ...,  0.00984353,\n",
              "        -0.04117767, -0.01926954], dtype=float32),\n",
              " array([ 0.0072745 , -0.01812702,  0.00075316, ...,  0.00879554,\n",
              "        -0.06115737, -0.00240581], dtype=float32),\n",
              " array([ 0.05113139, -0.0024611 , -0.01641941, ...,  0.00909916,\n",
              "        -0.05139833, -0.0098903 ], dtype=float32),\n",
              " array([ 0.02072303, -0.01121872, -0.00471135, ...,  0.01007406,\n",
              "        -0.05176439, -0.00733184], dtype=float32),\n",
              " array([ 0.04474024, -0.00479089, -0.0185472 , ...,  0.01017003,\n",
              "        -0.05757909, -0.0007897 ], dtype=float32),\n",
              " array([ 0.04455685, -0.00093638, -0.02448966, ...,  0.00811841,\n",
              "        -0.06406108,  0.00480536], dtype=float32),\n",
              " array([ 0.04293988,  0.00143113, -0.02389415, ...,  0.00776692,\n",
              "        -0.06167037,  0.00340301], dtype=float32),\n",
              " array([ 0.01691846, -0.01517421, -0.00542138, ...,  0.00576299,\n",
              "        -0.06350766,  0.00135369], dtype=float32),\n",
              " array([ 0.01574158, -0.02282297,  0.00516525, ...,  0.00494014,\n",
              "        -0.06283412, -0.0037498 ], dtype=float32),\n",
              " array([ 0.0148992 , -0.03807107,  0.00332703, ...,  0.00727571,\n",
              "        -0.06718568, -0.00289825], dtype=float32),\n",
              " array([ 0.01813343, -0.04992739,  0.0028198 , ...,  0.00587607,\n",
              "        -0.07564025,  0.00356377], dtype=float32),\n",
              " array([ 0.03756851, -0.06362206, -0.01812371, ...,  0.00745298,\n",
              "        -0.05984069, -0.00482122], dtype=float32),\n",
              " array([ 0.03267572, -0.05542219, -0.01612591, ...,  0.00785567,\n",
              "        -0.06135843, -0.0024332 ], dtype=float32),\n",
              " array([ 0.04223405, -0.04040875, -0.02030606, ...,  0.00826294,\n",
              "        -0.06203862, -0.00043475], dtype=float32),\n",
              " array([ 0.05003704, -0.01504669, -0.03185023, ...,  0.00801786,\n",
              "        -0.05792311, -0.00137859], dtype=float32),\n",
              " array([ 0.04159503, -0.00073595, -0.02965963, ...,  0.00842859,\n",
              "        -0.05200537, -0.00314322], dtype=float32),\n",
              " array([ 0.02561059, -0.00519961,  0.0027085 , ...,  0.00729742,\n",
              "        -0.00568383, -0.00912915], dtype=float32),\n",
              " array([ 0.03078006, -0.00095745,  0.00458852, ...,  0.00938285,\n",
              "        -0.04559118,  0.00185726], dtype=float32),\n",
              " array([ 0.04822621,  0.00613069, -0.0196036 , ...,  0.00730053,\n",
              "        -0.02806663, -0.00773638], dtype=float32),\n",
              " array([ 0.02303852, -0.01975666,  0.00339937, ...,  0.00644706,\n",
              "        -0.05173549, -0.0005003 ], dtype=float32),\n",
              " array([ 0.03363665, -0.0104629 ,  0.03401596, ...,  0.00538089,\n",
              "        -0.04862791, -0.00536224], dtype=float32),\n",
              " array([ 0.02164726, -0.00827449,  0.02399494, ...,  0.00576408,\n",
              "        -0.02881149, -0.01436836], dtype=float32),\n",
              " array([ 0.01079038, -0.02388009,  0.00150485, ...,  0.00309412,\n",
              "         0.01957699, -0.00416122], dtype=float32),\n",
              " array([ 0.05351913, -0.0185092 , -0.04007837, ...,  0.01053121,\n",
              "         0.00369485,  0.00600491], dtype=float32),\n",
              " array([ 0.02784534, -0.00571586, -0.01551616, ...,  0.00604608,\n",
              "         0.00754794,  0.00538139], dtype=float32),\n",
              " array([ 0.02083604, -0.00964787, -0.01809142, ..., -0.00245114,\n",
              "         0.01207146,  0.00486719], dtype=float32),\n",
              " array([ 3.0188806e-02,  3.4119729e-03, -2.5291363e-02, ...,\n",
              "        -4.2255248e-05, -2.5592470e-03,  2.4044618e-03], dtype=float32),\n",
              " array([ 0.01212646, -0.00343851,  0.00741832, ..., -0.00183349,\n",
              "        -0.00847565, -0.00394022], dtype=float32),\n",
              " array([ 0.01025857,  0.00631218,  0.01947611, ...,  0.00010006,\n",
              "         0.00432724, -0.00779485], dtype=float32),\n",
              " array([ 0.01419474,  0.01581931,  0.01692568, ..., -0.0076895 ,\n",
              "         0.03163421, -0.00255159], dtype=float32),\n",
              " array([ 0.00191282,  0.03243394, -0.00567691, ...,  0.00837512,\n",
              "        -0.03210055,  0.01099768], dtype=float32),\n",
              " array([ 0.00175343, -0.00144856, -0.03288691, ...,  0.00896379,\n",
              "        -0.05377013,  0.00327299], dtype=float32),\n",
              " array([ 0.04500415, -0.00819477, -0.05389898, ...,  0.01001897,\n",
              "        -0.05711605, -0.01316097], dtype=float32),\n",
              " array([ 0.01206586, -0.02906769, -0.03815421, ...,  0.01285487,\n",
              "         0.00358662, -0.01968275], dtype=float32),\n",
              " array([ 0.00556552, -0.03191609, -0.02345908, ...,  0.01506853,\n",
              "         0.03128489, -0.0001408 ], dtype=float32),\n",
              " array([ 0.01030803, -0.03065377, -0.01261158, ...,  0.01282094,\n",
              "         0.03721276,  0.01146151], dtype=float32),\n",
              " array([ 0.01495595, -0.02864822, -0.0058551 , ...,  0.00744765,\n",
              "         0.03763092,  0.01445116], dtype=float32),\n",
              " array([ 0.01761033, -0.02649868, -0.00194454, ...,  0.00401652,\n",
              "         0.03689817,  0.01444134], dtype=float32),\n",
              " array([ 1.9648267e-02, -2.4938250e-02, -4.1930438e-05, ...,\n",
              "         2.8962127e-04,  3.7877783e-02,  1.1395382e-02], dtype=float32),\n",
              " array([ 0.02042831, -0.02255946,  0.0019072 , ..., -0.00385947,\n",
              "         0.04084593,  0.01165718], dtype=float32),\n",
              " array([ 0.01785663, -0.01808082,  0.00541635, ..., -0.00412084,\n",
              "         0.04076852,  0.00622856], dtype=float32),\n",
              " array([ 0.01830743, -0.01721905,  0.00565699, ..., -0.00579326,\n",
              "         0.04345675,  0.0050608 ], dtype=float32),\n",
              " array([ 0.01863631, -0.01626204,  0.00568493, ..., -0.00162774,\n",
              "         0.04172387, -0.00270014], dtype=float32),\n",
              " array([ 0.01783887, -0.0178254 ,  0.00839304, ..., -0.0021262 ,\n",
              "         0.04420855,  0.00174583], dtype=float32),\n",
              " array([ 0.0175663 , -0.01776643,  0.00985689, ..., -0.00146735,\n",
              "         0.04343636, -0.00209878], dtype=float32),\n",
              " array([ 0.01519453, -0.01508745,  0.01251998, ...,  0.00057085,\n",
              "         0.04386115, -0.00482176], dtype=float32),\n",
              " array([ 0.01537915, -0.01366155,  0.01184444, ...,  0.00016801,\n",
              "         0.04329447, -0.00157386], dtype=float32),\n",
              " array([ 0.01428443, -0.0119706 ,  0.01150758, ...,  0.00251073,\n",
              "         0.04235195, -0.00664209], dtype=float32),\n",
              " array([ 0.01386275, -0.01095304,  0.01202231, ...,  0.00593448,\n",
              "         0.04262015, -0.00904428], dtype=float32),\n",
              " array([ 0.02641893, -0.00990186,  0.0068497 , ...,  0.01049179,\n",
              "         0.04304115, -0.01870689], dtype=float32),\n",
              " array([ 0.01947472, -0.00679408,  0.01192164, ...,  0.014097  ,\n",
              "         0.04423941, -0.02296614], dtype=float32),\n",
              " array([ 0.01181546, -0.00443402,  0.01799279, ...,  0.01503407,\n",
              "         0.04510862, -0.02270905], dtype=float32),\n",
              " array([ 0.00772568, -0.00359264,  0.02061194, ...,  0.01458777,\n",
              "         0.04541673, -0.02232806], dtype=float32),\n",
              " array([ 0.00350375, -0.00305286,  0.02151125, ...,  0.01341336,\n",
              "         0.04561743, -0.0203742 ], dtype=float32),\n",
              " array([ 0.00093051, -0.00316594,  0.02075819, ...,  0.01250637,\n",
              "         0.04561391, -0.02112318], dtype=float32),\n",
              " array([ 0.00291201, -0.00372588,  0.01775395, ...,  0.01200976,\n",
              "         0.04560138, -0.02007452], dtype=float32),\n",
              " array([-0.00101191, -0.00278309,  0.01915632, ...,  0.01121493,\n",
              "         0.04551141, -0.01894362], dtype=float32),\n",
              " array([-0.00225395, -0.00265134,  0.01885745, ...,  0.01092383,\n",
              "         0.04549289, -0.01975036], dtype=float32),\n",
              " array([-0.00271589, -0.00262521,  0.01800881, ...,  0.01070024,\n",
              "         0.04552612, -0.01914879], dtype=float32),\n",
              " array([-0.00275771, -0.0027756 ,  0.01705901, ...,  0.01053374,\n",
              "         0.04552933, -0.01964284], dtype=float32),\n",
              " array([-0.00273105, -0.00277358,  0.01651234, ...,  0.01068583,\n",
              "         0.04563304, -0.02063772], dtype=float32),\n",
              " array([-0.00299771, -0.00278295,  0.01639316, ...,  0.01041861,\n",
              "         0.04576673, -0.01961506], dtype=float32),\n",
              " array([-0.00225426, -0.00286109,  0.01586106, ...,  0.01023247,\n",
              "         0.04570887, -0.02007031], dtype=float32),\n",
              " array([-0.00268639, -0.00274672,  0.01594194, ...,  0.01301062,\n",
              "         0.04528109, -0.02798246], dtype=float32),\n",
              " array([ 0.02065328, -0.00362895,  0.00728993, ...,  0.0043043 ,\n",
              "         0.04216393,  0.0011733 ], dtype=float32),\n",
              " array([ 0.00394955, -0.00054824,  0.01723917, ..., -0.00427347,\n",
              "         0.03683022,  0.00434309], dtype=float32),\n",
              " array([-0.00121964, -0.00029682,  0.02070042, ..., -0.00599837,\n",
              "         0.03543222,  0.00333329], dtype=float32),\n",
              " array([-0.00358879, -0.0008015 ,  0.02075789, ..., -0.00558025,\n",
              "         0.03517861,  0.00186933], dtype=float32),\n",
              " array([-0.00581331, -0.00133112,  0.01993775, ..., -0.00520933,\n",
              "         0.0343594 ,  0.00285251], dtype=float32),\n",
              " array([-0.00631585, -0.00190561,  0.01837432, ..., -0.005789  ,\n",
              "         0.03310981,  0.00427804], dtype=float32),\n",
              " array([-0.00793178, -0.00206925,  0.01764677, ..., -0.01571615,\n",
              "         0.0249473 ,  0.01753373], dtype=float32),\n",
              " array([-0.01178631, -0.0017814 ,  0.018044  , ..., -0.02346529,\n",
              "         0.01949964,  0.01664796], dtype=float32),\n",
              " array([-0.01555345,  0.00491403,  0.02383835, ..., -0.02639472,\n",
              "         0.01799038,  0.01469483], dtype=float32),\n",
              " array([-0.03285952,  0.00142475,  0.01010818, ..., -0.02707978,\n",
              "         0.01813861,  0.01337587], dtype=float32),\n",
              " array([-0.01995098, -0.00592817, -0.00871812, ..., -0.027188  ,\n",
              "         0.01835353,  0.01389073], dtype=float32),\n",
              " array([-0.0080021 , -0.00749015, -0.01377114, ..., -0.02704032,\n",
              "         0.0185234 ,  0.01503622], dtype=float32),\n",
              " array([ 0.01874423, -0.00764672, -0.0206478 , ..., -0.00874805,\n",
              "         0.0345186 , -0.07087655], dtype=float32),\n",
              " array([ 0.01391344, -0.00396775, -0.00910388, ...,  0.00283626,\n",
              "         0.04669931, -0.06581227], dtype=float32),\n",
              " array([ 0.00695726, -0.00179883,  0.00238562, ...,  0.00402231,\n",
              "         0.04779095, -0.05233847], dtype=float32),\n",
              " array([ 0.00323288, -0.00171466,  0.00820017, ...,  0.00126895,\n",
              "         0.04669857, -0.03713073], dtype=float32),\n",
              " array([ 0.00028684, -0.00243049,  0.01059042, ..., -0.00208254,\n",
              "         0.04531224, -0.02696899], dtype=float32),\n",
              " array([-0.00225372, -0.00298348,  0.01169557, ..., -0.0040396 ,\n",
              "         0.04450866, -0.02479989], dtype=float32),\n",
              " array([-0.00366354, -0.00349626,  0.01169142, ..., -0.00511484,\n",
              "         0.04451651, -0.0242246 ], dtype=float32),\n",
              " array([-0.00357239, -0.00406401,  0.01119004, ..., -0.00403706,\n",
              "         0.04474572, -0.03101465], dtype=float32),\n",
              " array([-0.00371931, -0.00408636,  0.01084256, ..., -0.00331797,\n",
              "         0.04575282, -0.03291942], dtype=float32),\n",
              " array([-0.00339245, -0.00400681,  0.01077609, ..., -0.00391336,\n",
              "         0.0467283 , -0.0313563 ], dtype=float32),\n",
              " array([-0.03451781, -0.0068045 ,  0.02069832, ...,  0.03701056,\n",
              "         0.07076434, -0.02542232], dtype=float32),\n",
              " array([-0.02498408,  0.00262525,  0.0170002 , ...,  0.02185734,\n",
              "         0.0753707 , -0.02617999], dtype=float32),\n",
              " array([-0.01843483,  0.0038066 ,  0.0147044 , ...,  0.00852725,\n",
              "         0.07503428, -0.02142241], dtype=float32),\n",
              " array([-0.01532483,  0.00373141,  0.0135832 , ..., -0.00134508,\n",
              "         0.071591  , -0.01826099], dtype=float32),\n",
              " array([-0.01695002,  0.0046257 ,  0.01389194, ..., -0.03404567,\n",
              "         0.035356  ,  0.0158923 ], dtype=float32),\n",
              " array([-0.0139228 ,  0.00309714,  0.01103772, ..., -0.03440739,\n",
              "         0.01775629,  0.0122134 ], dtype=float32),\n",
              " array([-0.0144095 ,  0.00264369,  0.01167718, ..., -0.02756946,\n",
              "         0.01475033,  0.01046351], dtype=float32),\n",
              " array([-0.01373933,  0.00183438,  0.01173022, ..., -0.02235467,\n",
              "         0.01425111,  0.00987443], dtype=float32),\n",
              " array([-0.01266275,  0.00130648,  0.01175869, ..., -0.01944298,\n",
              "         0.01413146,  0.01106054], dtype=float32),\n",
              " array([-0.01263265,  0.00120256,  0.01258298, ..., -0.01806657,\n",
              "         0.01406203,  0.01291275], dtype=float32),\n",
              " array([-0.01177401,  0.00088872,  0.01299696, ..., -0.01748505,\n",
              "         0.013923  ,  0.01508934], dtype=float32),\n",
              " array([-0.01314249,  0.00070858,  0.01454129, ..., -0.01733928,\n",
              "         0.01359785,  0.01740906], dtype=float32),\n",
              " array([-0.01281426,  0.00013765,  0.01482744, ..., -0.01725672,\n",
              "         0.01339647,  0.01967542], dtype=float32),\n",
              " array([-0.00868702, -0.00090319,  0.01380201, ..., -0.01696599,\n",
              "         0.01373936,  0.02141579], dtype=float32),\n",
              " array([-0.01094276, -0.00054119,  0.01570208, ..., -0.01709573,\n",
              "         0.01355076,  0.02416605], dtype=float32),\n",
              " array([-0.00918447, -0.00097607,  0.01540943, ..., -0.01707279,\n",
              "         0.01337202,  0.02633788], dtype=float32),\n",
              " array([-0.01046365, -0.00078886,  0.01612594, ..., -0.01717377,\n",
              "         0.01316153,  0.02855133], dtype=float32),\n",
              " array([-0.01324833, -0.00057128,  0.01693982, ..., -0.01674584,\n",
              "         0.01335043,  0.03031145], dtype=float32),\n",
              " array([-0.00647451, -0.00164122,  0.01324886, ..., -0.01329645,\n",
              "         0.01860387,  0.02565913], dtype=float32),\n",
              " array([-0.01198642, -0.0008408 ,  0.015836  , ..., -0.01353954,\n",
              "         0.02038144,  0.03289305], dtype=float32),\n",
              " array([-0.01277302, -0.00129991,  0.01547104, ..., -0.01439743,\n",
              "         0.0203032 ,  0.03719668], dtype=float32),\n",
              " array([-0.01101102, -0.00197692,  0.01344188, ..., -0.01525918,\n",
              "         0.01998425,  0.04030835], dtype=float32),\n",
              " array([-0.010984  , -0.00195384,  0.01263897, ..., -0.01592101,\n",
              "         0.01974403,  0.04264373], dtype=float32),\n",
              " array([-0.00992099, -0.00230392,  0.01192732, ..., -0.01660463,\n",
              "         0.01923623,  0.04463804], dtype=float32),\n",
              " array([-0.00967818, -0.00243639,  0.01163212, ..., -0.01683997,\n",
              "         0.01909814,  0.04547128], dtype=float32),\n",
              " array([-0.00776267, -0.00302143,  0.01070328, ..., -0.01711497,\n",
              "         0.01894079,  0.04662404], dtype=float32),\n",
              " array([-0.0068207 , -0.00314946,  0.01036559, ..., -0.01699745,\n",
              "         0.01902428,  0.04716897], dtype=float32),\n",
              " array([-0.00643109, -0.00284845,  0.01065046, ..., -0.01680122,\n",
              "         0.01932982,  0.04769972], dtype=float32),\n",
              " array([-0.00603917, -0.00260948,  0.01045752, ..., -0.01700823,\n",
              "         0.0191172 ,  0.04874024], dtype=float32),\n",
              " array([-0.00341724, -0.00291569,  0.00967902, ..., -0.01726719,\n",
              "         0.01881595,  0.0493455 ], dtype=float32),\n",
              " array([-0.00517332, -0.00233644,  0.01079561, ..., -0.01697278,\n",
              "         0.01894262,  0.04924059], dtype=float32),\n",
              " array([-0.00666919, -0.00212496,  0.01144827, ..., -0.01694207,\n",
              "         0.01892301,  0.04988468], dtype=float32),\n",
              " array([-0.00627093, -0.00247735,  0.01086595, ..., -0.01669922,\n",
              "         0.0190163 ,  0.05001273], dtype=float32),\n",
              " array([-0.00670724, -0.00252505,  0.01066428, ..., -0.01657004,\n",
              "         0.01918931,  0.05040342], dtype=float32),\n",
              " array([ 0.01451605, -0.00153434, -0.00044577, ...,  0.00764139,\n",
              "        -0.00133171,  0.00236135], dtype=float32),\n",
              " array([-0.00765654,  0.00519349,  0.01539725, ...,  0.01316958,\n",
              "        -0.01282546,  0.01683702], dtype=float32),\n",
              " array([-0.02500878,  0.0039412 ,  0.01790168, ...,  0.01317687,\n",
              "        -0.01577799,  0.01590201], dtype=float32),\n",
              " array([-0.03419183,  0.00320013,  0.02139963, ...,  0.01366775,\n",
              "        -0.02194519,  0.04940796], dtype=float32),\n",
              " array([-0.04379278, -0.00654222,  0.01846024, ...,  0.01314094,\n",
              "        -0.02303887,  0.03483133], dtype=float32),\n",
              " array([-0.06569138, -0.01010571,  0.01800597, ...,  0.01381445,\n",
              "        -0.02584952,  0.04488758], dtype=float32),\n",
              " array([-0.07553619, -0.01487237,  0.02325143, ...,  0.0134053 ,\n",
              "        -0.0301079 ,  0.03300255], dtype=float32),\n",
              " array([-0.09679008, -0.01390128,  0.03465826, ...,  0.01312147,\n",
              "        -0.02831801,  0.00066784], dtype=float32),\n",
              " array([-0.10114378, -0.00556833,  0.01732426, ...,  0.01409941,\n",
              "        -0.02516788,  0.01543644], dtype=float32),\n",
              " array([-0.10224833, -0.0012328 , -0.00398471, ...,  0.01287599,\n",
              "        -0.00672068, -0.01954369], dtype=float32),\n",
              " array([-0.09476103,  0.00252576, -0.01023308, ...,  0.014799  ,\n",
              "         0.00879761, -0.03187311], dtype=float32),\n",
              " array([-0.09887109,  0.00294449, -0.02388519, ...,  0.01546565,\n",
              "         0.0155368 , -0.02705435], dtype=float32),\n",
              " array([-0.10617688,  0.00517677, -0.0459338 , ...,  0.01197639,\n",
              "         0.0271815 , -0.031891  ], dtype=float32),\n",
              " array([-0.09198752,  0.00768903, -0.07646757, ...,  0.00871718,\n",
              "         0.04226885, -0.03635828], dtype=float32),\n",
              " array([-0.00274233,  0.01136003, -0.12832105, ...,  0.00925784,\n",
              "         0.04459554, -0.03564378], dtype=float32),\n",
              " array([ 0.02535105,  0.01547744, -0.1230405 , ...,  0.00485237,\n",
              "         0.05228689, -0.03961891], dtype=float32),\n",
              " array([-0.0362402 ,  0.01855318, -0.06197327, ...,  0.00669071,\n",
              "         0.02113323, -0.01016987], dtype=float32),\n",
              " array([-0.05583292,  0.01510277, -0.01626663, ...,  0.00153621,\n",
              "        -0.00074014, -0.01164388], dtype=float32),\n",
              " array([-0.03064288,  0.00296777, -0.01629282, ..., -0.00525162,\n",
              "        -0.00430967, -0.02262471], dtype=float32),\n",
              " array([ 0.01525623, -0.0040257 , -0.03121535, ...,  0.00200931,\n",
              "        -0.04981149,  0.00683537], dtype=float32),\n",
              " array([ 0.05192306,  0.00208598, -0.04402607, ..., -0.01621039,\n",
              "        -0.06151571, -0.01110825], dtype=float32),\n",
              " array([-0.00836808,  0.00563931,  0.01880588, ..., -0.0313976 ,\n",
              "        -0.04806725, -0.03165083], dtype=float32),\n",
              " array([-0.03906778,  0.01088208,  0.0455909 , ..., -0.04811805,\n",
              "         0.00364706, -0.03632344], dtype=float32),\n",
              " array([-0.03131957, -0.00052013,  0.00737356, ..., -0.0402316 ,\n",
              "         0.02311586, -0.03177777], dtype=float32),\n",
              " array([ 0.02523834,  0.00293561, -0.04201583, ..., -0.01147219,\n",
              "        -0.03386224,  0.00102891], dtype=float32),\n",
              " array([ 0.0091866 ,  0.00592941,  0.00473597, ..., -0.02433296,\n",
              "        -0.06235688, -0.00502607], dtype=float32),\n",
              " array([-0.03401558, -0.00519085,  0.03850676, ..., -0.01863241,\n",
              "        -0.0873868 , -0.00051164], dtype=float32),\n",
              " array([-5.47145046e-02,  3.80708516e-05,  6.38422370e-02, ...,\n",
              "        -1.51937362e-02, -1.05654396e-01,  2.95080943e-03], dtype=float32),\n",
              " array([-6.1795659e-02,  8.1109265e-03,  4.1048162e-02, ...,\n",
              "        -1.7163152e-02, -1.1374214e-01,  5.7629815e-05], dtype=float32),\n",
              " array([-0.08757119,  0.00307783,  0.00199301, ..., -0.01860161,\n",
              "        -0.11731664,  0.00243282], dtype=float32),\n",
              " array([-0.04730499, -0.00816695, -0.04181376, ..., -0.01731841,\n",
              "        -0.11446849,  0.00368142], dtype=float32),\n",
              " array([-0.0512863 ,  0.00113049, -0.00516352, ..., -0.00799439,\n",
              "        -0.1132483 ,  0.01261555], dtype=float32),\n",
              " array([-0.03715203,  0.00992624,  0.00493899, ..., -0.01055159,\n",
              "        -0.09567193,  0.01505822], dtype=float32),\n",
              " array([ 0.06594086, -0.00339055, -0.09799838, ..., -0.00700015,\n",
              "        -0.08705072,  0.031978  ], dtype=float32),\n",
              " array([ 0.01348508, -0.01157685, -0.04039335, ..., -0.00795156,\n",
              "        -0.09615021,  0.04901288], dtype=float32),\n",
              " array([ 0.00916712,  0.00439474,  0.01343846, ..., -0.01133963,\n",
              "        -0.09127717,  0.0598057 ], dtype=float32),\n",
              " array([ 0.02498116,  0.00978958,  0.02495878, ..., -0.00759046,\n",
              "        -0.09334464,  0.07339655], dtype=float32),\n",
              " array([-0.01672067,  0.00228747, -0.0065268 , ..., -0.01171057,\n",
              "        -0.087362  ,  0.07663547], dtype=float32),\n",
              " array([ 0.07013949, -0.0073628 , -0.07999717, ..., -0.0183364 ,\n",
              "        -0.06048741,  0.08567762], dtype=float32),\n",
              " array([ 0.01814627, -0.01257338, -0.01239186, ..., -0.00380549,\n",
              "        -0.09487475,  0.09037858], dtype=float32),\n",
              " array([ 0.04054449, -0.01483089, -0.01544972, ..., -0.00777825,\n",
              "        -0.07826503,  0.07859361], dtype=float32),\n",
              " array([ 0.02563576, -0.01841002,  0.03051042, ..., -0.00143787,\n",
              "        -0.08568828,  0.07652564], dtype=float32),\n",
              " array([ 0.01289973, -0.0063936 ,  0.04702365, ..., -0.00105453,\n",
              "        -0.07878067,  0.06911297], dtype=float32),\n",
              " array([ 1.4441002e-02,  6.8764510e-03,  3.9114524e-02, ...,\n",
              "         5.1132021e-05, -8.0670707e-02,  6.4703286e-02], dtype=float32),\n",
              " array([ 0.00745633,  0.0135534 ,  0.01746415, ...,  0.00197446,\n",
              "        -0.09258817,  0.06155308], dtype=float32),\n",
              " array([-0.04574659,  0.02277078, -0.02092883, ..., -0.00345164,\n",
              "        -0.042096  ,  0.04587095], dtype=float32),\n",
              " array([ 0.03717275,  0.00354684, -0.08315611, ...,  0.00549205,\n",
              "        -0.0844876 ,  0.05271544], dtype=float32),\n",
              " array([ 0.01493328, -0.03048585, -0.04581144, ...,  0.00477682,\n",
              "        -0.07708123,  0.03919774], dtype=float32),\n",
              " array([ 0.00450341, -0.03364232, -0.01369574, ...,  0.00262568,\n",
              "        -0.09004724,  0.03501308], dtype=float32),\n",
              " array([ 0.00986726, -0.0058926 ,  0.0223169 , ...,  0.00296911,\n",
              "        -0.06684756,  0.01951416], dtype=float32),\n",
              " array([ 0.00435952,  0.00881022,  0.01978273, ...,  0.0016016 ,\n",
              "        -0.03295792,  0.01632783], dtype=float32),\n",
              " array([ 0.06102598,  0.01359071, -0.05116365, ...,  0.01063541,\n",
              "        -0.05511506,  0.02837062], dtype=float32),\n",
              " array([ 0.0089326 ,  0.04056694, -0.03802288, ...,  0.01378372,\n",
              "        -0.02359601,  0.03143929], dtype=float32),\n",
              " array([-7.4059288e-05,  1.9045889e-02,  2.8947914e-02, ...,\n",
              "         9.3335733e-03, -8.1255272e-02,  4.0688157e-02], dtype=float32),\n",
              " array([-0.03914208,  0.01287068,  0.01428456, ...,  0.00663393,\n",
              "        -0.08468178,  0.02908818], dtype=float32),\n",
              " array([ 0.01298651, -0.00416058, -0.01618059, ...,  0.0074328 ,\n",
              "        -0.08279615,  0.01496857], dtype=float32),\n",
              " array([ 0.0413009 , -0.00611025, -0.03966813, ...,  0.00864339,\n",
              "        -0.08095732, -0.00152764], dtype=float32),\n",
              " array([ 0.030666  ,  0.00033785, -0.03252102, ...,  0.00963288,\n",
              "        -0.08798464, -0.00255166], dtype=float32),\n",
              " array([ 0.00048501, -0.00621916, -0.00950987, ...,  0.01359757,\n",
              "        -0.06471127, -0.02674794], dtype=float32),\n",
              " array([ 0.01131655,  0.00228827,  0.01856291, ...,  0.01667106,\n",
              "        -0.02533269, -0.03266047], dtype=float32),\n",
              " array([ 0.00265684, -0.02394906,  0.00778821, ...,  0.0191996 ,\n",
              "        -0.00449733, -0.01955294], dtype=float32),\n",
              " array([ 0.0615107 , -0.02025794, -0.03784937, ...,  0.01722277,\n",
              "        -0.00885156, -0.00902141], dtype=float32),\n",
              " array([ 0.01961019, -0.02004997, -0.01257788, ...,  0.01076731,\n",
              "        -0.06613328,  0.00571567], dtype=float32),\n",
              " array([ 0.04541959, -0.00861682, -0.01539403, ...,  0.0135652 ,\n",
              "        -0.04534424, -0.0109423 ], dtype=float32),\n",
              " array([ 0.01734774, -0.01879652, -0.00125297, ...,  0.01730072,\n",
              "        -0.02750446, -0.00906803], dtype=float32),\n",
              " array([ 0.04442657, -0.00845952, -0.00473754, ...,  0.01173477,\n",
              "         0.01381457, -0.00076189], dtype=float32),\n",
              " array([-0.02293069,  0.05445156, -0.0142319 , ..., -0.07134655,\n",
              "        -0.05297643, -0.02309066], dtype=float32),\n",
              " array([ 0.0369821 ,  0.01580153, -0.04279962, ..., -0.0551373 ,\n",
              "        -0.01542969, -0.04417791], dtype=float32),\n",
              " array([ 0.05105625,  0.00584142, -0.03788203, ..., -0.01436163,\n",
              "         0.02757643, -0.05830432], dtype=float32),\n",
              " array([ 0.0241225 ,  0.00011865, -0.01284771, ...,  0.0065051 ,\n",
              "        -0.01098812, -0.03502889], dtype=float32),\n",
              " array([-0.01014558, -0.0111864 ,  0.01203713, ...,  0.00765756,\n",
              "        -0.032534  , -0.03921113], dtype=float32),\n",
              " array([ 0.0156347 ,  0.01009838,  0.04817856, ...,  0.01060105,\n",
              "        -0.03655775, -0.05251943], dtype=float32),\n",
              " array([-0.00511808,  0.0136131 ,  0.04815185, ...,  0.01276231,\n",
              "        -0.01122552, -0.06583005], dtype=float32),\n",
              " array([-0.0399217 ,  0.01859768,  0.00588832, ...,  0.00786143,\n",
              "         0.03320074, -0.04915384], dtype=float32),\n",
              " array([ 0.01048762,  0.00090628, -0.06432354, ...,  0.01335607,\n",
              "         0.01496514, -0.03302211], dtype=float32),\n",
              " array([ 0.02832551, -0.01096805, -0.05668159, ...,  0.01199014,\n",
              "        -0.04864684, -0.01403   ], dtype=float32),\n",
              " array([ 0.00909458, -0.02959098, -0.0252176 , ...,  0.00882406,\n",
              "        -0.04942221, -0.02639015], dtype=float32),\n",
              " array([ 0.0207959 , -0.01564417,  0.034449  , ...,  0.00172607,\n",
              "         0.00981859, -0.02343871], dtype=float32),\n",
              " array([-0.00284667, -0.05047184,  0.02150914, ...,  0.00536179,\n",
              "         0.00808053, -0.0155033 ], dtype=float32),\n",
              " array([ 0.04724549, -0.04379745, -0.01423253, ...,  0.00291365,\n",
              "         0.00933658, -0.01119305], dtype=float32),\n",
              " array([ 0.04237535, -0.03491405, -0.02579929, ...,  0.00711325,\n",
              "        -0.05678688,  0.00289432], dtype=float32),\n",
              " array([ 0.05276258, -0.01085356, -0.03314941, ...,  0.00850129,\n",
              "        -0.05280495, -0.01637815], dtype=float32),\n",
              " array([ 0.01910731, -0.01675528,  0.02909056, ...,  0.0080798 ,\n",
              "        -0.05438682, -0.02236661], dtype=float32),\n",
              " array([ 0.00979102,  0.00279874,  0.03218718, ...,  0.00974569,\n",
              "        -0.0235744 , -0.02944525], dtype=float32),\n",
              " array([-0.02708913, -0.00851533,  0.02167097, ...,  0.01357629,\n",
              "        -0.053518  , -0.01468396], dtype=float32),\n",
              " array([-0.00654263, -0.01572038,  0.00639272, ...,  0.00661487,\n",
              "        -0.07590853, -0.00389329], dtype=float32),\n",
              " array([-0.03246563, -0.02836317,  0.04117672, ...,  0.00585718,\n",
              "        -0.07755108, -0.00568641], dtype=float32),\n",
              " array([-0.02098832,  0.00309186,  0.03925458, ...,  0.00603556,\n",
              "        -0.07850687, -0.00798858], dtype=float32),\n",
              " array([-0.06760923, -0.00549081,  0.01984497, ...,  0.00901991,\n",
              "        -0.04037001, -0.03497187], dtype=float32),\n",
              " array([-0.07062019, -0.0190468 , -0.00422492, ...,  0.01404113,\n",
              "        -0.02599675, -0.0288043 ], dtype=float32),\n",
              " array([-0.06110772, -0.02242596, -0.01474097, ...,  0.01365163,\n",
              "        -0.01204235, -0.01751433], dtype=float32),\n",
              " array([-0.04809881, -0.02165118, -0.01763908, ...,  0.01010442,\n",
              "        -0.00470546, -0.00688036], dtype=float32),\n",
              " array([-3.3353146e-02, -1.9883577e-02, -1.7815817e-02, ...,\n",
              "         6.4217472e-03, -6.1692754e-03, -8.0342361e-05], dtype=float32),\n",
              " array([-0.02944375, -0.0148657 , -0.01087103, ...,  0.00367539,\n",
              "        -0.00841186,  0.00270675], dtype=float32),\n",
              " array([-0.02455555, -0.01194387, -0.00694657, ...,  0.0028006 ,\n",
              "        -0.01258861,  0.00306032], dtype=float32),\n",
              " array([-0.02265488, -0.00921456, -0.0030327 , ...,  0.00275414,\n",
              "        -0.01372567,  0.00188632], dtype=float32),\n",
              " array([-0.02018642, -0.0077305 , -0.00110698, ...,  0.00286266,\n",
              "        -0.01089103,  0.00056278], dtype=float32),\n",
              " array([-1.7614484e-02, -6.6342070e-03, -1.7836817e-05, ...,\n",
              "         3.4074977e-03, -1.1412925e-02, -2.9993020e-05], dtype=float32),\n",
              " array([-0.01492102, -0.0057593 ,  0.00070579, ...,  0.00350725,\n",
              "        -0.00879668, -0.00064421], dtype=float32),\n",
              " array([-0.01336282, -0.00493022,  0.00191341, ...,  0.003898  ,\n",
              "        -0.00901679, -0.00041797], dtype=float32),\n",
              " array([-0.01210574, -0.00428634,  0.00303465, ...,  0.00407647,\n",
              "        -0.01022685, -0.00033682], dtype=float32),\n",
              " array([-0.01045027, -0.00393377,  0.00356374, ...,  0.0042101 ,\n",
              "        -0.01116585, -0.00034872], dtype=float32),\n",
              " array([ 0.0214694 , -0.00345639, -0.00749314, ...,  0.00514635,\n",
              "        -0.0315592 ,  0.00141862], dtype=float32),\n",
              " array([ 0.00086359,  0.00121781,  0.0051098 , ...,  0.00563918,\n",
              "        -0.04352885, -0.00031856], dtype=float32),\n",
              " array([-0.00427156,  0.00152132,  0.00988697, ...,  0.00702045,\n",
              "        -0.03321963, -0.00545704], dtype=float32),\n",
              " array([-0.01132239,  0.00400581,  0.011326  , ...,  0.00798546,\n",
              "        -0.04606398, -0.00261352], dtype=float32),\n",
              " array([-0.00947718,  0.00186277,  0.00798016, ...,  0.00741269,\n",
              "        -0.05128367, -0.00289711], dtype=float32),\n",
              " array([-0.00761929,  0.00059367,  0.0074194 , ...,  0.00691537,\n",
              "        -0.04697441, -0.00453897], dtype=float32),\n",
              " array([-0.00674947, -0.00025524,  0.00790004, ...,  0.00686548,\n",
              "        -0.03796648, -0.00412715], dtype=float32),\n",
              " array([-0.00684442, -0.00045144,  0.00919644, ...,  0.00674407,\n",
              "        -0.04441389, -0.00029124], dtype=float32),\n",
              " array([-0.00731428, -0.00103997,  0.00957744, ...,  0.00563697,\n",
              "        -0.04193835,  0.00048307], dtype=float32),\n",
              " array([-0.00685591, -0.0019918 ,  0.00934766, ...,  0.00550308,\n",
              "        -0.04219981,  0.00248098], dtype=float32),\n",
              " array([-0.00196724, -0.00347605,  0.0072014 , ...,  0.00532648,\n",
              "        -0.0467395 ,  0.00425675], dtype=float32),\n",
              " array([-0.00412074, -0.00269931,  0.00873995, ...,  0.00510915,\n",
              "        -0.04788014,  0.00448066], dtype=float32),\n",
              " array([-0.003949  , -0.00258326,  0.00939516, ...,  0.00504253,\n",
              "        -0.05021879,  0.00472239], dtype=float32),\n",
              " array([-0.00463112, -0.00237769,  0.01006343, ...,  0.00506911,\n",
              "        -0.05191493,  0.00463933], dtype=float32),\n",
              " array([-0.00457559, -0.0024065 ,  0.00995398, ...,  0.00518097,\n",
              "        -0.05317087,  0.00441679], dtype=float32),\n",
              " array([-0.00378859, -0.00251984,  0.00946116, ...,  0.00531403,\n",
              "        -0.05354414,  0.00407246], dtype=float32),\n",
              " array([-0.00281541, -0.00267382,  0.01023283, ..., -0.01044306,\n",
              "         0.02618199,  0.022003  ], dtype=float32),\n",
              " array([-0.01162426, -0.00130966,  0.01420311, ..., -0.02677091,\n",
              "         0.0368588 ,  0.03775711], dtype=float32),\n",
              " array([-0.00870985, -0.00330139,  0.01015255, ..., -0.02797761,\n",
              "         0.03529639,  0.03771148], dtype=float32),\n",
              " array([-0.00885586, -0.00365603,  0.00886867, ..., -0.0229373 ,\n",
              "         0.03381342,  0.03051898], dtype=float32),\n",
              " array([-0.00743803, -0.00395965,  0.00769806, ..., -0.01576353,\n",
              "         0.03340792,  0.02176107], dtype=float32),\n",
              " array([-0.0053257 , -0.00393462,  0.00714722, ..., -0.00946946,\n",
              "         0.03286062,  0.01537726], dtype=float32),\n",
              " array([-0.00467232, -0.00372404,  0.00764373, ..., -0.00444594,\n",
              "         0.03263074,  0.01001833], dtype=float32),\n",
              " array([-0.00489559, -0.00337523,  0.00844503, ..., -0.00088212,\n",
              "         0.03202688,  0.00759162], dtype=float32),\n",
              " array([-0.00435293, -0.00316687,  0.00864049, ...,  0.00150504,\n",
              "         0.03186491,  0.00505433], dtype=float32),\n",
              " array([-0.00506847, -0.00277327,  0.00907629, ...,  0.00312638,\n",
              "         0.03161585,  0.00419338], dtype=float32),\n",
              " array([-0.00537096, -0.00272452,  0.0092639 , ...,  0.00422709,\n",
              "         0.03171121,  0.00286374], dtype=float32),\n",
              " array([-0.00557832, -0.00262742,  0.00917885, ...,  0.00515032,\n",
              "         0.0322183 ,  0.00164479], dtype=float32),\n",
              " array([-0.01973864,  0.00223377,  0.01796929, ...,  0.01709195,\n",
              "         0.03147614, -0.04102713], dtype=float32),\n",
              " array([-0.01359764, -0.00148481,  0.00317228, ...,  0.02552364,\n",
              "         0.02792598, -0.0419146 ], dtype=float32),\n",
              " array([-0.0004126 , -0.00307187, -0.00594624, ...,  0.02487132,\n",
              "         0.01350373, -0.02809473], dtype=float32),\n",
              " array([-0.00238833, -0.00184296, -0.00103993, ...,  0.02284161,\n",
              "         0.01993262, -0.02827573], dtype=float32),\n",
              " array([-0.0041677 , -0.00148368,  0.0043619 , ...,  0.02192174,\n",
              "         0.02360721, -0.02053132], dtype=float32),\n",
              " array([-0.00300459, -0.00228538,  0.00568137, ...,  0.02104285,\n",
              "         0.02937351, -0.01445123], dtype=float32),\n",
              " array([-0.00234722, -0.00262452,  0.00636806, ...,  0.02059946,\n",
              "         0.03283846, -0.00777984], dtype=float32),\n",
              " array([-0.00241258, -0.00270007,  0.00698729, ...,  0.02022064,\n",
              "         0.03364346, -0.00245455], dtype=float32),\n",
              " array([-0.00254356, -0.00286436,  0.00751526, ...,  0.01988163,\n",
              "         0.03699063, -0.00027567], dtype=float32),\n",
              " array([-0.00333372, -0.00271874,  0.00815655, ...,  0.01963632,\n",
              "         0.03965597,  0.0009664 ], dtype=float32),\n",
              " array([-0.00335619, -0.00267809,  0.0082187 , ...,  0.01994456,\n",
              "         0.03804316,  0.00213545], dtype=float32),\n",
              " array([-0.00321534, -0.0024949 ,  0.00839762, ...,  0.01955571,\n",
              "         0.01102429,  0.0209921 ], dtype=float32),\n",
              " array([-0.00389776, -0.00222558,  0.00870939, ...,  0.01890498,\n",
              "         0.00962203,  0.00518888], dtype=float32),\n",
              " array([-0.00732249, -0.00161117,  0.01040407, ...,  0.02076616,\n",
              "         0.01990675, -0.00576449], dtype=float32),\n",
              " array([-0.01195714, -0.00264134,  0.01270084, ..., -0.00032578,\n",
              "         0.03518371,  0.03718909], dtype=float32),\n",
              " array([-0.00053254, -0.00637446,  0.00559531, ..., -0.02025248,\n",
              "         0.02514604,  0.02981007], dtype=float32),\n",
              " array([-0.00399838, -0.00482607,  0.00821576, ..., -0.02103145,\n",
              "         0.02361802,  0.02134437], dtype=float32),\n",
              " array([-0.00455644, -0.00425869,  0.00897017, ..., -0.0195208 ,\n",
              "         0.02347051,  0.01722649], dtype=float32),\n",
              " array([-0.00472605, -0.0038477 ,  0.00911043, ..., -0.01863294,\n",
              "         0.02320969,  0.01637407], dtype=float32),\n",
              " array([-0.00515308, -0.0036956 ,  0.0091576 , ..., -0.0184088 ,\n",
              "         0.02296704,  0.01694549], dtype=float32),\n",
              " array([-0.00635281, -0.00337666,  0.00952932, ..., -0.01889054,\n",
              "         0.02227375,  0.01913178], dtype=float32),\n",
              " array([-0.00580167, -0.00365887,  0.00884072, ..., -0.0191958 ,\n",
              "         0.02183044,  0.02089307], dtype=float32),\n",
              " array([-0.00512371, -0.0036507 ,  0.00838418, ..., -0.01914338,\n",
              "         0.02168109,  0.02258626], dtype=float32),\n",
              " array([-0.00426194, -0.00363483,  0.00829642, ..., -0.01947394,\n",
              "         0.02109135,  0.02528646], dtype=float32),\n",
              " array([-0.00447673, -0.00328658,  0.00899809, ..., -0.01863935,\n",
              "         0.02172324,  0.02513185], dtype=float32),\n",
              " array([-0.0043709 , -0.00313618,  0.00907727, ..., -0.0199459 ,\n",
              "         0.02039333,  0.03124271], dtype=float32),\n",
              " array([-0.00683795, -0.00249544,  0.01049325, ..., -0.02053494,\n",
              "         0.01894752,  0.03263974], dtype=float32),\n",
              " array([-0.00908399, -0.00244873,  0.01117269, ..., -0.02024369,\n",
              "         0.0187635 ,  0.0331684 ], dtype=float32),\n",
              " array([-0.00791753, -0.00357814,  0.00982639, ..., -0.01961611,\n",
              "         0.01932481,  0.03364709], dtype=float32),\n",
              " array([-0.00656075, -0.00399395,  0.0084352 , ..., -0.01909771,\n",
              "         0.01985517,  0.03498147], dtype=float32),\n",
              " array([ 0.00241879, -0.00471793,  0.00558168, ..., -0.0184327 ,\n",
              "         0.02075295,  0.03576423], dtype=float32),\n",
              " array([-0.00511699, -0.00327581,  0.01009146, ..., -0.01888739,\n",
              "         0.02030253,  0.03894068], dtype=float32),\n",
              " array([-0.00848885, -0.00292229,  0.01193725, ..., -0.01957322,\n",
              "         0.01961416,  0.04065528], dtype=float32),\n",
              " array([-0.00783121, -0.0031351 ,  0.01030703, ..., -0.0197564 ,\n",
              "         0.0191225 ,  0.0415637 ], dtype=float32),\n",
              " array([-0.00877082, -0.00295278,  0.00965274, ..., -0.01961958,\n",
              "         0.01899212,  0.04214137], dtype=float32),\n",
              " array([-0.00909827, -0.00269256,  0.00948862, ..., -0.01929092,\n",
              "         0.01903568,  0.04275761], dtype=float32),\n",
              " array([-0.02521173,  0.0284117 , -0.0075479 , ..., -0.08842562,\n",
              "        -0.01496484, -0.02832167], dtype=float32),\n",
              " array([-0.02104533,  0.00835355, -0.00183326, ..., -0.0524862 ,\n",
              "         0.01173976,  0.00447644], dtype=float32),\n",
              " array([-0.01725336,  0.00026106,  0.00327939, ..., -0.03369863,\n",
              "         0.02110428,  0.00588631], dtype=float32),\n",
              " array([-0.01406081, -0.0029079 ,  0.0073121 , ..., -0.02185538,\n",
              "         0.02429374,  0.00537095], dtype=float32),\n",
              " array([-0.01191999, -0.00395735,  0.01061357, ..., -0.01645394,\n",
              "         0.02522548,  0.00497943], dtype=float32),\n",
              " array([-0.01100335, -0.0041935 ,  0.01289408, ..., -0.01535102,\n",
              "         0.02457055,  0.00702194], dtype=float32),\n",
              " array([-0.01064017, -0.00390623,  0.01443651, ..., -0.01589166,\n",
              "         0.02373029,  0.00907312], dtype=float32),\n",
              " array([-0.01084616, -0.00376567,  0.01574684, ..., -0.01572252,\n",
              "         0.02467129,  0.0086118 ], dtype=float32),\n",
              " array([-0.01095743, -0.00363081,  0.01633384, ..., -0.01759099,\n",
              "         0.02317106,  0.01497033], dtype=float32),\n",
              " array([-0.01321574, -0.00279984,  0.01680423, ..., -0.01843204,\n",
              "         0.02212154,  0.01731076], dtype=float32),\n",
              " array([-0.00250062, -0.00096893,  0.00770253, ...,  0.00366849,\n",
              "         0.0198179 , -0.07652902], dtype=float32),\n",
              " array([ 0.06628356,  0.00409456, -0.03856438, ...,  0.01273526,\n",
              "         0.0087653 , -0.0300584 ], dtype=float32),\n",
              " array([ 0.0191952 ,  0.01457851, -0.00137807, ...,  0.01170934,\n",
              "        -0.00260531, -0.00273951], dtype=float32),\n",
              " array([ 0.00672959,  0.01938936,  0.03835727, ...,  0.01052304,\n",
              "        -0.00538031,  0.00365136], dtype=float32),\n",
              " array([-0.02033159,  0.01899674,  0.03665072, ...,  0.01097918,\n",
              "        -0.00297354,  0.00889123], dtype=float32),\n",
              " array([-0.01534024,  0.01320031,  0.01089463, ...,  0.01156223,\n",
              "         0.00295661,  0.015491  ], dtype=float32),\n",
              " array([ 0.04557955,  0.01491952, -0.01665988, ...,  0.01095597,\n",
              "         0.00935811,  0.02053081], dtype=float32),\n",
              " array([-0.00425398, -0.00052282,  0.03914845, ...,  0.01054872,\n",
              "         0.02351126,  0.01453338], dtype=float32),\n",
              " array([-0.01298179,  0.00839445,  0.06505296, ...,  0.00826421,\n",
              "         0.03860717,  0.00615835], dtype=float32),\n",
              " array([-0.05504305,  0.01008956,  0.04937676, ...,  0.0106999 ,\n",
              "         0.03803924, -0.00123434], dtype=float32),\n",
              " array([-0.03932609, -0.00265877, -0.00401821, ...,  0.01489766,\n",
              "         0.00808909,  0.03974696], dtype=float32),\n",
              " array([ 0.00523475, -0.02118837, -0.01947867, ...,  0.01082505,\n",
              "        -0.00379758,  0.01596263], dtype=float32),\n",
              " array([-0.04088277, -0.03151158,  0.01564097, ...,  0.01400256,\n",
              "        -0.02822066,  0.04340176], dtype=float32),\n",
              " array([-0.04709041, -0.01830332,  0.0398753 , ...,  0.01188308,\n",
              "        -0.04253175,  0.03171453], dtype=float32),\n",
              " array([-0.06796855, -0.0165223 ,  0.02423987, ...,  0.01122967,\n",
              "        -0.04628051,  0.00722238], dtype=float32),\n",
              " array([-0.07601829, -0.01620071,  0.00427667, ...,  0.01247545,\n",
              "        -0.04269357, -0.00789706], dtype=float32),\n",
              " array([ 0.02435789, -0.03006425, -0.06664889, ...,  0.01431387,\n",
              "        -0.0554123 ,  0.01169553], dtype=float32),\n",
              " array([ 0.04522989, -0.0055999 , -0.06641482, ...,  0.01030188,\n",
              "        -0.05178836, -0.01739893], dtype=float32),\n",
              " array([-0.00021271,  0.01290864, -0.00382791, ...,  0.00526834,\n",
              "        -0.02419402, -0.04639993], dtype=float32),\n",
              " array([-0.02516931,  0.01939066,  0.0165339 , ...,  0.00516645,\n",
              "        -0.00055472, -0.05252685], dtype=float32),\n",
              " array([-0.01427847,  0.01721462, -0.01527082, ...,  0.00980889,\n",
              "        -0.01580588, -0.0334377 ], dtype=float32),\n",
              " array([ 0.03355936, -0.00093381, -0.041665  , ...,  0.00797415,\n",
              "        -0.05859182, -0.00146422], dtype=float32),\n",
              " array([ 0.00841128,  0.00086677, -0.01501658, ...,  0.00201576,\n",
              "        -0.08771951,  0.0037005 ], dtype=float32),\n",
              " array([-0.014557  ,  0.00251203,  0.02958063, ..., -0.00079439,\n",
              "        -0.10632815,  0.0030849 ], dtype=float32),\n",
              " array([-0.02303946,  0.00984454,  0.02858966, ..., -0.00384558,\n",
              "        -0.11734127, -0.00182741], dtype=float32),\n",
              " array([-0.05403098,  0.004212  ,  0.00203261, ..., -0.00838854,\n",
              "        -0.12124486, -0.00490943], dtype=float32),\n",
              " array([-0.04212688, -0.00904255, -0.02760968, ..., -0.00702855,\n",
              "        -0.1235384 ,  0.00026285], dtype=float32),\n",
              " array([ 0.04259542, -0.00627727, -0.08259836, ..., -0.01289903,\n",
              "        -0.08430751, -0.0292946 ], dtype=float32),\n",
              " array([ 0.0286033 ,  0.00827028, -0.06780827, ..., -0.00730508,\n",
              "        -0.06027108, -0.02026701], dtype=float32),\n",
              " array([-0.01834011,  0.00309752, -0.04078   , ...,  0.00233505,\n",
              "        -0.08897583,  0.00626409], dtype=float32),\n",
              " array([-0.03270575,  0.00961061, -0.01541905, ...,  0.00169692,\n",
              "        -0.09969925,  0.01523687], dtype=float32),\n",
              " array([-0.04186628,  0.00592224,  0.0107221 , ..., -0.00236637,\n",
              "        -0.10082867,  0.01488709], dtype=float32),\n",
              " array([ 0.04535858,  0.00565016, -0.02496925, ..., -0.00544831,\n",
              "        -0.09150405,  0.0139017 ], dtype=float32),\n",
              " array([ 0.04570483,  0.00454228, -0.02485692, ..., -0.00272608,\n",
              "        -0.10290945,  0.02557593], dtype=float32),\n",
              " array([-0.00800573, -0.0130437 , -0.01044906, ..., -0.00926376,\n",
              "        -0.08579925,  0.02242505], dtype=float32),\n",
              " array([ 0.00104249,  0.00128566,  0.00891974, ..., -0.00457545,\n",
              "        -0.09910892,  0.03398094], dtype=float32),\n",
              " array([ 0.0344236 , -0.00458131, -0.01633074, ..., -0.00989112,\n",
              "        -0.06209277,  0.03212217], dtype=float32),\n",
              " array([ 0.00981116,  0.00071079,  0.00989145, ..., -0.00927312,\n",
              "        -0.05034561,  0.04551087], dtype=float32),\n",
              " array([-0.00068786,  0.00152537,  0.01334708, ..., -0.00149664,\n",
              "        -0.08607318,  0.05572141], dtype=float32),\n",
              " array([ 0.00700077,  0.00063957,  0.0033201 , ..., -0.01228781,\n",
              "        -0.05982104,  0.04371066], dtype=float32),\n",
              " array([-0.00425692, -0.00082522,  0.02117224, ..., -0.01133255,\n",
              "        -0.04156217,  0.05102859], dtype=float32),\n",
              " array([-0.00072037, -0.01139981,  0.03364443, ..., -0.01380637,\n",
              "        -0.04769654,  0.05078824], dtype=float32),\n",
              " array([-0.01075506, -0.00515324,  0.04372653, ..., -0.00525253,\n",
              "        -0.07889836,  0.05340333], dtype=float32),\n",
              " array([ 0.01643607, -0.02949066,  0.00963871, ..., -0.00709344,\n",
              "        -0.06402532,  0.04210753], dtype=float32),\n",
              " array([ 0.07370531, -0.02129779, -0.06334776, ..., -0.00630688,\n",
              "        -0.04173777,  0.0384526 ], dtype=float32),\n",
              " array([ 0.01561102, -0.00828544,  0.01473579, ...,  0.00175757,\n",
              "        -0.05195938,  0.04352239], dtype=float32),\n",
              " array([-0.01457294, -0.01396965,  0.00750285, ..., -0.00055371,\n",
              "        -0.07889193,  0.0436207 ], dtype=float32),\n",
              " array([ 0.03718454, -0.01197787, -0.0510984 , ...,  0.00202088,\n",
              "        -0.08350015,  0.04164648], dtype=float32),\n",
              " array([ 0.00281338, -0.01940834,  0.00251614, ...,  0.00216979,\n",
              "        -0.06654183,  0.0165445 ], dtype=float32),\n",
              " array([-0.00293492, -0.02342181,  0.02436791, ...,  0.00467809,\n",
              "        -0.07592653,  0.01257487], dtype=float32),\n",
              " array([ 0.02811259,  0.00700026,  0.03108048, ...,  0.00681518,\n",
              "        -0.06411912, -0.00286454], dtype=float32),\n",
              " array([-0.01497764, -0.00073785,  0.00273941, ...,  0.00867801,\n",
              "        -0.0192825 , -0.01158275], dtype=float32),\n",
              " array([-0.02484992, -0.01136068, -0.01140109, ...,  0.01365421,\n",
              "        -0.03602676, -0.00166336], dtype=float32),\n",
              " array([-7.6389755e-05, -2.6987555e-02, -3.8536727e-02, ...,\n",
              "         1.0541349e-02, -1.6275460e-02, -1.4730536e-03], dtype=float32),\n",
              " array([ 0.04210022, -0.0219647 , -0.06468485, ...,  0.00947287,\n",
              "        -0.01159713,  0.00548898], dtype=float32),\n",
              " array([ 0.05364544, -0.00455981, -0.06305702, ...,  0.00711685,\n",
              "        -0.01321946,  0.00896063], dtype=float32),\n",
              " array([ 0.03677285, -0.00754495, -0.03910052, ...,  0.00703419,\n",
              "        -0.02818117,  0.01144041], dtype=float32),\n",
              " array([ 0.04351076, -0.00100834, -0.03989912, ...,  0.00576066,\n",
              "        -0.02031123,  0.00801704], dtype=float32),\n",
              " array([ 0.03227602,  0.0009368 , -0.03377803, ...,  0.0059811 ,\n",
              "        -0.0294042 ,  0.00855554], dtype=float32),\n",
              " array([ 0.02649765, -0.00457875, -0.02859257, ...,  0.0062981 ,\n",
              "        -0.04013765,  0.00739082], dtype=float32),\n",
              " array([ 0.00296959, -0.01776844, -0.0171062 , ...,  0.00557837,\n",
              "        -0.04517512,  0.00403863], dtype=float32),\n",
              " array([ 0.01647239, -0.01322555, -0.00908178, ...,  0.00670534,\n",
              "        -0.04460297,  0.00100367], dtype=float32),\n",
              " array([ 0.05417392, -0.011163  , -0.02074056, ...,  0.00622472,\n",
              "        -0.07605804,  0.01258684], dtype=float32),\n",
              " array([ 0.04053129, -0.02067012, -0.01768198, ...,  0.00551751,\n",
              "        -0.06964377,  0.00305641], dtype=float32),\n",
              " array([ 0.05158129, -0.01717794, -0.01700098, ...,  0.00821365,\n",
              "        -0.06738491, -0.00768649], dtype=float32),\n",
              " array([ 0.01612811, -0.04113226,  0.00369367, ...,  0.00455558,\n",
              "        -0.06866036, -0.00745956], dtype=float32),\n",
              " array([ 0.01173987, -0.04859955,  0.01418563, ...,  0.00851686,\n",
              "        -0.05297993, -0.02445173], dtype=float32),\n",
              " array([ 0.02964938, -0.01426734,  0.02279122, ...,  0.01071481,\n",
              "        -0.02876308, -0.02634215], dtype=float32),\n",
              " array([ 0.01180385, -0.02003494,  0.00248251, ...,  0.01099104,\n",
              "        -0.01610311, -0.01670224], dtype=float32),\n",
              " array([ 0.00693138, -0.01813276, -0.0081776 , ...,  0.00951576,\n",
              "        -0.00808269, -0.00634118], dtype=float32),\n",
              " array([ 0.04089824, -0.0228579 , -0.03124649, ...,  0.00536413,\n",
              "        -0.06225207,  0.01326168], dtype=float32),\n",
              " array([ 0.03335116, -0.02320294, -0.02692837, ...,  0.00618064,\n",
              "        -0.05227716, -0.00094827], dtype=float32),\n",
              " array([ 0.01819989, -0.02994581, -0.00355699, ...,  0.00678548,\n",
              "        -0.07032271,  0.00837235], dtype=float32),\n",
              " array([ 0.02967738, -0.00492213,  0.01626315, ...,  0.00747848,\n",
              "        -0.04497906, -0.01187064], dtype=float32),\n",
              " array([ 0.01275195,  0.00592052,  0.00561353, ...,  0.01211607,\n",
              "        -0.04037197, -0.00787842], dtype=float32),\n",
              " array([-0.00336027,  0.00916145, -0.00087048, ...,  0.01138207,\n",
              "        -0.03880024, -0.00124481], dtype=float32),\n",
              " array([-0.02210096,  0.00741482, -0.01977747, ...,  0.00813011,\n",
              "        -0.05508064,  0.01132636], dtype=float32),\n",
              " array([-0.02690132,  0.00999222, -0.02009827, ...,  0.00807976,\n",
              "        -0.04615723,  0.01029184], dtype=float32),\n",
              " array([ 0.04144299, -0.00444906, -0.07731881, ..., -0.00755889,\n",
              "         0.03429664,  0.03436339], dtype=float32),\n",
              " array([ 0.01124574, -0.01187855, -0.04625627, ..., -0.02701875,\n",
              "         0.03648766,  0.04493224], dtype=float32),\n",
              " array([ 0.02339305, -0.01668309, -0.03602275, ..., -0.01410567,\n",
              "         0.03406852,  0.03073308], dtype=float32),\n",
              " array([ 0.01957674, -0.01415583, -0.0145829 , ..., -0.01499397,\n",
              "         0.0379122 ,  0.03363428], dtype=float32),\n",
              " array([ 0.03654435, -0.01910271, -0.01590963, ..., -0.0142116 ,\n",
              "         0.03653187,  0.02504128], dtype=float32),\n",
              " array([ 0.02600782, -0.01628093, -0.00226566, ..., -0.01079528,\n",
              "         0.03689866,  0.01908749], dtype=float32),\n",
              " array([ 0.02029869, -0.01387097,  0.00540686, ..., -0.00673248,\n",
              "         0.03697179,  0.01404963], dtype=float32),\n",
              " array([ 0.01625241, -0.01225347,  0.00947364, ..., -0.00306984,\n",
              "         0.03731828,  0.01007889], dtype=float32),\n",
              " array([ 0.01415358, -0.01102114,  0.0103962 , ...,  0.00022321,\n",
              "         0.03764024,  0.00647674], dtype=float32),\n",
              " array([ 0.01038813, -0.00902651,  0.01213912, ...,  0.00539831,\n",
              "         0.0390353 , -0.00163049], dtype=float32),\n",
              " array([ 0.00833639, -0.00788957,  0.01270442, ...,  0.00471346,\n",
              "         0.03832426,  0.0064317 ], dtype=float32),\n",
              " array([ 0.00897585, -0.00719077,  0.01203579, ...,  0.00456303,\n",
              "         0.03745288,  0.00182075], dtype=float32),\n",
              " array([-0.05751082,  0.04841938, -0.05839811, ..., -0.0602436 ,\n",
              "         0.05724775,  0.02561247], dtype=float32),\n",
              " array([-0.02439053,  0.008564  , -0.05163001, ..., -0.05156164,\n",
              "         0.04085239,  0.04326012], dtype=float32),\n",
              " array([-0.00855202, -0.00254745, -0.03973938, ..., -0.03942329,\n",
              "         0.03787195,  0.04217936], dtype=float32),\n",
              " array([ 0.04006972, -0.00448914, -0.04870352, ..., -0.02326142,\n",
              "         0.03686846,  0.02642409], dtype=float32),\n",
              " array([ 0.01544197, -0.00270847, -0.0242541 , ..., -0.01216962,\n",
              "         0.03928629,  0.016788  ], dtype=float32),\n",
              " array([ 0.00541066, -0.00120049, -0.00744181, ..., -0.00629093,\n",
              "         0.04196036,  0.01009987], dtype=float32),\n",
              " array([ 0.00182311, -0.00180187, -0.00026   , ..., -0.00373693,\n",
              "         0.04457106,  0.00539825], dtype=float32),\n",
              " array([-0.00084318, -0.00242779,  0.00241693, ..., -0.00175208,\n",
              "         0.04606185,  0.0010225 ], dtype=float32),\n",
              " array([-0.00332588, -0.00229126,  0.00430772, ..., -0.00094069,\n",
              "         0.04745194, -0.00207955], dtype=float32),\n",
              " array([-4.3922868e-03, -2.2879785e-03,  4.8805238e-03, ...,\n",
              "         9.1973277e-05,  4.7979206e-02, -4.7708326e-03], dtype=float32),\n",
              " array([-0.00539657, -0.00190323,  0.00562963, ...,  0.00080491,\n",
              "         0.04829203, -0.00759679], dtype=float32),\n",
              " array([-0.00579049, -0.00170268,  0.00588663, ...,  0.00189203,\n",
              "         0.04809658, -0.01064656], dtype=float32),\n",
              " array([-0.00534854, -0.00158662,  0.00593461, ...,  0.00201494,\n",
              "         0.0487672 , -0.01195966], dtype=float32),\n",
              " array([-0.00443528, -0.00141751,  0.00592483, ...,  0.00111558,\n",
              "         0.04965146, -0.01173552], dtype=float32),\n",
              " array([-0.00478695, -0.00111564,  0.00680107, ...,  0.00042837,\n",
              "         0.04958262, -0.0117108 ], dtype=float32),\n",
              " array([-0.00447025, -0.00109197,  0.00741203, ...,  0.00065835,\n",
              "         0.04911863, -0.01324386], dtype=float32),\n",
              " array([-0.01229974,  0.00032149,  0.0120673 , ..., -0.01672666,\n",
              "         0.03867635,  0.01648627], dtype=float32),\n",
              " array([-1.7445840e-02,  3.2649234e-05,  1.0138261e-02, ...,\n",
              "        -2.2005161e-02,  3.1800725e-02,  1.2618943e-02], dtype=float32),\n",
              " array([-0.01272905, -0.00280451,  0.00381099, ..., -0.01855866,\n",
              "         0.03082425,  0.00856435], dtype=float32),\n",
              " array([-0.01034155, -0.00353717,  0.00239147, ..., -0.01244369,\n",
              "         0.03157959,  0.00229739], dtype=float32),\n",
              " array([-0.00735758, -0.0039077 ,  0.00189385, ..., -0.0072051 ,\n",
              "         0.03227812, -0.00035938], dtype=float32),\n",
              " array([-0.00296195, -0.00421768,  0.00130325, ..., -0.0043487 ,\n",
              "         0.03227974, -0.00096869], dtype=float32),\n",
              " array([-0.00161082, -0.00355877,  0.00216989, ..., -0.00364656,\n",
              "         0.0315093 ,  0.00048173], dtype=float32),\n",
              " array([-0.00071332, -0.00305185,  0.00325067, ..., -0.00318974,\n",
              "         0.03203837, -0.00179021], dtype=float32),\n",
              " array([-0.0022911 , -0.00195927,  0.00610678, ..., -0.00236377,\n",
              "         0.03263137, -0.00223323], dtype=float32),\n",
              " array([-0.00182687, -0.00208866,  0.00552449, ..., -0.0026465 ,\n",
              "         0.03282574, -0.00092708], dtype=float32),\n",
              " array([-0.00115316, -0.00229448,  0.00484448, ..., -0.00421152,\n",
              "         0.03288819,  0.00015785], dtype=float32),\n",
              " array([ 0.00724807, -0.0025806 ,  0.00264691, ...,  0.00189476,\n",
              "         0.03759366, -0.02130978], dtype=float32),\n",
              " array([ 0.00506675, -0.00156036,  0.00488227, ...,  0.0084231 ,\n",
              "         0.04172404, -0.0274825 ], dtype=float32),\n",
              " array([ 0.00095451, -0.00074647,  0.00804982, ...,  0.00964763,\n",
              "         0.04345395, -0.02541866], dtype=float32),\n",
              " array([-0.00142818, -0.00045282,  0.00955398, ...,  0.00763159,\n",
              "         0.04299394, -0.01839197], dtype=float32),\n",
              " array([-0.00471671, -0.00068753,  0.0102212 , ...,  0.00416668,\n",
              "         0.04189492, -0.01105332], dtype=float32),\n",
              " array([-0.00462561, -0.00125143,  0.00917862, ...,  0.00283046,\n",
              "         0.04160186, -0.01506584], dtype=float32),\n",
              " array([-0.00665364, -0.00162327,  0.00965532, ...,  0.00228831,\n",
              "         0.04173461, -0.01411904], dtype=float32),\n",
              " array([-0.00415102, -0.0024312 ,  0.00769359, ...,  0.00031275,\n",
              "         0.0415733 , -0.01140233], dtype=float32),\n",
              " array([-0.00464782, -0.00224483,  0.00753123, ..., -0.00086874,\n",
              "         0.04152053, -0.01350663], dtype=float32),\n",
              " array([-0.00387977, -0.00221205,  0.00696513, ..., -0.00148189,\n",
              "         0.04193168, -0.01529099], dtype=float32),\n",
              " array([-0.00261152, -0.00230455,  0.0066145 , ..., -0.00027978,\n",
              "         0.04278353, -0.02255127], dtype=float32),\n",
              " array([-0.00336286, -0.00185448,  0.00727552, ...,  0.00067165,\n",
              "         0.04391177, -0.02367567], dtype=float32),\n",
              " array([ 0.01651591,  0.0105123 ,  0.01811088, ..., -0.00935941,\n",
              "         0.03794684,  0.01128786], dtype=float32),\n",
              " array([ 0.00196545,  0.00688208, -0.01075159, ..., -0.01668   ,\n",
              "         0.03244703,  0.0118801 ], dtype=float32),\n",
              " array([ 0.00202239,  0.0021643 , -0.01742043, ..., -0.01703214,\n",
              "         0.03164676,  0.00676002], dtype=float32),\n",
              " array([ 0.00823799, -0.00110768, -0.01657245, ..., -0.01430727,\n",
              "         0.03358973, -0.00204859], dtype=float32),\n",
              " array([ 0.02391948, -0.0026261 , -0.0174024 , ..., -0.01252663,\n",
              "         0.03477854, -0.00230413], dtype=float32),\n",
              " array([ 0.01176845, -0.00057237, -0.00275008, ..., -0.01220997,\n",
              "         0.03478464, -0.00096187], dtype=float32),\n",
              " array([ 0.00695913, -0.00140102,  0.00380421, ..., -0.01202633,\n",
              "         0.0350418 , -0.00217688], dtype=float32),\n",
              " array([ 5.3429380e-03, -2.8652695e-03,  5.9386096e-03, ...,\n",
              "        -1.2258925e-02,  3.4660663e-02,  8.8628745e-05], dtype=float32),\n",
              " array([ 0.00235605, -0.00352384,  0.0077044 , ..., -0.01249953,\n",
              "         0.03427178,  0.00034984], dtype=float32),\n",
              " array([ 0.00163837, -0.00415488,  0.00793314, ..., -0.01298566,\n",
              "         0.03396367,  0.00159365], dtype=float32),\n",
              " array([ 5.6409353e-05, -4.0032812e-03,  8.7552564e-03, ...,\n",
              "        -1.2646704e-02,  3.4181535e-02, -4.8763142e-04], dtype=float32),\n",
              " array([-0.00065698, -0.004027  ,  0.00925427, ..., -0.013113  ,\n",
              "         0.03385331,  0.00245951], dtype=float32),\n",
              " array([-0.00073255, -0.00382894,  0.00919303, ..., -0.0133674 ,\n",
              "         0.03356598,  0.00233945], dtype=float32),\n",
              " array([-0.0012419 , -0.00361841,  0.0095818 , ..., -0.01395511,\n",
              "         0.03286052,  0.00479582], dtype=float32),\n",
              " array([ 0.03991333,  0.01104976,  0.01802849, ..., -0.01297041,\n",
              "         0.03375774, -0.0007322 ], dtype=float32),\n",
              " array([ 0.00734228,  0.01110794, -0.01476605, ..., -0.01166604,\n",
              "         0.03500102, -0.0036548 ], dtype=float32),\n",
              " array([ 0.00924517,  0.00417744, -0.02556782, ..., -0.01186293,\n",
              "         0.03498824, -0.00063382], dtype=float32),\n",
              " array([ 0.01070987, -0.0004458 , -0.02106708, ..., -0.01127069,\n",
              "         0.03568108, -0.0052202 ], dtype=float32),\n",
              " array([ 0.01788053, -0.00387249, -0.01601143, ..., -0.01162123,\n",
              "         0.03574768, -0.00237228], dtype=float32),\n",
              " array([ 0.01644859, -0.00480397, -0.00632168, ..., -0.01192441,\n",
              "         0.03561736, -0.00283262], dtype=float32),\n",
              " array([ 0.01570524, -0.00613702, -0.0002048 , ..., -0.01249492,\n",
              "         0.03520469, -0.0007018 ], dtype=float32),\n",
              " array([ 0.01028477, -0.00622754,  0.00581281, ..., -0.011967  ,\n",
              "         0.03556975, -0.00487552], dtype=float32),\n",
              " array([ 0.00819814, -0.00684661,  0.00824968, ..., -0.01221264,\n",
              "         0.03554093, -0.00211891], dtype=float32),\n",
              " array([ 0.00434085, -0.00668466,  0.01013623, ..., -0.0122287 ,\n",
              "         0.035503  , -0.00335096], dtype=float32),\n",
              " array([ 0.00472101, -0.00683551,  0.00962111, ..., -0.01227757,\n",
              "         0.03546127, -0.00296694], dtype=float32),\n",
              " array([ 0.00235188, -0.00608809,  0.0110002 , ..., -0.01166158,\n",
              "         0.03593106, -0.00615245], dtype=float32),\n",
              " array([ 0.002578  , -0.00585949,  0.01081144, ..., -0.01182983,\n",
              "         0.03595212, -0.00400833], dtype=float32),\n",
              " array([ 0.00060831, -0.00504717,  0.01164204, ..., -0.01178979,\n",
              "         0.03620814, -0.00583077], dtype=float32),\n",
              " array([ 0.00237976, -0.00552105,  0.02168152, ..., -0.00036445,\n",
              "         0.03630162, -0.05542237], dtype=float32),\n",
              " array([ 0.0285694 ,  0.00166368,  0.01488093, ...,  0.00669851,\n",
              "         0.03547016, -0.04349454], dtype=float32),\n",
              " array([ 0.00048434,  0.01081156,  0.02843175, ...,  0.00718225,\n",
              "         0.03221763, -0.02767194], dtype=float32),\n",
              " array([-0.02292593, -0.00601869,  0.02146506, ...,  0.00502056,\n",
              "         0.03182033, -0.02354789], dtype=float32),\n",
              " array([-0.03080554, -0.01174563,  0.03299535, ...,  0.00300047,\n",
              "         0.03556027, -0.02026208], dtype=float32),\n",
              " array([-0.04262321, -0.00709868,  0.04772795, ...,  0.00252062,\n",
              "         0.03887964, -0.02049216], dtype=float32),\n",
              " array([-0.0576124 ,  0.00074119,  0.03567842, ..., -0.00136851,\n",
              "         0.04782434, -0.01866203], dtype=float32),\n",
              " array([-0.06643025,  0.006272  ,  0.01282274, ..., -0.00438591,\n",
              "         0.05167405, -0.01453882], dtype=float32),\n",
              " array([-0.05678964,  0.00195212, -0.04070359, ..., -0.00321102,\n",
              "         0.0520917 , -0.0300825 ], dtype=float32),\n",
              " array([-0.02792869, -0.00135445, -0.06616714, ..., -0.00339459,\n",
              "         0.0555076 , -0.0382831 ], dtype=float32),\n",
              " array([ 0.03617138,  0.00122826, -0.08392093, ...,  0.00559503,\n",
              "         0.04293963, -0.04131534], dtype=float32),\n",
              " array([ 0.00848099, -0.00362478, -0.02834171, ...,  0.00422333,\n",
              "         0.04287382, -0.04140545], dtype=float32),\n",
              " array([-0.01718649,  0.00226234,  0.01570347, ...,  0.00907186,\n",
              "         0.02227507, -0.02001701], dtype=float32),\n",
              " array([-0.04056782,  0.00238291,  0.01654209, ...,  0.0053016 ,\n",
              "         0.02071078, -0.02601493], dtype=float32),\n",
              " array([-0.03989483, -0.00340353, -0.00644126, ..., -0.00027823,\n",
              "         0.03849056, -0.03737599], dtype=float32),\n",
              " array([ 0.01547151, -0.00470101, -0.03453923, ...,  0.00270841,\n",
              "         0.04724588, -0.03863829], dtype=float32),\n",
              " array([-0.02452153,  0.00184555,  0.00526826, ..., -0.00116218,\n",
              "         0.05993391, -0.04223313], dtype=float32),\n",
              " array([ 0.0065031 ,  0.01326885,  0.02254273, ..., -0.00340224,\n",
              "         0.06667046, -0.03802495], dtype=float32),\n",
              " array([-0.02790015,  0.02767006, -0.01519853, ..., -0.00123961,\n",
              "         0.06479896, -0.04931559], dtype=float32),\n",
              " array([ 0.04484788,  0.01639788, -0.06713303, ...,  0.00211738,\n",
              "         0.05020946, -0.04476202], dtype=float32),\n",
              " array([-0.00540164, -0.00198427, -0.01672678, ...,  0.00565169,\n",
              "         0.02072085, -0.02831928], dtype=float32),\n",
              " array([-0.01483897,  0.00347524,  0.00334542, ...,  0.00292387,\n",
              "        -0.00774852, -0.01940385], dtype=float32),\n",
              " array([-0.02971054, -0.00272194,  0.00289973, ..., -0.00504633,\n",
              "        -0.0005981 , -0.04002421], dtype=float32),\n",
              " array([-0.00957049, -0.01516397, -0.01592688, ..., -0.00600299,\n",
              "         0.00960425, -0.04144571], dtype=float32),\n",
              " array([ 0.01245446, -0.01984906, -0.02177884, ..., -0.00450471,\n",
              "         0.00118483, -0.03283924], dtype=float32),\n",
              " array([ 0.00732512, -0.0262296 ,  0.01011747, ..., -0.01775223,\n",
              "         0.02747512, -0.04141579], dtype=float32),\n",
              " array([ 0.02170008, -0.00018915,  0.03264416, ..., -0.02583983,\n",
              "         0.05251485, -0.03480327], dtype=float32),\n",
              " array([-0.01707274,  0.00067263,  0.00516362, ..., -0.02842204,\n",
              "         0.06396964, -0.02958963], dtype=float32),\n",
              " array([ 0.0291312 , -0.00513162, -0.04545954, ..., -0.02446766,\n",
              "         0.05896875, -0.03554822], dtype=float32),\n",
              " array([ 0.03111725,  0.00015977, -0.02500129, ..., -0.02016234,\n",
              "         0.03811267, -0.03040321], dtype=float32),\n",
              " array([ 0.01938361,  0.01494946,  0.00473798, ..., -0.02159997,\n",
              "         0.02398556, -0.02924501], dtype=float32),\n",
              " array([-0.0246855 ,  0.02073129,  0.01074105, ..., -0.02109256,\n",
              "         0.01692546, -0.02692734], dtype=float32),\n",
              " array([ 0.00044914,  0.00766875, -0.02552843, ..., -0.02136807,\n",
              "         0.00495932, -0.01809121], dtype=float32),\n",
              " array([ 0.06136264,  0.09708864, -0.05863184, ..., -0.04375355,\n",
              "        -0.01939002, -0.10486399], dtype=float32),\n",
              " array([ 0.02968939,  0.0491429 , -0.03975242, ..., -0.01562906,\n",
              "         0.01832324, -0.10607444], dtype=float32),\n",
              " array([ 0.00184151,  0.03189919, -0.02463225, ..., -0.00080787,\n",
              "         0.03001094, -0.0903011 ], dtype=float32),\n",
              " array([-0.02172176,  0.02616771, -0.01527611, ...,  0.00813368,\n",
              "         0.03162469, -0.07463001], dtype=float32),\n",
              " array([-0.0359154 ,  0.01597196, -0.01011447, ...,  0.00471815,\n",
              "         0.04948738, -0.0621075 ], dtype=float32),\n",
              " array([ 0.00438306,  0.00468076, -0.01413502, ...,  0.00059118,\n",
              "         0.06807762, -0.03822736], dtype=float32),\n",
              " array([-0.00295754,  0.00063765,  0.00878492, ..., -0.0049125 ,\n",
              "         0.0540928 , -0.02799899], dtype=float32),\n",
              " array([-0.00022358,  0.00984453,  0.01542566, ..., -0.00421635,\n",
              "         0.04131562, -0.02139954], dtype=float32),\n",
              " array([ 0.00170223, -0.02023253, -0.00092975, ..., -0.00473215,\n",
              "         0.02695179, -0.01756997], dtype=float32),\n",
              " array([ 0.01502124, -0.00144558, -0.01436352, ..., -0.002021  ,\n",
              "         0.02079759, -0.01479734], dtype=float32),\n",
              " array([ 0.00787524, -0.00595765, -0.00900622, ..., -0.01292994,\n",
              "         0.04657137, -0.00540669], dtype=float32),\n",
              " array([ 0.00409368, -0.00429447, -0.00601385, ..., -0.02749511,\n",
              "         0.05936769,  0.01030375], dtype=float32),\n",
              " array([ 0.00135138, -0.01276563, -0.00639786, ..., -0.02840912,\n",
              "         0.05289679,  0.01192701], dtype=float32),\n",
              " array([ 0.00561461,  0.00278312, -0.00170028, ..., -0.02507015,\n",
              "         0.04798386,  0.00474392], dtype=float32),\n",
              " array([-0.00719425,  0.00265344, -0.00573561, ..., -0.02959649,\n",
              "         0.0534521 ,  0.0036138 ], dtype=float32),\n",
              " array([ 0.00714187, -0.00265601, -0.01181976, ..., -0.0197415 ,\n",
              "         0.04495232, -0.0046462 ], dtype=float32),\n",
              " array([ 0.00115731, -0.03858896,  0.00506217, ..., -0.01301842,\n",
              "         0.04486704, -0.01088272], dtype=float32),\n",
              " array([-0.0011622 , -0.0345876 ,  0.00849287, ...,  0.00443428,\n",
              "         0.0177339 , -0.01570627], dtype=float32),\n",
              " array([-0.00108901, -0.05859235,  0.00058473, ...,  0.00835932,\n",
              "         0.00480177, -0.02204629], dtype=float32),\n",
              " array([ 0.00733904, -0.02647492, -0.00553633, ...,  0.00723327,\n",
              "         0.00977142, -0.03124988], dtype=float32),\n",
              " array([ 0.00875857,  0.00988073,  0.00527193, ...,  0.0001599 ,\n",
              "         0.04554661, -0.01249066], dtype=float32),\n",
              " array([ 0.01528681, -0.00644202, -0.00924073, ..., -0.01454812,\n",
              "         0.05177243,  0.00019942], dtype=float32),\n",
              " array([-0.0057161 , -0.05334428, -0.00022736, ..., -0.00106259,\n",
              "         0.02009697, -0.00629832], dtype=float32),\n",
              " array([-0.00490059, -0.03398036,  0.0019352 , ...,  0.00802615,\n",
              "        -0.00113821, -0.00930994], dtype=float32),\n",
              " array([-0.00215225, -0.03826834,  0.00112975, ...,  0.00889559,\n",
              "         0.00999851, -0.01498769], dtype=float32),\n",
              " array([-0.00021348, -0.03350717,  0.00038239, ...,  0.00700581,\n",
              "         0.03000374, -0.01039067], dtype=float32),\n",
              " array([0.00514878, 0.00695622, 0.00593793, ..., 0.00075159, 0.04364201,\n",
              "        0.00366554], dtype=float32),\n",
              " array([-0.00341142,  0.00921264,  0.00344456, ..., -0.00987235,\n",
              "         0.04564112,  0.01836883], dtype=float32),\n",
              " array([-0.00456372, -0.02084689, -0.00312549, ..., -0.0134708 ,\n",
              "         0.04206156,  0.01985717], dtype=float32),\n",
              " array([ 0.01094758, -0.02098296, -0.01472832, ..., -0.00314022,\n",
              "         0.04054623,  0.00715496], dtype=float32),\n",
              " array([-0.00163983, -0.0216052 , -0.00998707, ...,  0.00389097,\n",
              "         0.04228714,  0.00460188], dtype=float32),\n",
              " array([-0.00712759, -0.00440944, -0.01032739, ...,  0.00176134,\n",
              "         0.04330904,  0.00347494], dtype=float32),\n",
              " array([ 0.00885637,  0.00284483, -0.01726787, ...,  0.00213773,\n",
              "         0.04152386,  0.00116824], dtype=float32),\n",
              " array([ 0.00776867, -0.00084749, -0.01067429, ...,  0.00232814,\n",
              "         0.04174944, -0.00017919], dtype=float32),\n",
              " array([ 0.01149832,  0.00358302, -0.00799991, ...,  0.0055119 ,\n",
              "         0.04135181, -0.00667797], dtype=float32),\n",
              " array([ 0.00989879,  0.00362439, -0.00359206, ...,  0.00175072,\n",
              "         0.03411538,  0.01003507], dtype=float32),\n",
              " array([ 0.00171477,  0.00852994,  0.00341397, ...,  0.00830523,\n",
              "         0.03454932, -0.02201154], dtype=float32),\n",
              " array([-0.01796508,  0.01129939,  0.00767603, ...,  0.02061109,\n",
              "         0.03374029, -0.03983501], dtype=float32),\n",
              " array([ 0.00210583,  0.01682191,  0.02879588, ...,  0.02402825,\n",
              "         0.0296973 , -0.04432493], dtype=float32),\n",
              " array([ 0.03193408,  0.00952371, -0.00254795, ...,  0.01799949,\n",
              "         0.04247634, -0.01587625], dtype=float32),\n",
              " array([ 0.03286471,  0.00588725, -0.00913656, ...,  0.01284218,\n",
              "         0.04098851, -0.00983802], dtype=float32),\n",
              " array([ 0.01202349,  0.01416752,  0.00223731, ...,  0.01383841,\n",
              "         0.03968036, -0.00752262], dtype=float32),\n",
              " array([ 0.00381646,  0.01988034,  0.0280909 , ...,  0.01969432,\n",
              "         0.03775875, -0.02456759], dtype=float32),\n",
              " array([ 0.00168873,  0.01787941,  0.04335519, ...,  0.02220944,\n",
              "         0.02760105, -0.03541636], dtype=float32),\n",
              " array([ 0.00733832,  0.02460778,  0.03697754, ...,  0.02327105,\n",
              "         0.0256815 , -0.04068718], dtype=float32),\n",
              " array([-0.00818737,  0.02635692,  0.01749558, ...,  0.02457407,\n",
              "         0.01570274, -0.03527351], dtype=float32),\n",
              " array([-0.02877508,  0.02070775, -0.0119761 , ...,  0.02539027,\n",
              "         0.01124662, -0.0332608 ], dtype=float32),\n",
              " array([-0.02603615,  0.00088228, -0.02918503, ...,  0.01987205,\n",
              "         0.0400024 ,  0.00265455], dtype=float32),\n",
              " array([-0.02105253, -0.00025302, -0.02559434, ...,  0.00594687,\n",
              "         0.03888823,  0.01606396], dtype=float32),\n",
              " array([-0.01241946, -0.00203966, -0.02093942, ...,  0.00266041,\n",
              "         0.03851925,  0.01271347], dtype=float32),\n",
              " array([-0.00709532, -0.00319801, -0.01361746, ...,  0.00469177,\n",
              "         0.04006517,  0.0049051 ], dtype=float32),\n",
              " array([-0.00728418, -0.00334469, -0.00574204, ...,  0.00729141,\n",
              "         0.04149378, -0.00015822], dtype=float32),\n",
              " array([-0.00662477, -0.00468449, -0.00061506, ...,  0.00595308,\n",
              "         0.04029423,  0.00369744], dtype=float32),\n",
              " array([-0.00844373, -0.00495216,  0.00399851, ...,  0.00882306,\n",
              "         0.0411787 , -0.00879482], dtype=float32),\n",
              " array([-0.0102181 , -0.00522246,  0.00808985, ...,  0.01061748,\n",
              "         0.0423816 , -0.00743131], dtype=float32),\n",
              " array([-0.01072501, -0.00595746,  0.01047696, ...,  0.00940601,\n",
              "         0.04173073, -0.00580129], dtype=float32),\n",
              " array([-0.01296681, -0.00623677,  0.01320894, ...,  0.00865386,\n",
              "         0.04148625, -0.00762933], dtype=float32),\n",
              " array([-0.01357352, -0.00691848,  0.01462352, ...,  0.00763269,\n",
              "         0.0411902 , -0.0060827 ], dtype=float32),\n",
              " array([-0.01225014, -0.00743237,  0.01477834, ...,  0.00571807,\n",
              "         0.04030664, -0.003986  ], dtype=float32),\n",
              " array([-0.01152663, -0.00761409,  0.01525103, ...,  0.00465109,\n",
              "         0.03994972, -0.00532469], dtype=float32),\n",
              " array([-0.00963593, -0.00789342,  0.01514584, ...,  0.0039458 ,\n",
              "         0.03970588, -0.00489196], dtype=float32),\n",
              " array([ 0.02444346, -0.01071241,  0.00386782, ...,  0.00698568,\n",
              "         0.0418382 , -0.02120822], dtype=float32),\n",
              " array([ 0.01028646, -0.0063737 ,  0.01212008, ...,  0.00940164,\n",
              "         0.04325758, -0.01849391], dtype=float32),\n",
              " array([ 0.00329822, -0.00416652,  0.0190718 , ...,  0.00986769,\n",
              "         0.04406879, -0.02288676], dtype=float32),\n",
              " array([ 0.00136291, -0.00522156,  0.02063229, ...,  0.00918354,\n",
              "         0.04449373, -0.01930019], dtype=float32),\n",
              " array([ 0.0014206 , -0.00589374,  0.0193842 , ...,  0.00648631,\n",
              "         0.04379304, -0.01308805], dtype=float32),\n",
              " array([ 0.00266022, -0.00663523,  0.01668697, ...,  0.00566664,\n",
              "         0.04342016, -0.0166547 ], dtype=float32),\n",
              " array([ 0.00213893, -0.0063384 ,  0.01546522, ...,  0.00479528,\n",
              "         0.04377805, -0.01556344], dtype=float32),\n",
              " array([ 0.0025688 , -0.00619809,  0.01426142, ...,  0.00441895,\n",
              "         0.04395656, -0.01787053], dtype=float32),\n",
              " array([ 0.00363366, -0.00613718,  0.01256957, ...,  0.00390019,\n",
              "         0.04428229, -0.01764853], dtype=float32),\n",
              " array([ 0.00464255, -0.00600785,  0.01101067, ...,  0.00441978,\n",
              "         0.04398692, -0.02113567], dtype=float32),\n",
              " array([ 0.0059749 , -0.00588758,  0.00949957, ...,  0.00417144,\n",
              "         0.04473613, -0.02275585], dtype=float32),\n",
              " array([ 0.00927849, -0.00637259,  0.0083674 , ...,  0.0040345 ,\n",
              "         0.04536987, -0.02481987], dtype=float32),\n",
              " array([ 0.00579827, -0.00634558,  0.00913675, ...,  0.00320912,\n",
              "         0.04590345, -0.02328924], dtype=float32),\n",
              " array([ 0.00487442, -0.00615706,  0.00864227, ...,  0.01414484,\n",
              "         0.02944249, -0.02986049], dtype=float32),\n",
              " array([ 0.00072245, -0.00501218,  0.00971558, ...,  0.00427661,\n",
              "         0.0399636 , -0.00247115], dtype=float32),\n",
              " array([-0.0013493 , -0.00525815,  0.00775047, ..., -0.00385988,\n",
              "         0.03987853,  0.00131903], dtype=float32),\n",
              " array([ 0.00062461, -0.00583252,  0.00433566, ..., -0.00543962,\n",
              "         0.04032017, -0.00376884], dtype=float32),\n",
              " array([ 0.00131193, -0.00550253,  0.00266668, ..., -0.00493517,\n",
              "         0.04117248, -0.00816024], dtype=float32),\n",
              " array([ 0.00162347, -0.00479275,  0.00178055, ..., -0.00444707,\n",
              "         0.0417246 , -0.01083571], dtype=float32),\n",
              " array([ 0.0019761 , -0.00420481,  0.00142541, ..., -0.00323328,\n",
              "         0.04267706, -0.01683173], dtype=float32),\n",
              " array([ 0.00209192, -0.00370724,  0.00121887, ..., -0.00279591,\n",
              "         0.04308034, -0.01687667], dtype=float32),\n",
              " array([ 0.00234154, -0.00337651,  0.00089314, ..., -0.00254033,\n",
              "         0.04360224, -0.02057004], dtype=float32),\n",
              " array([ 0.0018645 , -0.00295204,  0.00102959, ..., -0.00332496,\n",
              "         0.04344992, -0.01786879], dtype=float32),\n",
              " array([ 0.00173127, -0.00273571,  0.00098601, ..., -0.00520001,\n",
              "         0.04252521, -0.01485601], dtype=float32),\n",
              " array([ 0.00154432, -0.00260866,  0.00082477, ..., -0.00499571,\n",
              "         0.04256263, -0.02055985], dtype=float32),\n",
              " array([-0.00181334, -0.00234611,  0.00275566, ...,  0.00640209,\n",
              "         0.03775096, -0.05174986], dtype=float32),\n",
              " array([ 0.00572898, -0.00316833, -0.00158812, ...,  0.0128495 ,\n",
              "         0.03004753, -0.03640328], dtype=float32),\n",
              " array([ 0.00127614, -0.00154822,  0.00046701, ...,  0.00947119,\n",
              "         0.03567095, -0.03361943], dtype=float32),\n",
              " array([ 0.00191871, -0.00126448,  0.00021799, ...,  0.00840537,\n",
              "         0.03977672, -0.02912349], dtype=float32),\n",
              " array([ 0.00113383, -0.00097831,  0.00122101, ...,  0.00786788,\n",
              "         0.04267547, -0.02620113], dtype=float32),\n",
              " array([ 0.00032092, -0.00108495,  0.00215776, ...,  0.00799979,\n",
              "         0.043823  , -0.02515565], dtype=float32),\n",
              " array([-0.0010794 , -0.00128323,  0.00276647, ...,  0.00794702,\n",
              "         0.04483781, -0.02511719], dtype=float32),\n",
              " array([-0.00106171, -0.00155352,  0.00240573, ...,  0.00795894,\n",
              "         0.04549531, -0.02590137], dtype=float32),\n",
              " array([-0.00238159, -0.00143247,  0.00286984, ...,  0.00798262,\n",
              "         0.04631108, -0.02709799], dtype=float32),\n",
              " array([-0.00324803, -0.00155369,  0.00322056, ...,  0.0081191 ,\n",
              "         0.04688947, -0.02845089], dtype=float32),\n",
              " array([-0.00462096,  0.00738914,  0.01362697, ..., -0.0108653 ,\n",
              "         0.0430215 ,  0.0264492 ], dtype=float32),\n",
              " array([ 0.01107714,  0.00065815, -0.01288132, ..., -0.01964096,\n",
              "         0.03325313,  0.02246061], dtype=float32),\n",
              " array([ 0.00018712,  0.00014788, -0.01043407, ..., -0.01642053,\n",
              "         0.03119858,  0.01386219], dtype=float32),\n",
              " array([ 0.00047698, -0.00125674, -0.00810501, ..., -0.0123728 ,\n",
              "         0.03130272,  0.00908789], dtype=float32),\n",
              " array([ 0.00011717, -0.04239557,  0.03033579, ..., -0.04160909,\n",
              "         0.01404621, -0.02577025], dtype=float32),\n",
              " array([ 0.00046652, -0.03092964,  0.02551107, ..., -0.04322926,\n",
              "         0.03439809,  0.00356406], dtype=float32),\n",
              " array([ 0.00185815, -0.02153757,  0.01909599, ..., -0.03415769,\n",
              "         0.03817194,  0.00477116], dtype=float32),\n",
              " array([ 0.00488387, -0.01629952,  0.01377237, ..., -0.02362682,\n",
              "         0.03829324,  0.00186898], dtype=float32),\n",
              " array([ 0.00637495, -0.01249764,  0.01061965, ..., -0.01616442,\n",
              "         0.03729777, -0.00181251], dtype=float32),\n",
              " array([ 0.006449  , -0.00980494,  0.00868039, ..., -0.0125247 ,\n",
              "         0.03598266, -0.00318465], dtype=float32),\n",
              " array([ 0.00654135, -0.00782045,  0.00726903, ..., -0.01045428,\n",
              "         0.03568076, -0.00602872], dtype=float32),\n",
              " array([ 0.00517408, -0.00604238,  0.00694172, ..., -0.01052649,\n",
              "         0.03488673, -0.00470082], dtype=float32),\n",
              " array([-0.00444865, -0.00086801,  0.01083292, ..., -0.00950808,\n",
              "         0.03557024, -0.00873087], dtype=float32),\n",
              " array([ 0.00763553, -0.0041983 ,  0.00024848, ..., -0.01011981,\n",
              "         0.03494963, -0.00409801], dtype=float32),\n",
              " array([ 0.00050795, -0.00262991,  0.00204145, ..., -0.01135065,\n",
              "         0.03389425, -0.00180285], dtype=float32),\n",
              " array([ 0.00095397, -0.0026138 ,  0.00142929, ..., -0.01258266,\n",
              "         0.03259025,  0.00177908], dtype=float32),\n",
              " array([ 0.00168096, -0.00253067,  0.00112224, ..., -0.01353151,\n",
              "         0.03169454,  0.00378363], dtype=float32),\n",
              " array([ 0.00164051, -0.00228651,  0.00142396, ..., -0.01470035,\n",
              "         0.03063343,  0.00716939], dtype=float32),\n",
              " array([ 0.00102705, -0.00197957,  0.00189324, ..., -0.01497767,\n",
              "         0.0303461 ,  0.00700024], dtype=float32),\n",
              " array([ 0.00111299, -0.00187862,  0.00207768, ..., -0.01526726,\n",
              "         0.02999237,  0.00904835], dtype=float32),\n",
              " array([-0.00032931, -0.00164671,  0.00246447, ..., -0.01552127,\n",
              "         0.02977435,  0.00975413], dtype=float32),\n",
              " array([ 0.00070907, -0.00179628,  0.00157323, ..., -0.01569039,\n",
              "         0.02947793,  0.01128036], dtype=float32),\n",
              " array([-0.00019019, -0.0015052 ,  0.00201306, ..., -0.01543787,\n",
              "         0.02939499,  0.01096256], dtype=float32),\n",
              " array([-0.00325511, -0.001124  ,  0.00330881, ..., -0.01546094,\n",
              "         0.02933609,  0.01219579], dtype=float32),\n",
              " array([-0.01389346,  0.00270419,  0.00743148, ..., -0.00510664,\n",
              "         0.03770145, -0.04664279], dtype=float32),\n",
              " array([ 0.00468268,  0.00527665, -0.00848733, ...,  0.00581621,\n",
              "         0.03583543, -0.05194993], dtype=float32),\n",
              " array([ 0.06376024,  0.00774101, -0.04074608, ...,  0.00057164,\n",
              "         0.04175463, -0.0270682 ], dtype=float32),\n",
              " array([ 0.05737329,  0.02197134, -0.00214859, ..., -0.00194785,\n",
              "         0.04110241, -0.02598581], dtype=float32),\n",
              " array([ 0.0579685 ,  0.01868162, -0.02204759, ...,  0.00392528,\n",
              "         0.03497874, -0.02332017], dtype=float32),\n",
              " array([ 0.01322307,  0.00151347,  0.0012226 , ...,  0.00229209,\n",
              "         0.03818894, -0.02218586], dtype=float32),\n",
              " array([ 0.01505876, -0.00063246,  0.01174657, ...,  0.00023268,\n",
              "         0.04050197, -0.02292976], dtype=float32),\n",
              " array([ 0.06733892, -0.00527231, -0.00917961, ..., -0.00383422,\n",
              "         0.04848852, -0.01921012], dtype=float32),\n",
              " array([ 0.04748187, -0.00029087,  0.04202306, ..., -0.00450476,\n",
              "         0.04813118, -0.01968068], dtype=float32),\n",
              " array([ 0.01703245, -0.0045278 ,  0.02764127, ..., -0.00231867,\n",
              "         0.04564674, -0.03541972], dtype=float32),\n",
              " array([ 0.05600198, -0.00854114,  0.00899389, ...,  0.00539775,\n",
              "         0.03177442, -0.0195891 ], dtype=float32),\n",
              " array([ 0.01409847,  0.00869711,  0.04259818, ..., -0.00099042,\n",
              "         0.04311294, -0.02876683], dtype=float32),\n",
              " array([ 0.04287379,  0.00105645,  0.00814484, ...,  0.00104891,\n",
              "         0.04494514, -0.03023425], dtype=float32),\n",
              " array([ 0.00590084, -0.00094676,  0.04997515, ..., -0.00394838,\n",
              "         0.05161593, -0.02422154], dtype=float32),\n",
              " array([ 0.01159085,  0.02244407,  0.03145135, ...,  0.00596932,\n",
              "         0.03772788, -0.03249499], dtype=float32),\n",
              " array([ 0.04219774,  0.01324393, -0.01173312, ...,  0.00661513,\n",
              "         0.0327707 , -0.03075368], dtype=float32),\n",
              " array([ 0.00706478,  0.01194019,  0.00062022, ...,  0.0015426 ,\n",
              "         0.04991176, -0.04013532], dtype=float32),\n",
              " array([ 0.02727194, -0.00662385, -0.01624301, ...,  0.00455356,\n",
              "         0.04481879, -0.03581842], dtype=float32),\n",
              " array([ 0.03903883, -0.02542646, -0.02873087, ..., -0.00376571,\n",
              "         0.06048806, -0.03941658], dtype=float32),\n",
              " array([ 0.05684528,  0.00755141,  0.00583833, ...,  0.00079012,\n",
              "         0.05835494, -0.04684841], dtype=float32),\n",
              " array([ 0.06639268,  0.00125219, -0.01750879, ...,  0.00337949,\n",
              "         0.04923135, -0.05119607], dtype=float32),\n",
              " array([ 0.02329039, -0.00807297,  0.01818269, ..., -0.00612194,\n",
              "         0.05948202, -0.05677628], dtype=float32),\n",
              " array([ 0.01012269, -0.01135355,  0.02219014, ..., -0.00844116,\n",
              "         0.05974447, -0.05148653], dtype=float32),\n",
              " array([ 0.03767681, -0.02126494,  0.00168964, ..., -0.01751078,\n",
              "         0.06424358, -0.05212755], dtype=float32),\n",
              " array([ 0.03111609, -0.02436608,  0.04550528, ..., -0.02762675,\n",
              "         0.07795553, -0.0442843 ], dtype=float32),\n",
              " array([-0.00280384, -0.02920688,  0.03805357, ..., -0.01737156,\n",
              "         0.06744969, -0.05011446], dtype=float32),\n",
              " array([ 0.01615823,  0.00714868,  0.04250434, ..., -0.03385456,\n",
              "         0.08680432, -0.04353292], dtype=float32),\n",
              " array([ 0.06317177,  0.00596267, -0.02812545, ..., -0.02564606,\n",
              "         0.07705153, -0.04875105], dtype=float32),\n",
              " array([ 0.03601613, -0.01368399,  0.05779376, ..., -0.03384287,\n",
              "         0.08349024, -0.05277198], dtype=float32),\n",
              " array([ 0.04827546,  0.01544226,  0.07228257, ..., -0.02721754,\n",
              "         0.07044638, -0.0516072 ], dtype=float32),\n",
              " array([ 0.00509728,  0.0175717 ,  0.04205596, ..., -0.0491821 ,\n",
              "         0.04359038, -0.03222722], dtype=float32),\n",
              " array([ 0.04820119,  0.0011659 , -0.03147766, ..., -0.04544488,\n",
              "         0.03930085, -0.0395517 ], dtype=float32),\n",
              " array([ 0.04372012, -0.02555355,  0.05728049, ..., -0.07129105,\n",
              "         0.07616107, -0.02348798], dtype=float32),\n",
              " array([ 0.04023276, -0.01543653, -0.00492001, ..., -0.04623817,\n",
              "         0.06766618, -0.02916354], dtype=float32),\n",
              " array([ 0.03219847, -0.00966554,  0.05521337, ..., -0.02719746,\n",
              "         0.04268619, -0.02900286], dtype=float32),\n",
              " array([ 0.0359671 , -0.00274686,  0.00078236, ..., -0.05296438,\n",
              "         0.06905479, -0.03578736], dtype=float32),\n",
              " array([ 0.0146315 ,  0.00403661,  0.02342811, ..., -0.06217757,\n",
              "         0.07777671, -0.01526794], dtype=float32),\n",
              " array([ 0.02816964, -0.0150281 , -0.00413035, ..., -0.03816061,\n",
              "         0.05126093, -0.02784019], dtype=float32),\n",
              " array([ 0.00619547, -0.00138607,  0.00946645, ..., -0.02968549,\n",
              "         0.02729401, -0.0289382 ], dtype=float32),\n",
              " array([ 0.00330835, -0.06418017, -0.00199975, ..., -0.04278648,\n",
              "         0.05590503, -0.02276443], dtype=float32),\n",
              " array([ 0.01583279, -0.01856597, -0.02117233, ..., -0.03349029,\n",
              "         0.06118138, -0.0205416 ], dtype=float32),\n",
              " array([ 0.01298719,  0.01492143,  0.0064445 , ..., -0.02586119,\n",
              "         0.03462205, -0.01757667], dtype=float32),\n",
              " array([ 0.01716786, -0.00232845, -0.00795388, ..., -0.02611213,\n",
              "         0.03842148, -0.01747211], dtype=float32),\n",
              " array([-0.00919985, -0.01690444,  0.00615702, ..., -0.03208137,\n",
              "         0.05450288, -0.0029585 ], dtype=float32),\n",
              " array([-0.00107915, -0.05015199,  0.00082221, ..., -0.01727545,\n",
              "        -0.00180336,  0.00205559], dtype=float32),\n",
              " array([-0.00350131, -0.02052804,  0.00849414, ..., -0.01091434,\n",
              "        -0.02583745, -0.00693325], dtype=float32),\n",
              " array([-0.001937  , -0.05001781,  0.00522139, ..., -0.01458545,\n",
              "        -0.00617106, -0.01734798], dtype=float32),\n",
              " array([ 0.01016869,  0.01699398,  0.01922599, ..., -0.0248806 ,\n",
              "         0.03082449,  0.00588136], dtype=float32),\n",
              " array([ 0.02307734,  0.01942584,  0.03738705, ..., -0.01758265,\n",
              "         0.02069802,  0.00674249], dtype=float32),\n",
              " array([ 0.02084719,  0.03509016,  0.01675322, ..., -0.02787391,\n",
              "         0.03435465,  0.01331642], dtype=float32),\n",
              " array([ 0.01890521,  0.02598076, -0.03138741, ..., -0.03262709,\n",
              "         0.04354531,  0.01903722], dtype=float32),\n",
              " array([ 0.02246285,  0.01543181, -0.0433135 , ..., -0.0329072 ,\n",
              "         0.04912542,  0.02439616], dtype=float32),\n",
              " array([ 0.01614094,  0.00869218, -0.02245024, ..., -0.02741919,\n",
              "         0.04972623,  0.02567304], dtype=float32),\n",
              " array([-0.00428839,  0.0229449 , -0.01417672, ..., -0.01291967,\n",
              "         0.03033372,  0.00867883], dtype=float32),\n",
              " array([-0.0100335 ,  0.01560117, -0.00118645, ..., -0.0031869 ,\n",
              "         0.00355455,  0.00240153], dtype=float32),\n",
              " array([ 0.00631784,  0.03138718,  0.00210895, ...,  0.00324367,\n",
              "        -0.02065724,  0.00025768], dtype=float32),\n",
              " array([ 0.01812219,  0.01890286,  0.00871559, ..., -0.00646725,\n",
              "         0.02016766, -0.00879239], dtype=float32),\n",
              " array([ 0.00596067,  0.0131707 , -0.01876796, ..., -0.01180857,\n",
              "         0.04123345,  0.009525  ], dtype=float32),\n",
              " array([ 0.02240164,  0.00836863, -0.03430331, ..., -0.01797002,\n",
              "         0.04785888,  0.02108513], dtype=float32),\n",
              " array([ 0.01929234, -0.00110052, -0.0175014 , ..., -0.00590045,\n",
              "         0.0298814 ,  0.01006284], dtype=float32),\n",
              " array([-0.00413541, -0.01150101, -0.00515864, ...,  0.00573175,\n",
              "         0.00882158,  0.00174996], dtype=float32),\n",
              " array([ 0.02179233,  0.01300286,  0.02286266, ...,  0.00636279,\n",
              "        -0.00677912, -0.00781336], dtype=float32),\n",
              " array([ 0.0269844 ,  0.02065335,  0.027968  , ...,  0.00812123,\n",
              "        -0.02457594, -0.00955162], dtype=float32),\n",
              " array([ 0.00133266,  0.02700074, -0.0045928 , ...,  0.00721394,\n",
              "         0.00229019, -0.01166828], dtype=float32),\n",
              " array([ 0.03241688, -0.00186442, -0.04004336, ...,  0.00767271,\n",
              "        -0.01714273, -0.00929833], dtype=float32),\n",
              " array([ 0.01780999, -0.01621151,  0.01389056, ...,  0.00937525,\n",
              "        -0.03209655, -0.00886732], dtype=float32),\n",
              " array([ 0.0146573 ,  0.03199384,  0.00714944, ...,  0.0068812 ,\n",
              "        -0.05550847, -0.0054187 ], dtype=float32),\n",
              " array([ 0.01134648,  0.00941891, -0.01475485, ...,  0.00581098,\n",
              "        -0.05677775, -0.01198356], dtype=float32),\n",
              " array([ 0.02489479,  0.01024411, -0.03092253, ...,  0.00734409,\n",
              "        -0.07628193, -0.00194873], dtype=float32),\n",
              " array([ 0.0254194 ,  0.00761285, -0.0194992 , ...,  0.00477802,\n",
              "        -0.06336012, -0.01704658], dtype=float32),\n",
              " array([-0.01225646, -0.00524135, -0.00727809, ...,  0.00116301,\n",
              "        -0.01087607, -0.015283  ], dtype=float32),\n",
              " array([-0.00862256, -0.00469636, -0.00184941, ..., -0.00024951,\n",
              "         0.0125728 ,  0.00698665], dtype=float32),\n",
              " array([-0.00031692, -0.00472497,  0.00026196, ..., -0.0064228 ,\n",
              "         0.0255142 ,  0.02240133], dtype=float32),\n",
              " array([ 0.00476735, -0.00411111,  0.00061918, ..., -0.01077055,\n",
              "         0.02924124,  0.02705024], dtype=float32),\n",
              " array([ 0.00686799, -0.0027629 ,  0.00059535, ..., -0.01326103,\n",
              "         0.0322812 ,  0.02565242], dtype=float32),\n",
              " array([ 0.00745541, -0.00128283,  0.00064475, ..., -0.01125877,\n",
              "         0.03366109,  0.01936367], dtype=float32),\n",
              " array([ 0.00725125,  0.00040479,  0.0011549 , ..., -0.00887286,\n",
              "         0.03665122,  0.01489637], dtype=float32),\n",
              " array([ 0.00678211,  0.00157665,  0.00155034, ..., -0.00462575,\n",
              "         0.03824435,  0.00875189], dtype=float32),\n",
              " array([ 0.00588425,  0.00276776,  0.00217966, ..., -0.00054513,\n",
              "         0.04000001,  0.00429867], dtype=float32),\n",
              " array([ 4.8900819e-03,  3.6178150e-03,  2.6640175e-03, ...,\n",
              "         3.2315676e-03,  4.1028723e-02, -5.4212014e-05], dtype=float32),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6AtswwMA0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a072387c-e1d1-4a97-c4e8-539c513866a5"
      },
      "source": [
        "train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7347</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7348</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7349</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7350</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7351</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7352 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label\n",
              "0         5\n",
              "1         5\n",
              "2         5\n",
              "3         5\n",
              "4         5\n",
              "...     ...\n",
              "7347      2\n",
              "7348      2\n",
              "7349      2\n",
              "7350      2\n",
              "7351      2\n",
              "\n",
              "[7352 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EswTTenw0LGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './file.pt'\n",
        "torch.save({\n",
        "            'epoch': 200,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "\n",
        "            }, PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSkQ6WA-np-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "47a94693-23c8-47b2-8129-2fb3df492004"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42, C = 0.5, kernel = 'linear')\n",
        "params = {\n",
        "    #'C' : [0.05, 0.5,1,10], 'kernel':['rbf','linear'], 'decision_function_shape':['ova','ovr']\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(np.array(new_train), np.array(train_y[:-52]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=0.5, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='linear', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HxbBkSV88ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  new_test, _=  model(test_D.to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh8jXE3In2_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test = np.array(new_test.cpu())#np.resize(new_test, (2996,128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ONZfVfn6-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = cv.predict(new_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H83fo7arn7_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5d8d844b-77a0-4343-e460-80140b8b88f1"
      },
      "source": [
        "print(classification_report(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.97      0.98       509\n",
            "           2       0.99      0.97      0.98       483\n",
            "           3       0.92      0.98      0.95       397\n",
            "           4       0.93      0.94      0.94       486\n",
            "           5       0.94      0.94      0.94       535\n",
            "           6       1.00      1.00      1.00       537\n",
            "\n",
            "    accuracy                           0.96      2947\n",
            "   macro avg       0.96      0.96      0.96      2947\n",
            "weighted avg       0.96      0.96      0.96      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDrMrswDn94u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e02c144a-3768-4357-8db5-687195fc0ab1"
      },
      "source": [
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"LSTM_SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM_SVM : 0.9613165931455717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va9qRoUb7NNs",
        "colab_type": "text"
      },
      "source": [
        "#bi-LSTM + SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dbLWt4CTXT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(train_L.shape[1], True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J2ubgicTaeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWwEzMd0TdZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "35278ce9-6eaa-40f5-e000-99043dc74298"
      },
      "source": [
        "running_loss = 0\n",
        "epoch = 200\n",
        "new_train = []\n",
        "for e in range(epoch+1):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    new_t, h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss  += loss.item()\n",
        "    if e == epoch:\n",
        "      new_train.extend(new_t.cpu().detach().numpy())\n",
        "  if (e) % 10 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss = 0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] loss : 0.081\n",
            "[10] loss : 0.393\n",
            "[20] loss : 0.205\n",
            "[30] loss : 0.161\n",
            "[40] loss : 0.139\n",
            "[50] loss : 0.124\n",
            "[60] loss : 0.112\n",
            "[70] loss : 0.108\n",
            "[80] loss : 0.096\n",
            "[90] loss : 0.093\n",
            "[100] loss : 0.087\n",
            "[110] loss : 0.082\n",
            "[120] loss : 0.079\n",
            "[130] loss : 0.074\n",
            "[140] loss : 0.074\n",
            "[150] loss : 0.071\n",
            "[160] loss : 0.066\n",
            "[170] loss : 0.068\n",
            "[180] loss : 0.063\n",
            "[190] loss : 0.063\n",
            "[200] loss : 0.063\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7eB2r9pVE_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99b19936-3663-4c0f-a994-02cefc04b3b7"
      },
      "source": [
        "np.array(new_train).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7300, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WMv2ueCTiXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "cdab802f-6f07-4082-f68a-b9396a7e14a0"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42, C = 0.5, kernel = 'linear')\n",
        "params = {\n",
        "    #'C' : [0.05, 0.5,1,10], 'kernel':['rbf','linear'], 'decision_function_shape':['ova','ovr']\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(np.array(new_train), np.array(train_y[:-52]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=0.5, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='linear', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JhxnAZ5TzDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  new_test, _=  model(test_D.to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wApbRHDZT1BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test = np.array(new_test.cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvtiYCUzT2zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = cv.predict(new_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zZBFFbBT4sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "473c3336-4145-43a7-89e0-4581a92c59ce"
      },
      "source": [
        "print(classification_report(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.95      0.94       487\n",
            "           2       0.90      0.93      0.92       460\n",
            "           3       0.89      0.85      0.87       438\n",
            "           4       0.95      0.87      0.91       535\n",
            "           5       0.87      0.94      0.90       490\n",
            "           6       1.00      1.00      1.00       537\n",
            "\n",
            "    accuracy                           0.93      2947\n",
            "   macro avg       0.92      0.92      0.92      2947\n",
            "weighted avg       0.93      0.93      0.92      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1HCH3uT6TS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49792449-ff4e-44fc-e2e4-40f76d7b53e5"
      },
      "source": [
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"bi-LSTM_SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bi-LSTM_SVM : 0.9250084832032576\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}