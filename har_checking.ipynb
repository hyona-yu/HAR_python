{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "har_checking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQjJ6fc26m3Fk2lHMixReR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyona-yu/HAR_python/blob/master/har_checking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNv8R2035Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoO-AWGAh4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! git clone https://github.com/hyona-yu/Dataset.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGBB8lUHFrfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'Dataset/UCI HAR Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3unIx-ms4Hqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name_df = pd.read_csv(url + 'features.txt', sep='\\s+', header=None, \n",
        "                              names=['column_index','column_name'])\n",
        "\n",
        "feature_name = feature_name_df.iloc[:,1].values.tolist()\n",
        "train_csv = pd.read_csv(url + 'train/X_train.txt', sep ='\\s+', header = None)\n",
        "train_csv.columns = feature_name\n",
        "test_csv = pd.read_csv(url + 'test/X_test.txt', sep = '\\s+', header= None)\n",
        "test_csv.columns = feature_name\n",
        "train_y = pd.read_csv(url + 'train/y_train.txt', header = None, names= ['label'])\n",
        "test_y =pd.read_csv(url + 'test/y_test.txt', header =None, names= ['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaxBTuP85JXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "f8df85cd-ee2d-45e1-84ab-1c549a69e9e9"
      },
      "source": [
        "train_csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-energy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.288585</td>\n",
              "      <td>-0.020294</td>\n",
              "      <td>-0.132905</td>\n",
              "      <td>-0.995279</td>\n",
              "      <td>-0.983111</td>\n",
              "      <td>-0.913526</td>\n",
              "      <td>-0.995112</td>\n",
              "      <td>-0.983185</td>\n",
              "      <td>-0.923527</td>\n",
              "      <td>-0.934724</td>\n",
              "      <td>-0.567378</td>\n",
              "      <td>-0.744413</td>\n",
              "      <td>0.852947</td>\n",
              "      <td>0.685845</td>\n",
              "      <td>0.814263</td>\n",
              "      <td>-0.965523</td>\n",
              "      <td>-0.999945</td>\n",
              "      <td>-0.999863</td>\n",
              "      <td>-0.994612</td>\n",
              "      <td>-0.994231</td>\n",
              "      <td>-0.987614</td>\n",
              "      <td>-0.943220</td>\n",
              "      <td>-0.407747</td>\n",
              "      <td>-0.679338</td>\n",
              "      <td>-0.602122</td>\n",
              "      <td>0.929294</td>\n",
              "      <td>-0.853011</td>\n",
              "      <td>0.359910</td>\n",
              "      <td>-0.058526</td>\n",
              "      <td>0.256892</td>\n",
              "      <td>-0.224848</td>\n",
              "      <td>0.264106</td>\n",
              "      <td>-0.095246</td>\n",
              "      <td>0.278851</td>\n",
              "      <td>-0.465085</td>\n",
              "      <td>0.491936</td>\n",
              "      <td>-0.190884</td>\n",
              "      <td>0.376314</td>\n",
              "      <td>0.435129</td>\n",
              "      <td>0.660790</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999918</td>\n",
              "      <td>-0.991364</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.346989</td>\n",
              "      <td>-0.516080</td>\n",
              "      <td>-0.802760</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.961309</td>\n",
              "      <td>-0.973653</td>\n",
              "      <td>-0.952264</td>\n",
              "      <td>-0.989498</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.999240</td>\n",
              "      <td>-0.992656</td>\n",
              "      <td>-0.701291</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.128989</td>\n",
              "      <td>0.586156</td>\n",
              "      <td>0.374605</td>\n",
              "      <td>-0.991990</td>\n",
              "      <td>-0.990697</td>\n",
              "      <td>-0.989941</td>\n",
              "      <td>-0.992448</td>\n",
              "      <td>-0.991048</td>\n",
              "      <td>-0.991990</td>\n",
              "      <td>-0.999937</td>\n",
              "      <td>-0.990458</td>\n",
              "      <td>-0.871306</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.074323</td>\n",
              "      <td>-0.298676</td>\n",
              "      <td>-0.710304</td>\n",
              "      <td>-0.112754</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>-0.464761</td>\n",
              "      <td>-0.018446</td>\n",
              "      <td>-0.841247</td>\n",
              "      <td>0.179941</td>\n",
              "      <td>-0.058627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.278419</td>\n",
              "      <td>-0.016411</td>\n",
              "      <td>-0.123520</td>\n",
              "      <td>-0.998245</td>\n",
              "      <td>-0.975300</td>\n",
              "      <td>-0.960322</td>\n",
              "      <td>-0.998807</td>\n",
              "      <td>-0.974914</td>\n",
              "      <td>-0.957686</td>\n",
              "      <td>-0.943068</td>\n",
              "      <td>-0.557851</td>\n",
              "      <td>-0.818409</td>\n",
              "      <td>0.849308</td>\n",
              "      <td>0.685845</td>\n",
              "      <td>0.822637</td>\n",
              "      <td>-0.981930</td>\n",
              "      <td>-0.999991</td>\n",
              "      <td>-0.999788</td>\n",
              "      <td>-0.998405</td>\n",
              "      <td>-0.999150</td>\n",
              "      <td>-0.977866</td>\n",
              "      <td>-0.948225</td>\n",
              "      <td>-0.714892</td>\n",
              "      <td>-0.500930</td>\n",
              "      <td>-0.570979</td>\n",
              "      <td>0.611627</td>\n",
              "      <td>-0.329549</td>\n",
              "      <td>0.284213</td>\n",
              "      <td>0.284595</td>\n",
              "      <td>0.115705</td>\n",
              "      <td>-0.090963</td>\n",
              "      <td>0.294310</td>\n",
              "      <td>-0.281211</td>\n",
              "      <td>0.085988</td>\n",
              "      <td>-0.022153</td>\n",
              "      <td>-0.016657</td>\n",
              "      <td>-0.220643</td>\n",
              "      <td>-0.013429</td>\n",
              "      <td>-0.072692</td>\n",
              "      <td>0.579382</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999867</td>\n",
              "      <td>-0.991134</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.532061</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.900160</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.983322</td>\n",
              "      <td>-0.982659</td>\n",
              "      <td>-0.986321</td>\n",
              "      <td>-0.991829</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.999811</td>\n",
              "      <td>-0.993979</td>\n",
              "      <td>-0.720683</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.271958</td>\n",
              "      <td>-0.336310</td>\n",
              "      <td>-0.720015</td>\n",
              "      <td>-0.995854</td>\n",
              "      <td>-0.996399</td>\n",
              "      <td>-0.995442</td>\n",
              "      <td>-0.996866</td>\n",
              "      <td>-0.994440</td>\n",
              "      <td>-0.995854</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.994544</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.158075</td>\n",
              "      <td>-0.595051</td>\n",
              "      <td>-0.861499</td>\n",
              "      <td>0.053477</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>-0.732626</td>\n",
              "      <td>0.703511</td>\n",
              "      <td>-0.844788</td>\n",
              "      <td>0.180289</td>\n",
              "      <td>-0.054317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.279653</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.113462</td>\n",
              "      <td>-0.995380</td>\n",
              "      <td>-0.967187</td>\n",
              "      <td>-0.978944</td>\n",
              "      <td>-0.996520</td>\n",
              "      <td>-0.963668</td>\n",
              "      <td>-0.977469</td>\n",
              "      <td>-0.938692</td>\n",
              "      <td>-0.557851</td>\n",
              "      <td>-0.818409</td>\n",
              "      <td>0.843609</td>\n",
              "      <td>0.682401</td>\n",
              "      <td>0.839344</td>\n",
              "      <td>-0.983478</td>\n",
              "      <td>-0.999969</td>\n",
              "      <td>-0.999660</td>\n",
              "      <td>-0.999470</td>\n",
              "      <td>-0.997130</td>\n",
              "      <td>-0.964810</td>\n",
              "      <td>-0.974675</td>\n",
              "      <td>-0.592235</td>\n",
              "      <td>-0.485821</td>\n",
              "      <td>-0.570979</td>\n",
              "      <td>0.273025</td>\n",
              "      <td>-0.086309</td>\n",
              "      <td>0.337202</td>\n",
              "      <td>-0.164739</td>\n",
              "      <td>0.017150</td>\n",
              "      <td>-0.074507</td>\n",
              "      <td>0.342256</td>\n",
              "      <td>-0.332564</td>\n",
              "      <td>0.239281</td>\n",
              "      <td>-0.136204</td>\n",
              "      <td>0.173863</td>\n",
              "      <td>-0.299493</td>\n",
              "      <td>-0.124698</td>\n",
              "      <td>-0.181105</td>\n",
              "      <td>0.608900</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999845</td>\n",
              "      <td>-0.986658</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.660795</td>\n",
              "      <td>-0.724697</td>\n",
              "      <td>-0.928539</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.986028</td>\n",
              "      <td>-0.984274</td>\n",
              "      <td>-0.990979</td>\n",
              "      <td>-0.995703</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.999854</td>\n",
              "      <td>-0.993238</td>\n",
              "      <td>-0.736521</td>\n",
              "      <td>-0.794872</td>\n",
              "      <td>-0.212728</td>\n",
              "      <td>-0.535352</td>\n",
              "      <td>-0.871914</td>\n",
              "      <td>-0.995031</td>\n",
              "      <td>-0.995127</td>\n",
              "      <td>-0.994640</td>\n",
              "      <td>-0.996060</td>\n",
              "      <td>-0.995866</td>\n",
              "      <td>-0.995031</td>\n",
              "      <td>-0.999973</td>\n",
              "      <td>-0.993755</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>0.414503</td>\n",
              "      <td>-0.390748</td>\n",
              "      <td>-0.760104</td>\n",
              "      <td>-0.118559</td>\n",
              "      <td>0.177899</td>\n",
              "      <td>0.100699</td>\n",
              "      <td>0.808529</td>\n",
              "      <td>-0.848933</td>\n",
              "      <td>0.180637</td>\n",
              "      <td>-0.049118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.279174</td>\n",
              "      <td>-0.026201</td>\n",
              "      <td>-0.123283</td>\n",
              "      <td>-0.996091</td>\n",
              "      <td>-0.983403</td>\n",
              "      <td>-0.990675</td>\n",
              "      <td>-0.997099</td>\n",
              "      <td>-0.982750</td>\n",
              "      <td>-0.989302</td>\n",
              "      <td>-0.938692</td>\n",
              "      <td>-0.576159</td>\n",
              "      <td>-0.829711</td>\n",
              "      <td>0.843609</td>\n",
              "      <td>0.682401</td>\n",
              "      <td>0.837869</td>\n",
              "      <td>-0.986093</td>\n",
              "      <td>-0.999976</td>\n",
              "      <td>-0.999736</td>\n",
              "      <td>-0.999504</td>\n",
              "      <td>-0.997180</td>\n",
              "      <td>-0.983799</td>\n",
              "      <td>-0.986007</td>\n",
              "      <td>-0.627446</td>\n",
              "      <td>-0.850930</td>\n",
              "      <td>-0.911872</td>\n",
              "      <td>0.061436</td>\n",
              "      <td>0.074840</td>\n",
              "      <td>0.198204</td>\n",
              "      <td>-0.264307</td>\n",
              "      <td>0.072545</td>\n",
              "      <td>-0.155320</td>\n",
              "      <td>0.323154</td>\n",
              "      <td>-0.170813</td>\n",
              "      <td>0.294938</td>\n",
              "      <td>-0.306081</td>\n",
              "      <td>0.482148</td>\n",
              "      <td>-0.470129</td>\n",
              "      <td>-0.305693</td>\n",
              "      <td>-0.362654</td>\n",
              "      <td>0.507459</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999895</td>\n",
              "      <td>-0.988055</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.678921</td>\n",
              "      <td>-0.701131</td>\n",
              "      <td>-0.909639</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.987836</td>\n",
              "      <td>-0.986850</td>\n",
              "      <td>-0.986749</td>\n",
              "      <td>-0.996199</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.999876</td>\n",
              "      <td>-0.989136</td>\n",
              "      <td>-0.720891</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.035684</td>\n",
              "      <td>-0.230091</td>\n",
              "      <td>-0.511217</td>\n",
              "      <td>-0.995221</td>\n",
              "      <td>-0.995237</td>\n",
              "      <td>-0.995722</td>\n",
              "      <td>-0.995273</td>\n",
              "      <td>-0.995732</td>\n",
              "      <td>-0.995221</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995226</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.404573</td>\n",
              "      <td>-0.117290</td>\n",
              "      <td>-0.482845</td>\n",
              "      <td>-0.036788</td>\n",
              "      <td>-0.012892</td>\n",
              "      <td>0.640011</td>\n",
              "      <td>-0.485366</td>\n",
              "      <td>-0.848649</td>\n",
              "      <td>0.181935</td>\n",
              "      <td>-0.047663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.276629</td>\n",
              "      <td>-0.016570</td>\n",
              "      <td>-0.115362</td>\n",
              "      <td>-0.998139</td>\n",
              "      <td>-0.980817</td>\n",
              "      <td>-0.990482</td>\n",
              "      <td>-0.998321</td>\n",
              "      <td>-0.979672</td>\n",
              "      <td>-0.990441</td>\n",
              "      <td>-0.942469</td>\n",
              "      <td>-0.569174</td>\n",
              "      <td>-0.824705</td>\n",
              "      <td>0.849095</td>\n",
              "      <td>0.683250</td>\n",
              "      <td>0.837869</td>\n",
              "      <td>-0.992653</td>\n",
              "      <td>-0.999991</td>\n",
              "      <td>-0.999856</td>\n",
              "      <td>-0.999757</td>\n",
              "      <td>-0.998004</td>\n",
              "      <td>-0.981232</td>\n",
              "      <td>-0.991325</td>\n",
              "      <td>-0.786553</td>\n",
              "      <td>-0.559477</td>\n",
              "      <td>-0.761434</td>\n",
              "      <td>0.313276</td>\n",
              "      <td>-0.131208</td>\n",
              "      <td>0.191161</td>\n",
              "      <td>0.086904</td>\n",
              "      <td>0.257615</td>\n",
              "      <td>-0.272505</td>\n",
              "      <td>0.434728</td>\n",
              "      <td>-0.315375</td>\n",
              "      <td>0.439744</td>\n",
              "      <td>-0.269069</td>\n",
              "      <td>0.179414</td>\n",
              "      <td>-0.088952</td>\n",
              "      <td>-0.155804</td>\n",
              "      <td>-0.189763</td>\n",
              "      <td>0.599213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999941</td>\n",
              "      <td>-0.994169</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.559058</td>\n",
              "      <td>-0.528901</td>\n",
              "      <td>-0.858933</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.989059</td>\n",
              "      <td>-0.987744</td>\n",
              "      <td>-0.991462</td>\n",
              "      <td>-0.998353</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.999902</td>\n",
              "      <td>-0.989321</td>\n",
              "      <td>-0.763372</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.273582</td>\n",
              "      <td>-0.510282</td>\n",
              "      <td>-0.830702</td>\n",
              "      <td>-0.995093</td>\n",
              "      <td>-0.995465</td>\n",
              "      <td>-0.995279</td>\n",
              "      <td>-0.995609</td>\n",
              "      <td>-0.997418</td>\n",
              "      <td>-0.995093</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995487</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.087753</td>\n",
              "      <td>-0.351471</td>\n",
              "      <td>-0.699205</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>0.122542</td>\n",
              "      <td>0.693578</td>\n",
              "      <td>-0.615971</td>\n",
              "      <td>-0.847865</td>\n",
              "      <td>0.185151</td>\n",
              "      <td>-0.043892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7347</th>\n",
              "      <td>0.299665</td>\n",
              "      <td>-0.057193</td>\n",
              "      <td>-0.181233</td>\n",
              "      <td>-0.195387</td>\n",
              "      <td>0.039905</td>\n",
              "      <td>0.077078</td>\n",
              "      <td>-0.282301</td>\n",
              "      <td>0.043616</td>\n",
              "      <td>0.060410</td>\n",
              "      <td>0.210795</td>\n",
              "      <td>0.029369</td>\n",
              "      <td>-0.076700</td>\n",
              "      <td>0.273480</td>\n",
              "      <td>0.186626</td>\n",
              "      <td>0.266917</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>-0.674986</td>\n",
              "      <td>-0.788077</td>\n",
              "      <td>-0.473463</td>\n",
              "      <td>-0.501092</td>\n",
              "      <td>-0.166197</td>\n",
              "      <td>0.034015</td>\n",
              "      <td>0.195643</td>\n",
              "      <td>0.140158</td>\n",
              "      <td>-0.082077</td>\n",
              "      <td>-0.561607</td>\n",
              "      <td>0.426433</td>\n",
              "      <td>-0.078255</td>\n",
              "      <td>-0.056751</td>\n",
              "      <td>-0.094106</td>\n",
              "      <td>0.099141</td>\n",
              "      <td>-0.119821</td>\n",
              "      <td>0.293112</td>\n",
              "      <td>-0.425386</td>\n",
              "      <td>0.267986</td>\n",
              "      <td>-0.205315</td>\n",
              "      <td>0.142117</td>\n",
              "      <td>-0.211822</td>\n",
              "      <td>-0.251582</td>\n",
              "      <td>-0.283335</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.732995</td>\n",
              "      <td>-0.303590</td>\n",
              "      <td>0.354983</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.066650</td>\n",
              "      <td>-0.076714</td>\n",
              "      <td>-0.426588</td>\n",
              "      <td>-0.332753</td>\n",
              "      <td>-0.129727</td>\n",
              "      <td>-0.128549</td>\n",
              "      <td>-0.251258</td>\n",
              "      <td>-0.995117</td>\n",
              "      <td>-0.332753</td>\n",
              "      <td>-0.605727</td>\n",
              "      <td>-0.292601</td>\n",
              "      <td>0.577573</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.376234</td>\n",
              "      <td>-0.170845</td>\n",
              "      <td>-0.551898</td>\n",
              "      <td>-0.681097</td>\n",
              "      <td>-0.723951</td>\n",
              "      <td>-0.647418</td>\n",
              "      <td>-0.799450</td>\n",
              "      <td>-0.925241</td>\n",
              "      <td>-0.681097</td>\n",
              "      <td>-0.951092</td>\n",
              "      <td>-0.599074</td>\n",
              "      <td>0.310836</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.070157</td>\n",
              "      <td>-0.588433</td>\n",
              "      <td>-0.880324</td>\n",
              "      <td>-0.190437</td>\n",
              "      <td>0.829718</td>\n",
              "      <td>0.206972</td>\n",
              "      <td>-0.425619</td>\n",
              "      <td>-0.791883</td>\n",
              "      <td>0.238604</td>\n",
              "      <td>0.049819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7348</th>\n",
              "      <td>0.273853</td>\n",
              "      <td>-0.007749</td>\n",
              "      <td>-0.147468</td>\n",
              "      <td>-0.235309</td>\n",
              "      <td>0.004816</td>\n",
              "      <td>0.059280</td>\n",
              "      <td>-0.322552</td>\n",
              "      <td>-0.029456</td>\n",
              "      <td>0.080585</td>\n",
              "      <td>0.117440</td>\n",
              "      <td>0.029369</td>\n",
              "      <td>-0.031966</td>\n",
              "      <td>0.282174</td>\n",
              "      <td>0.202880</td>\n",
              "      <td>0.266917</td>\n",
              "      <td>-0.041310</td>\n",
              "      <td>-0.706359</td>\n",
              "      <td>-0.804546</td>\n",
              "      <td>-0.495789</td>\n",
              "      <td>-0.520057</td>\n",
              "      <td>-0.279863</td>\n",
              "      <td>0.026565</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>0.293566</td>\n",
              "      <td>-0.051532</td>\n",
              "      <td>-0.361660</td>\n",
              "      <td>0.149854</td>\n",
              "      <td>0.206839</td>\n",
              "      <td>-0.154722</td>\n",
              "      <td>0.032725</td>\n",
              "      <td>-0.057240</td>\n",
              "      <td>0.034260</td>\n",
              "      <td>0.239835</td>\n",
              "      <td>-0.364480</td>\n",
              "      <td>0.121335</td>\n",
              "      <td>0.188717</td>\n",
              "      <td>-0.207505</td>\n",
              "      <td>-0.198555</td>\n",
              "      <td>-0.225866</td>\n",
              "      <td>-0.274504</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775857</td>\n",
              "      <td>-0.373955</td>\n",
              "      <td>0.361739</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.193946</td>\n",
              "      <td>-0.151879</td>\n",
              "      <td>-0.509448</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>-0.187114</td>\n",
              "      <td>-0.210320</td>\n",
              "      <td>-0.131733</td>\n",
              "      <td>-0.916112</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>-0.649987</td>\n",
              "      <td>-0.427577</td>\n",
              "      <td>0.620646</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.296176</td>\n",
              "      <td>0.019626</td>\n",
              "      <td>-0.277183</td>\n",
              "      <td>-0.682756</td>\n",
              "      <td>-0.771183</td>\n",
              "      <td>-0.727039</td>\n",
              "      <td>-0.779350</td>\n",
              "      <td>-0.761880</td>\n",
              "      <td>-0.682756</td>\n",
              "      <td>-0.957032</td>\n",
              "      <td>-0.670062</td>\n",
              "      <td>0.207930</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.165259</td>\n",
              "      <td>-0.390738</td>\n",
              "      <td>-0.680744</td>\n",
              "      <td>0.064907</td>\n",
              "      <td>0.875679</td>\n",
              "      <td>-0.879033</td>\n",
              "      <td>0.400219</td>\n",
              "      <td>-0.771840</td>\n",
              "      <td>0.252676</td>\n",
              "      <td>0.050053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7349</th>\n",
              "      <td>0.273387</td>\n",
              "      <td>-0.017011</td>\n",
              "      <td>-0.045022</td>\n",
              "      <td>-0.218218</td>\n",
              "      <td>-0.103822</td>\n",
              "      <td>0.274533</td>\n",
              "      <td>-0.304515</td>\n",
              "      <td>-0.098913</td>\n",
              "      <td>0.332584</td>\n",
              "      <td>0.043999</td>\n",
              "      <td>-0.110405</td>\n",
              "      <td>0.055411</td>\n",
              "      <td>0.263175</td>\n",
              "      <td>0.202880</td>\n",
              "      <td>0.264670</td>\n",
              "      <td>0.008034</td>\n",
              "      <td>-0.693162</td>\n",
              "      <td>-0.844279</td>\n",
              "      <td>-0.271194</td>\n",
              "      <td>-0.488620</td>\n",
              "      <td>-0.250723</td>\n",
              "      <td>0.334376</td>\n",
              "      <td>0.173131</td>\n",
              "      <td>0.276040</td>\n",
              "      <td>0.152003</td>\n",
              "      <td>-0.376773</td>\n",
              "      <td>0.200784</td>\n",
              "      <td>0.063584</td>\n",
              "      <td>-0.017019</td>\n",
              "      <td>-0.004323</td>\n",
              "      <td>-0.023053</td>\n",
              "      <td>0.119962</td>\n",
              "      <td>0.080689</td>\n",
              "      <td>-0.420093</td>\n",
              "      <td>0.197763</td>\n",
              "      <td>-0.033780</td>\n",
              "      <td>0.016677</td>\n",
              "      <td>-0.226826</td>\n",
              "      <td>-0.184700</td>\n",
              "      <td>-0.198452</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.801702</td>\n",
              "      <td>-0.489794</td>\n",
              "      <td>0.189903</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.007099</td>\n",
              "      <td>0.331457</td>\n",
              "      <td>0.083984</td>\n",
              "      <td>-0.351948</td>\n",
              "      <td>-0.032290</td>\n",
              "      <td>-0.193130</td>\n",
              "      <td>0.167388</td>\n",
              "      <td>-0.972099</td>\n",
              "      <td>-0.351948</td>\n",
              "      <td>-0.545002</td>\n",
              "      <td>-0.241789</td>\n",
              "      <td>0.584816</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.320249</td>\n",
              "      <td>0.490169</td>\n",
              "      <td>0.313280</td>\n",
              "      <td>-0.685851</td>\n",
              "      <td>-0.726372</td>\n",
              "      <td>-0.724976</td>\n",
              "      <td>-0.709270</td>\n",
              "      <td>-0.692582</td>\n",
              "      <td>-0.685851</td>\n",
              "      <td>-0.952309</td>\n",
              "      <td>-0.696373</td>\n",
              "      <td>0.158936</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.195034</td>\n",
              "      <td>0.025145</td>\n",
              "      <td>-0.304029</td>\n",
              "      <td>0.052806</td>\n",
              "      <td>-0.266724</td>\n",
              "      <td>0.864404</td>\n",
              "      <td>0.701169</td>\n",
              "      <td>-0.779133</td>\n",
              "      <td>0.249145</td>\n",
              "      <td>0.040811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7350</th>\n",
              "      <td>0.289654</td>\n",
              "      <td>-0.018843</td>\n",
              "      <td>-0.158281</td>\n",
              "      <td>-0.219139</td>\n",
              "      <td>-0.111412</td>\n",
              "      <td>0.268893</td>\n",
              "      <td>-0.310487</td>\n",
              "      <td>-0.068200</td>\n",
              "      <td>0.319473</td>\n",
              "      <td>0.101702</td>\n",
              "      <td>-0.149495</td>\n",
              "      <td>0.055411</td>\n",
              "      <td>0.234850</td>\n",
              "      <td>0.237784</td>\n",
              "      <td>0.264670</td>\n",
              "      <td>0.020011</td>\n",
              "      <td>-0.693855</td>\n",
              "      <td>-0.846871</td>\n",
              "      <td>-0.279718</td>\n",
              "      <td>-0.488245</td>\n",
              "      <td>-0.196204</td>\n",
              "      <td>0.239455</td>\n",
              "      <td>0.160333</td>\n",
              "      <td>0.246561</td>\n",
              "      <td>0.021678</td>\n",
              "      <td>-0.475165</td>\n",
              "      <td>0.296546</td>\n",
              "      <td>0.009588</td>\n",
              "      <td>-0.038354</td>\n",
              "      <td>-0.277801</td>\n",
              "      <td>0.201032</td>\n",
              "      <td>0.101761</td>\n",
              "      <td>-0.108375</td>\n",
              "      <td>-0.438356</td>\n",
              "      <td>0.250837</td>\n",
              "      <td>-0.234309</td>\n",
              "      <td>0.232444</td>\n",
              "      <td>-0.257775</td>\n",
              "      <td>-0.231103</td>\n",
              "      <td>-0.189915</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.826289</td>\n",
              "      <td>-0.559787</td>\n",
              "      <td>0.240644</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.109902</td>\n",
              "      <td>0.038175</td>\n",
              "      <td>-0.305554</td>\n",
              "      <td>-0.415004</td>\n",
              "      <td>0.039199</td>\n",
              "      <td>-0.171131</td>\n",
              "      <td>0.115989</td>\n",
              "      <td>-0.959329</td>\n",
              "      <td>-0.415004</td>\n",
              "      <td>-0.510548</td>\n",
              "      <td>-0.513205</td>\n",
              "      <td>0.445207</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.412332</td>\n",
              "      <td>0.308105</td>\n",
              "      <td>-0.042502</td>\n",
              "      <td>-0.712131</td>\n",
              "      <td>-0.689421</td>\n",
              "      <td>-0.702221</td>\n",
              "      <td>-0.694807</td>\n",
              "      <td>-0.886154</td>\n",
              "      <td>-0.712131</td>\n",
              "      <td>-0.951972</td>\n",
              "      <td>-0.760044</td>\n",
              "      <td>0.210070</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.013865</td>\n",
              "      <td>0.063907</td>\n",
              "      <td>-0.344314</td>\n",
              "      <td>-0.101360</td>\n",
              "      <td>0.700740</td>\n",
              "      <td>0.936674</td>\n",
              "      <td>-0.589479</td>\n",
              "      <td>-0.785181</td>\n",
              "      <td>0.246432</td>\n",
              "      <td>0.025339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7351</th>\n",
              "      <td>0.351503</td>\n",
              "      <td>-0.012423</td>\n",
              "      <td>-0.203867</td>\n",
              "      <td>-0.269270</td>\n",
              "      <td>-0.087212</td>\n",
              "      <td>0.177404</td>\n",
              "      <td>-0.377404</td>\n",
              "      <td>-0.038678</td>\n",
              "      <td>0.229430</td>\n",
              "      <td>0.269013</td>\n",
              "      <td>-0.147028</td>\n",
              "      <td>-0.133749</td>\n",
              "      <td>0.234850</td>\n",
              "      <td>0.237784</td>\n",
              "      <td>0.301579</td>\n",
              "      <td>-0.027958</td>\n",
              "      <td>-0.730624</td>\n",
              "      <td>-0.838478</td>\n",
              "      <td>-0.368309</td>\n",
              "      <td>-0.627128</td>\n",
              "      <td>-0.112288</td>\n",
              "      <td>0.262496</td>\n",
              "      <td>0.312180</td>\n",
              "      <td>0.333536</td>\n",
              "      <td>-0.099101</td>\n",
              "      <td>-0.442905</td>\n",
              "      <td>0.386497</td>\n",
              "      <td>-0.230562</td>\n",
              "      <td>0.139282</td>\n",
              "      <td>-0.446446</td>\n",
              "      <td>0.391569</td>\n",
              "      <td>-0.156435</td>\n",
              "      <td>0.097870</td>\n",
              "      <td>-0.405691</td>\n",
              "      <td>0.183340</td>\n",
              "      <td>-0.056556</td>\n",
              "      <td>0.054368</td>\n",
              "      <td>-0.266442</td>\n",
              "      <td>-0.291113</td>\n",
              "      <td>-0.200293</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.759097</td>\n",
              "      <td>-0.434679</td>\n",
              "      <td>0.298694</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.242448</td>\n",
              "      <td>-0.321950</td>\n",
              "      <td>-0.768542</td>\n",
              "      <td>-0.330780</td>\n",
              "      <td>-0.106002</td>\n",
              "      <td>-0.106450</td>\n",
              "      <td>-0.090538</td>\n",
              "      <td>-0.779153</td>\n",
              "      <td>-0.330780</td>\n",
              "      <td>-0.589429</td>\n",
              "      <td>-0.290645</td>\n",
              "      <td>0.436453</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.389084</td>\n",
              "      <td>-0.057581</td>\n",
              "      <td>-0.387956</td>\n",
              "      <td>-0.715588</td>\n",
              "      <td>-0.745120</td>\n",
              "      <td>-0.697404</td>\n",
              "      <td>-0.783571</td>\n",
              "      <td>-0.758685</td>\n",
              "      <td>-0.715588</td>\n",
              "      <td>-0.959988</td>\n",
              "      <td>-0.677185</td>\n",
              "      <td>0.202026</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.058402</td>\n",
              "      <td>-0.387052</td>\n",
              "      <td>-0.740738</td>\n",
              "      <td>-0.280088</td>\n",
              "      <td>-0.007739</td>\n",
              "      <td>-0.056088</td>\n",
              "      <td>-0.616956</td>\n",
              "      <td>-0.783267</td>\n",
              "      <td>0.246809</td>\n",
              "      <td>0.036695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7352 rows × 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tBodyAcc-mean()-X  ...  angle(Z,gravityMean)\n",
              "0              0.288585  ...             -0.058627\n",
              "1              0.278419  ...             -0.054317\n",
              "2              0.279653  ...             -0.049118\n",
              "3              0.279174  ...             -0.047663\n",
              "4              0.276629  ...             -0.043892\n",
              "...                 ...  ...                   ...\n",
              "7347           0.299665  ...              0.049819\n",
              "7348           0.273853  ...              0.050053\n",
              "7349           0.273387  ...              0.040811\n",
              "7350           0.289654  ...              0.025339\n",
              "7351           0.351503  ...              0.036695\n",
              "\n",
              "[7352 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1VMjIPLGKm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57b19b7c-bfbc-43d4-dcaf-81a058518c95"
      },
      "source": [
        "print(len(train_csv), len(train_y))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7352 7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWYMkb35GxAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c5749a8e-9936-43cb-da53-91184f84cb5e"
      },
      "source": [
        "test_y\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2942</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2944</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2947 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label\n",
              "0         5\n",
              "1         5\n",
              "2         5\n",
              "3         5\n",
              "4         5\n",
              "...     ...\n",
              "2942      2\n",
              "2943      2\n",
              "2944      2\n",
              "2945      2\n",
              "2946      2\n",
              "\n",
              "[2947 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8mpTq24zTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "26636c93-600a-4050-d636-1c82a32ffc22"
      },
      "source": [
        "feature_name_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_index</th>\n",
              "      <th>column_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>tBodyAcc-mean()-X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>tBodyAcc-mean()-Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>tBodyAcc-mean()-Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>tBodyAcc-std()-X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>tBodyAcc-std()-Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   column_index        column_name\n",
              "0             1  tBodyAcc-mean()-X\n",
              "1             2  tBodyAcc-mean()-Y\n",
              "2             3  tBodyAcc-mean()-Z\n",
              "3             4   tBodyAcc-std()-X\n",
              "4             5   tBodyAcc-std()-Y"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFWzdIwYAGbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4c7f8892-09f3-4da2-b9eb-ed104c7f6e56"
      },
      "source": [
        "train_y.describe()\n",
        "test_y.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2947.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.577876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.740348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             label\n",
              "count  2947.000000\n",
              "mean      3.577876\n",
              "std       1.740348\n",
              "min       1.000000\n",
              "25%       2.000000\n",
              "50%       4.000000\n",
              "75%       5.000000\n",
              "max       6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbue8FkSXVDj",
        "colab_type": "text"
      },
      "source": [
        "#preprocessing version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF2nkW9TXUGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "new_train_csv = scaler.fit_transform(np.array(train_csv), np.array(train_y))\n",
        "new_test_csv = scaler.transform(np.array(test_csv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AspYGtIxNMl5",
        "colab_type": "text"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWfNUq5NNlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "bd4373f4-bfce-4759-de0d-9fd525a68306"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42)\n",
        "params = {\n",
        "    'C' : [0.5,1,10]\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(train_csv, train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={'C': [0.5, 1, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUSXJRS3NvX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24db0994-6ddd-4e1c-dc64-23c4b5edfc71"
      },
      "source": [
        "pred = cv.predict(test_csv)\n",
        "\n",
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM : 0.9619952494061758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEANJHdHOSf-",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1wVohaawwFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "# filter 수 늘리는게 중요? kernel size 크게\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 1, stride= 1), torch.nn.MaxPool1d(kernel_size= 1), \n",
        "                                          torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,128, kernel_size= 1, stride= 1, padding =0),\n",
        "                                          torch.nn.MaxPool1d(kernel_size= 1, stride = 1, padding = 0), \n",
        "                                          torch.nn.ReLU())\n",
        "\n",
        "        self.layer3 = torch.nn.Linear(128 , output_size, bias = True) #(input_size - kernel_size + 2*padding_size)/stride + 1\n",
        "\n",
        "        torch.nn.init.kaiming_uniform(self.layer3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV9XBWyQ-Kkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a95a616a-a444-4e28-b62c-e39f48e40c02"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
              "              handle_unknown='error', sparse=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-lRv-Yu-duG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_L = encoder.transform(train_y).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wAATZyQw6F0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "690a2e22-5030-4286-c25b-25230e26205c"
      },
      "source": [
        "model = CNN(train_csv.shape[1], train_L.shape[1]).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHGF_WLHAPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "51fb85a0-eee5-46a9-fb6a-cbfb32479792"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv1d(561, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer3): Linear(in_features=128, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyLCJ3LFOzzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "925c543f-590b-4b20-ca54-df14f18ab432"
      },
      "source": [
        "train_csv\n",
        "# train_y.shape\n",
        "# train_y\n",
        "train_csv.shape[1]\n",
        "train_L.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hpGKaKsFczC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f32c49ad-7fee-4497-8836-6dfbe4690bae"
      },
      "source": [
        "train_L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovoSyr_1O4bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f35d3660-b8c1-436b-c3fa-a3134e52fc0c"
      },
      "source": [
        "np.array(train_csv).dtype#describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWRQKPtDrW3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_D = np.expand_dims(np.array(train_csv), axis = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qHUm4o5TIuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D = torch.FloatTensor(np.array(train_csv))\n",
        "train_L = torch.FloatTensor(np.array(train_L))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jM1i_UjRF-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_D, train_L), batch_size = 100, shuffle= True, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xnzirKQzN9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9ea7fac8-cd93-4d95-9ca0-320e9ab2e008"
      },
      "source": [
        "running_loss =0\n",
        "for e in range(1001):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    #print(x.shape)\n",
        "    x = x.resize(100,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if (e+1) % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:358: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[99] loss : 5.622\n",
            "[199] loss : 3.581\n",
            "[299] loss : 2.814\n",
            "[399] loss : 2.395\n",
            "[499] loss : 2.112\n",
            "[599] loss : 1.891\n",
            "[699] loss : 1.717\n",
            "[799] loss : 1.576\n",
            "[899] loss : 1.461\n",
            "[999] loss : 1.364\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4Cg_08oAlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "writer = SummaryWriter('runs/har_cnn')\n",
        "dataiter = iter(train_loader)\n",
        "img, labels = dataiter.next()\n",
        "img_grid = torchvision.utils.make_grid(img)\n",
        "\n",
        "#matplotlib_imshow(img_grid, one_channel = True)\n",
        "writer.add_image('har_cnn', img_grid)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOwNDvzwon9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! tensorboard --logdir=data/ --host localhost --port 8088\n",
        "# ! tensorboard --logdir=runs"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq45GMYnfpt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './file.pt'\n",
        "torch.save({\n",
        "            'epoch': 1001,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "\n",
        "            }, PATH)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9o70AWeccxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred=  model(test_D.view(-1,561,1).to(device))\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxbWbvcaFgM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80486a95-477c-4f5a-d123-c11d88a89dfe"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2947, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdNEEpCYD6Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dea99e8-f6ca-4c73-e595-52a756dc2952"
      },
      "source": [
        "pred[0]\n",
        "np.array(test_y).reshape(2947,)[1]\n",
        "#test_y = np.array(test_y).reshape(1, 2947)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hx43UhyTeF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "964d3edc-dea4-407e-bde3-cce481e9037e"
      },
      "source": [
        "test_y"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2942</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2944</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2947 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label\n",
              "0         5\n",
              "1         5\n",
              "2         5\n",
              "3         5\n",
              "4         5\n",
              "...     ...\n",
              "2942      2\n",
              "2943      2\n",
              "2944      2\n",
              "2945      2\n",
              "2946      2\n",
              "\n",
              "[2947 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9jl8V8rc8fZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5dd71fd-0e55-4cd4-ca31-8b48f167b777"
      },
      "source": [
        "acc = [pred[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('CNN : ', real_acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN :  0.93926024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztJICNZACm3j",
        "colab_type": "text"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73egTv-ipKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1uEYIv8Cn0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "  def __init__(self, n_class, bi):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(561, 128, 2,dropout = 0.1, bidirectional = bi)\n",
        "    self.l1 = torch.nn.Linear(128, n_class)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.softmax = torch.nn.Softmax(dim = 1)\n",
        "    self.h = torch.randn(2,1,128).to(device)\n",
        "    self.c = torch.randn(2,1,128).to(device)\n",
        "  def forward(self, x):\n",
        "    #print(x.shape)\n",
        "    x = x.permute(1,0,2)# 축 바꾸기. 전치행렬처럼\n",
        "    #print(x.shape)\n",
        "\n",
        "    out, hidden = self.lstm(x,(self.h,self.c) )\n",
        "    #print(out.shape)\n",
        "    out = self.tanh(out)\n",
        "    out = self.dropout(out)\n",
        "    out = out.contiguous().view(-1, 128)\n",
        "    #print(out.shape)\n",
        "    out = self.l1(out)\n",
        "    #out = self.softmax(out)\n",
        "    return out\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC06MpYtUU0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(train_L.shape[1], False).to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCciuT1MUcl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4d5075ae-eae6-4b7a-f8a6-fca231165e75"
      },
      "source": [
        "model"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(561, 128, num_layers=2, dropout=0.1)\n",
              "  (l1): Linear(in_features=128, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (tanh): Tanh()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Or6MCrhSvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo778L6TRJ2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "47c6e0cd-f51b-493d-d04a-6ba7bf36b42c"
      },
      "source": [
        "running_loss =0\n",
        "for e in range(1001):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    x = x.resize(1,100,561).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:358: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0] loss : 0.133\n",
            "[100] loss : 10.184\n",
            "[200] loss : 9.777\n",
            "[300] loss : 9.488\n",
            "[400] loss : 9.160\n",
            "[500] loss : 8.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBs5GMFuo0Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hquEfHomf92B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_lstm = model(test_D.view(1,-1,561).to(device))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M4-HjqBgFwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kthoFP0wr88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCXZv5epnvlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLJmLRx9pHQp",
        "colab_type": "text"
      },
      "source": [
        "#CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3F9nUSmpLmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, n_class, bi):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 1, stride= 1, padding =0), torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,256, kernel_size= 1, stride= 1, padding =0), torch.nn.ReLU())\n",
        "        self.layer3 = torch.nn.LSTM(256,  64, 2,dropout = 0.3, bidirectional = bi)\n",
        "        if bi:\n",
        "          self.layer3 = torch.nn.LSTM(64, 32, 2, dropout = 0.3, bidirectional = bi)\n",
        "        self.bi = bi\n",
        "        #self.h = torch.randn(2,1,64).to(device)\n",
        "        #self.c = torch.randn(2,1,64).to(device)\n",
        "        self.layer4 = torch.nn.Linear(64, n_class)\n",
        "        if bi:\n",
        "          self.layer = torch.nn.Linear(32, n_class)\n",
        "        torch.nn.init.xavier_uniform(self.layer4.weight)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.layer1(x)\n",
        "      #print('first layer,', out.shape)\n",
        "      out = self.layer2(out)\n",
        "      #print('sec layer', out.shape)\n",
        "      out = out.permute(2, 0, 1)\n",
        "      #print('premute', out.shape)\n",
        "      out, hidden = self.layer3(out)#,(self.h,self.c))\n",
        "      #print('third layer', out.shape)\n",
        "      out = self.dropout(out)\n",
        "      out = out.contiguous().view(-1, 64)\n",
        "      #print('contig', out.view)\n",
        "      out = self.layer4(out)\n",
        "      #print('last layer', out)\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "#       first layer, torch.Size([2947, 64, 1])\n",
        "# sec layer torch.Size([2947, 64, 1])\n",
        "# premute torch.Size([1, 2947, 64])\n",
        "# third layer torch.Size([1, 2947, 64]\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mRfY7UsqbKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_LSTM(train_D.shape[1], train_L.shape[1], train_L.shape[1] , False).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I459fIOJqqOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-c8zOYq7D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(1001):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    x = x.view(-1,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELQtu1Og12DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_cnn_lstm = model(test_D.reshape(-1,561,1).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI9H0ytLWAzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNMGigKh186O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BKufZfmHZ8I",
        "colab_type": "text"
      },
      "source": [
        "#bi-LSTM_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VUq8vwXHcat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_LSTM(train_D.shape[1], train_L.shape[1], train_L.shape[1] , True).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djlPfvvqHhBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(1001):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H9G7475HikF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_cnn_lstm = model(test_D.reshape(-1,561,1).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gof6V_GKHjwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('bi-LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrwAMpg366Z6",
        "colab_type": "text"
      },
      "source": [
        "#LSTM + CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4XzO5VP68CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_CNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTM_CNN, self).__init__()\n",
        "    self.lstm1 = torch.nn.LSTM(561, 32, 2)\n",
        "    #self.lstm2 = torch.nn.LSTM(32, 32)\n",
        "    self.conv1 = torch.nn.Sequential(torch.nn.Conv1d(32, 64,kernel_size = 5,stride = 2) ,torch.nn.MaxPool1d(2))\n",
        "    self.conv2 = torch.nn.Sequential( torch.nn.Conv1d(64, 128, 3, 1),\n",
        "                                     torch.nn.AvgPool1d(1))\n",
        "    self.bn = torch.nn.BatchNorm2d(128)\n",
        "    self.l1 = torch.nn.Linear(128, 6)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, _ = self.lstm1(x)\n",
        "    print('lstm1')\n",
        "    #out = self.lstm2(out)\n",
        "    #print('lstm2')\n",
        "    out = out.permute(0, 2, 1)\n",
        "\n",
        "    out = self.conv1(out)\n",
        "    print('conv1')\n",
        "    out = self.conv2(out)\n",
        "    print('conv2')\n",
        "    out = self.bn(out)\n",
        "    print('batchnormal')\n",
        "    out= self.l1(out)\n",
        "    print('linear')\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPjkg2doAyWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM_CNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTo7Ov5HA1JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Vwg0YoA8ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(1001):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1,1,561).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}