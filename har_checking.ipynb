{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "har_checking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDrXXFRatnsLN73izg61pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyona-yu/HAR_python/blob/master/har_checking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClNv8R2035Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoO-AWGAh4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "5c600168-30b3-40b5-e9b3-8f52de03b520"
      },
      "source": [
        "! git clone https://github.com/hyona-yu/Dataset.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Dataset'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 182 (delta 1), reused 19 (delta 1), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (182/182), 133.20 MiB | 24.24 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Checking out files: 100% (163/163), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGBB8lUHFrfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'Dataset/UCI HAR Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3unIx-ms4Hqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name_df = pd.read_csv(url + 'features.txt', sep='\\s+', header=None, \n",
        "                              names=['column_index','column_name'])\n",
        "\n",
        "feature_name = feature_name_df.iloc[:,1].values.tolist()\n",
        "train_csv = pd.read_csv(url + 'train/X_train.txt', sep ='\\s+', header = None)\n",
        "train_csv.columns = feature_name\n",
        "test_csv = pd.read_csv(url + 'test/X_test.txt', sep = '\\s+', header= None)\n",
        "test_csv.columns = feature_name\n",
        "train_y = pd.read_csv(url + 'train/y_train.txt', header = None, names= ['label'])\n",
        "test_y =pd.read_csv(url + 'test/y_test.txt', header =None, names= ['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaxBTuP85JXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1VMjIPLGKm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_csv), len(train_y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWYMkb35GxAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8mpTq24zTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFWzdIwYAGbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y.describe()\n",
        "test_y.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbue8FkSXVDj",
        "colab_type": "text"
      },
      "source": [
        "#preprocessing version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF2nkW9TXUGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "new_train_csv = scaler.fit_transform(np.array(train_csv), np.array(train_y))\n",
        "new_test_csv = scaler.transform(np.array(test_csv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AspYGtIxNMl5",
        "colab_type": "text"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWfNUq5NNlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state = 42)\n",
        "params = {\n",
        "    'C' : [0.5,1,10]\n",
        "}\n",
        "cv = GridSearchCV(clf, param_grid = params)\n",
        "cv.fit(train_csv, train_y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUSXJRS3NvX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = cv.predict(test_csv)\n",
        "\n",
        "acc = accuracy_score(pred, test_y)\n",
        "print(\"SVM :\",acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEANJHdHOSf-",
        "colab_type": "text"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1wVohaawwFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "# filter 수 늘리는게 중요? kernel size 크게\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 1, stride= 1), torch.nn.MaxPool1d(kernel_size= 1), \n",
        "                                          torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,128, kernel_size= 1, stride= 1, padding =0),\n",
        "                                          torch.nn.MaxPool1d(kernel_size= 1, stride = 1, padding = 0), \n",
        "                                          torch.nn.ReLU())\n",
        "\n",
        "        self.layer3 = torch.nn.Linear(128 , output_size, bias = True) #(input_size - kernel_size + 2*padding_size)/stride + 1\n",
        "\n",
        "        torch.nn.init.kaiming_uniform(self.layer3.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV9XBWyQ-Kkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(train_y)\n",
        "train_L = encoder.transform(train_y).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wAATZyQw6F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN(train_csv.shape[1], train_L.shape[1]).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHGF_WLHAPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyLCJ3LFOzzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv\n",
        "# train_y.shape\n",
        "# train_y\n",
        "train_csv.shape[1]\n",
        "train_L.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hpGKaKsFczC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovoSyr_1O4bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(train_csv).dtype#describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWRQKPtDrW3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_D = np.expand_dims(np.array(train_csv), axis = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qHUm4o5TIuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D = torch.FloatTensor(np.array(train_csv))\n",
        "train_L = torch.FloatTensor(np.array(train_L))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jM1i_UjRF-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_D, train_L), batch_size = 100, shuffle= True, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xnzirKQzN9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss =0\n",
        "for e in range(1001):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    #print(x.shape)\n",
        "    x = x.resize(100,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if (e+1) % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4Cg_08oAlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "writer = SummaryWriter('runs/har_cnn')\n",
        "dataiter = iter(train_loader)\n",
        "img, labels = dataiter.next()\n",
        "img_grid = torchvision.utils.make_grid(img)\n",
        "\n",
        "#matplotlib_imshow(img_grid, one_channel = True)\n",
        "writer.add_image('har_cnn', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOwNDvzwon9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! tensorboard --logdir=data/ --host localhost --port 8088\n",
        "# ! tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq45GMYnfpt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './file.pt'\n",
        "torch.save({\n",
        "            'epoch': 1001,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "\n",
        "            }, PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9o70AWeccxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred=  model(test_D.view(-1,561,1).to(device))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxbWbvcaFgM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdNEEpCYD6Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred[0]\n",
        "np.array(test_y).reshape(2947,)[1]\n",
        "#test_y = np.array(test_y).reshape(1, 2947)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hx43UhyTeF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9jl8V8rc8fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztJICNZACm3j",
        "colab_type": "text"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y73egTv-ipKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1uEYIv8Cn0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "  def __init__(self, n_class, bi):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(561, 128, 2,dropout = 0.1, bidirectional = bi)\n",
        "    self.l1 = torch.nn.Linear(128, n_class)\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.softmax = torch.nn.Softmax(dim = 1)\n",
        "    self.h = torch.randn(2,1,128).to(device)\n",
        "    self.c = torch.randn(2,1,128).to(device)\n",
        "  def forward(self, x):\n",
        "    #print(x.shape)\n",
        "    x = x.permute(1,0,2)# 축 바꾸기. 전치행렬처럼\n",
        "    #print(x.shape)\n",
        "\n",
        "    out, hidden = self.lstm(x,(self.h,self.c) )\n",
        "    #print(out.shape)\n",
        "    out = self.tanh(out)\n",
        "    out = self.dropout(out)\n",
        "    out = out.contiguous().view(-1, 128)\n",
        "    #print(out.shape)\n",
        "    out = self.l1(out)\n",
        "    #out = self.softmax(out)\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC06MpYtUU0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(train_L.shape[1], False).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCciuT1MUcl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Or6MCrhSvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo778L6TRJ2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss =0\n",
        "for e in range(1001):\n",
        "  for i , data in enumerate(train_loader):\n",
        "    x, y = data\n",
        "    x = x.resize(1,100,561).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 == 0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss / 100))\n",
        "    running_loss =0\n",
        "\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBs5GMFuo0Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hquEfHomf92B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_lstm = model(test_D.view(1,-1,561).to(device))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M4-HjqBgFwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pred_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kthoFP0wr88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCXZv5epnvlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLJmLRx9pHQp",
        "colab_type": "text"
      },
      "source": [
        "#CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3F9nUSmpLmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, n_class, bi):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.layer1 = torch.nn.Sequential(torch.nn.Conv1d(input_size ,128, kernel_size= 1, stride= 1, padding =0), torch.nn.ReLU()) #\n",
        "        self.layer2 = torch.nn.Sequential(torch.nn.Conv1d(128,256, kernel_size= 1, stride= 1, padding =0), torch.nn.ReLU())\n",
        "        self.layer3 = torch.nn.LSTM(256,  64, 2,dropout = 0.3, bidirectional = bi)\n",
        "        if bi:\n",
        "          self.layer3 = torch.nn.LSTM(64, 32, 2, dropout = 0.3, bidirectional = bi)\n",
        "        self.bi = bi\n",
        "        #self.h = torch.randn(2,1,64).to(device)\n",
        "        #self.c = torch.randn(2,1,64).to(device)\n",
        "        self.layer4 = torch.nn.Linear(64, n_class)\n",
        "        if bi:\n",
        "          self.layer = torch.nn.Linear(32, n_class)\n",
        "        torch.nn.init.xavier_uniform(self.layer4.weight)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.layer1(x)\n",
        "      #print('first layer,', out.shape)\n",
        "      out = self.layer2(out)\n",
        "      #print('sec layer', out.shape)\n",
        "      out = out.permute(2, 0, 1)\n",
        "      #print('premute', out.shape)\n",
        "      out, hidden = self.layer3(out)#,(self.h,self.c))\n",
        "      #print('third layer', out.shape)\n",
        "      out = self.dropout(out)\n",
        "      out = out.contiguous().view(-1, 64)\n",
        "      #print('contig', out.view)\n",
        "      out = self.layer4(out)\n",
        "      #print('last layer', out)\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "#       first layer, torch.Size([2947, 64, 1])\n",
        "# sec layer torch.Size([2947, 64, 1])\n",
        "# premute torch.Size([1, 2947, 64])\n",
        "# third layer torch.Size([1, 2947, 64]\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mRfY7UsqbKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_LSTM(train_D.shape[1], train_L.shape[1], train_L.shape[1] , False).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I459fIOJqqOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-c8zOYq7D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(1001):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    x = x.view(-1,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELQtu1Og12DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_cnn_lstm = model(test_D.reshape(-1,561,1).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI9H0ytLWAzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNMGigKh186O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BKufZfmHZ8I",
        "colab_type": "text"
      },
      "source": [
        "#bi-LSTM_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VUq8vwXHcat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_LSTM(train_D.shape[1], train_L.shape[1], train_L.shape[1] , True).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djlPfvvqHhBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(1001):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1,561,1).to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 100 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H9G7475HikF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  test_D = torch.FloatTensor(np.array(test_csv))\n",
        "  model.eval()\n",
        "  pred_cnn_lstm = model(test_D.reshape(-1,561,1).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gof6V_GKHjwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = [pred_cnn_lstm[i].argmax()+1 == np.array(test_y).reshape(2947,)[i] for i in range(len(test_D))]\n",
        "acc = np.array(acc, dtype=np.float32)\n",
        "real_acc = acc.mean()\n",
        "print('bi-LSTM_CNN : ', real_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrwAMpg366Z6",
        "colab_type": "text"
      },
      "source": [
        "#LSTM + CNN\n",
        "####LSTM-CNN Architecture for Human Activity Recognition [IEEE]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOJ2RShRj1pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZChl1hduQRN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'Dataset/HAPT Data Set/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFV6VBGAQOf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name_df = pd.read_csv(url + 'features.txt', sep='\\s+', header=None, \n",
        "                              names=['column_name'])\n",
        "\n",
        "feature_name = feature_name_df.values\n",
        "train_csv = pd.read_csv(url + 'Train/X_train.txt', sep ='\\s+', header = None)\n",
        "train_csv.columns = feature_name\n",
        "test_csv = pd.read_csv(url + 'Test/X_test.txt', sep = '\\s+', header= None)\n",
        "test_csv.columns = feature_name\n",
        "train_y = pd.read_csv(url + 'Train/y_train.txt', header = None, names= ['label'])\n",
        "test_y =pd.read_csv(url + 'Test/y_test.txt', header =None, names= ['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBh9SHReEGl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20f3bc96-85e3-4aa6-ba25-cdfb3f984dfd"
      },
      "source": [
        "train_csv.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQrh6RNPMS0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a5e3950-4034-49cf-8dfd-0b5a61bf2681"
      },
      "source": [
        "test_csv.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDL3g2ldSBBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_y)):\n",
        "  if train_y.loc[i,'label'] >=7 :\n",
        "    train_csv.drop(i, inplace =True)\n",
        "    train_y.drop(i, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRXbZ3zxLWDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_y)):\n",
        "  if test_y.loc[i,'label'] >=7 :\n",
        "    test_csv.drop(i, inplace =True)\n",
        "    test_y.drop(i, inplace = True)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwNBiz2SRO-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# encoder = OneHotEncoder()\n",
        "# encoder.fit(train_y)\n",
        "# train_L = encoder.transform(train_y).toarray()\n",
        "train_L = train_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQWib3iZRPxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "b17a6431-fd6f-42cb-a95b-0c84303716b1"
      },
      "source": [
        "train_L.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7415.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.654484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.742175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             label\n",
              "count  7415.000000\n",
              "mean      3.654484\n",
              "std       1.742175\n",
              "min       1.000000\n",
              "25%       2.000000\n",
              "50%       4.000000\n",
              "75%       5.000000\n",
              "max       6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COELAaZnQcIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "357ad6f5-acb1-4d9a-d60c-a72db784b89d"
      },
      "source": [
        "train_csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(tBodyAcc-Mean-1,)</th>\n",
              "      <th>(tBodyAcc-Mean-2,)</th>\n",
              "      <th>(tBodyAcc-Mean-3,)</th>\n",
              "      <th>(tBodyAcc-STD-1,)</th>\n",
              "      <th>(tBodyAcc-STD-2,)</th>\n",
              "      <th>(tBodyAcc-STD-3,)</th>\n",
              "      <th>(tBodyAcc-Mad-1,)</th>\n",
              "      <th>(tBodyAcc-Mad-2,)</th>\n",
              "      <th>(tBodyAcc-Mad-3,)</th>\n",
              "      <th>(tBodyAcc-Max-1,)</th>\n",
              "      <th>(tBodyAcc-Max-2,)</th>\n",
              "      <th>(tBodyAcc-Max-3,)</th>\n",
              "      <th>(tBodyAcc-Min-1,)</th>\n",
              "      <th>(tBodyAcc-Min-2,)</th>\n",
              "      <th>(tBodyAcc-Min-3,)</th>\n",
              "      <th>(tBodyAcc-SMA-1,)</th>\n",
              "      <th>(tBodyAcc-Energy-1,)</th>\n",
              "      <th>(tBodyAcc-Energy-2,)</th>\n",
              "      <th>(tBodyAcc-Energy-3,)</th>\n",
              "      <th>(tBodyAcc-IQR-1,)</th>\n",
              "      <th>(tBodyAcc-IQR-2,)</th>\n",
              "      <th>(tBodyAcc-IQR-3,)</th>\n",
              "      <th>(tBodyAcc-ropy-1,)</th>\n",
              "      <th>(tBodyAcc-ropy-1,)</th>\n",
              "      <th>(tBodyAcc-ropy-1,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-1,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-2,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-3,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-4,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-5,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-6,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-7,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-8,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-9,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-10,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-11,)</th>\n",
              "      <th>(tBodyAcc-ARCoeff-12,)</th>\n",
              "      <th>(tBodyAcc-Correlation-1,)</th>\n",
              "      <th>(tBodyAcc-Correlation-2,)</th>\n",
              "      <th>(tBodyAcc-Correlation-3,)</th>\n",
              "      <th>...</th>\n",
              "      <th>(fBodyAccJerkMag-Energy-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-IQR-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-ropy-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-MaxInds-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-MeanFreq-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-Skewness-1,)</th>\n",
              "      <th>(fBodyAccJerkMag-Kurtosis-1,)</th>\n",
              "      <th>(fBodyGyroMag-Mean-1,)</th>\n",
              "      <th>(fBodyGyroMag-STD-1,)</th>\n",
              "      <th>(fBodyGyroMag-Mad-1,)</th>\n",
              "      <th>(fBodyGyroMag-Max-1,)</th>\n",
              "      <th>(fBodyGyroMag-Min-1,)</th>\n",
              "      <th>(fBodyGyroMag-SMA-1,)</th>\n",
              "      <th>(fBodyGyroMag-Energy-1,)</th>\n",
              "      <th>(fBodyGyroMag-IQR-1,)</th>\n",
              "      <th>(fBodyGyroMag-ropy-1,)</th>\n",
              "      <th>(fBodyGyroMag-MaxInds-1,)</th>\n",
              "      <th>(fBodyGyroMag-MeanFreq-1,)</th>\n",
              "      <th>(fBodyGyroMag-Skewness-1,)</th>\n",
              "      <th>(fBodyGyroMag-Kurtosis-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Mean-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-STD-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Mad-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Max-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Min-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-SMA-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Energy-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-IQR-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-ropy-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-MaxInds-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-MeanFreq-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Skewness-1,)</th>\n",
              "      <th>(fBodyGyroJerkMag-Kurtosis-1,)</th>\n",
              "      <th>(tBodyAcc-AngleWRTGravity-1,)</th>\n",
              "      <th>(tBodyAccJerk-AngleWRTGravity-1,)</th>\n",
              "      <th>(tBodyGyro-AngleWRTGravity-1,)</th>\n",
              "      <th>(tBodyGyroJerk-AngleWRTGravity-1,)</th>\n",
              "      <th>(tXAxisAcc-AngleWRTGravity-1,)</th>\n",
              "      <th>(tYAxisAcc-AngleWRTGravity-1,)</th>\n",
              "      <th>(tZAxisAcc-AngleWRTGravity-1,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043580</td>\n",
              "      <td>-0.005970</td>\n",
              "      <td>-0.035054</td>\n",
              "      <td>-0.995381</td>\n",
              "      <td>-0.988366</td>\n",
              "      <td>-0.937382</td>\n",
              "      <td>-0.995007</td>\n",
              "      <td>-0.988816</td>\n",
              "      <td>-0.953325</td>\n",
              "      <td>-0.794796</td>\n",
              "      <td>-0.744893</td>\n",
              "      <td>-0.648447</td>\n",
              "      <td>0.841796</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.651716</td>\n",
              "      <td>-0.975752</td>\n",
              "      <td>-0.999950</td>\n",
              "      <td>-0.999888</td>\n",
              "      <td>-0.998014</td>\n",
              "      <td>-0.993999</td>\n",
              "      <td>-0.991980</td>\n",
              "      <td>-0.970970</td>\n",
              "      <td>-0.547095</td>\n",
              "      <td>-0.700974</td>\n",
              "      <td>-0.622697</td>\n",
              "      <td>0.921884</td>\n",
              "      <td>-0.719483</td>\n",
              "      <td>0.342168</td>\n",
              "      <td>-0.161318</td>\n",
              "      <td>0.266049</td>\n",
              "      <td>-0.274351</td>\n",
              "      <td>0.267205</td>\n",
              "      <td>-0.020958</td>\n",
              "      <td>0.382610</td>\n",
              "      <td>-0.501748</td>\n",
              "      <td>0.512463</td>\n",
              "      <td>-0.206337</td>\n",
              "      <td>0.376778</td>\n",
              "      <td>0.435172</td>\n",
              "      <td>0.660199</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999918</td>\n",
              "      <td>-0.991736</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.349260</td>\n",
              "      <td>-0.517127</td>\n",
              "      <td>-0.801006</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.961301</td>\n",
              "      <td>-0.974129</td>\n",
              "      <td>-0.956013</td>\n",
              "      <td>-0.989894</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.999240</td>\n",
              "      <td>-0.992673</td>\n",
              "      <td>-0.701291</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.132480</td>\n",
              "      <td>0.565697</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.990877</td>\n",
              "      <td>-0.990169</td>\n",
              "      <td>-0.992521</td>\n",
              "      <td>-0.991044</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.999937</td>\n",
              "      <td>-0.990537</td>\n",
              "      <td>-0.871306</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.012236</td>\n",
              "      <td>-0.314848</td>\n",
              "      <td>-0.713308</td>\n",
              "      <td>-0.112754</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>-0.464761</td>\n",
              "      <td>-0.018446</td>\n",
              "      <td>-0.841559</td>\n",
              "      <td>0.179913</td>\n",
              "      <td>-0.051718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.039480</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>-0.029067</td>\n",
              "      <td>-0.998348</td>\n",
              "      <td>-0.982945</td>\n",
              "      <td>-0.971273</td>\n",
              "      <td>-0.998702</td>\n",
              "      <td>-0.983315</td>\n",
              "      <td>-0.974000</td>\n",
              "      <td>-0.802537</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.838758</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.659340</td>\n",
              "      <td>-0.987427</td>\n",
              "      <td>-0.999993</td>\n",
              "      <td>-0.999826</td>\n",
              "      <td>-0.999411</td>\n",
              "      <td>-0.998918</td>\n",
              "      <td>-0.985482</td>\n",
              "      <td>-0.973481</td>\n",
              "      <td>-0.781973</td>\n",
              "      <td>-0.534604</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.607435</td>\n",
              "      <td>-0.266783</td>\n",
              "      <td>0.275882</td>\n",
              "      <td>0.200417</td>\n",
              "      <td>0.131266</td>\n",
              "      <td>-0.149017</td>\n",
              "      <td>0.292436</td>\n",
              "      <td>-0.192986</td>\n",
              "      <td>0.217496</td>\n",
              "      <td>-0.089175</td>\n",
              "      <td>0.059909</td>\n",
              "      <td>-0.236609</td>\n",
              "      <td>-0.012696</td>\n",
              "      <td>-0.072711</td>\n",
              "      <td>0.578649</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999867</td>\n",
              "      <td>-0.991506</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.533688</td>\n",
              "      <td>-0.625993</td>\n",
              "      <td>-0.898311</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.983313</td>\n",
              "      <td>-0.982951</td>\n",
              "      <td>-0.987406</td>\n",
              "      <td>-0.992134</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.999811</td>\n",
              "      <td>-0.993996</td>\n",
              "      <td>-0.720683</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.268979</td>\n",
              "      <td>-0.364219</td>\n",
              "      <td>-0.723724</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.995671</td>\n",
              "      <td>-0.996939</td>\n",
              "      <td>-0.994436</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.994623</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.202804</td>\n",
              "      <td>-0.603199</td>\n",
              "      <td>-0.860677</td>\n",
              "      <td>0.053477</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>-0.732626</td>\n",
              "      <td>0.703511</td>\n",
              "      <td>-0.845092</td>\n",
              "      <td>0.180261</td>\n",
              "      <td>-0.047436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039978</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>-0.022651</td>\n",
              "      <td>-0.995482</td>\n",
              "      <td>-0.977314</td>\n",
              "      <td>-0.984760</td>\n",
              "      <td>-0.996415</td>\n",
              "      <td>-0.975835</td>\n",
              "      <td>-0.985973</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.674551</td>\n",
              "      <td>-0.988528</td>\n",
              "      <td>-0.999972</td>\n",
              "      <td>-0.999719</td>\n",
              "      <td>-0.999803</td>\n",
              "      <td>-0.996898</td>\n",
              "      <td>-0.976781</td>\n",
              "      <td>-0.986754</td>\n",
              "      <td>-0.688176</td>\n",
              "      <td>-0.520514</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.272262</td>\n",
              "      <td>-0.056424</td>\n",
              "      <td>0.322283</td>\n",
              "      <td>-0.273292</td>\n",
              "      <td>0.037180</td>\n",
              "      <td>-0.133612</td>\n",
              "      <td>0.332487</td>\n",
              "      <td>-0.240491</td>\n",
              "      <td>0.348733</td>\n",
              "      <td>-0.195409</td>\n",
              "      <td>0.229436</td>\n",
              "      <td>-0.316816</td>\n",
              "      <td>-0.123889</td>\n",
              "      <td>-0.181137</td>\n",
              "      <td>0.608219</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999845</td>\n",
              "      <td>-0.987029</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.661975</td>\n",
              "      <td>-0.725887</td>\n",
              "      <td>-0.926663</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.986019</td>\n",
              "      <td>-0.984533</td>\n",
              "      <td>-0.991701</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.999854</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.736521</td>\n",
              "      <td>-0.794872</td>\n",
              "      <td>-0.212429</td>\n",
              "      <td>-0.564868</td>\n",
              "      <td>-0.874594</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.995308</td>\n",
              "      <td>-0.994868</td>\n",
              "      <td>-0.996133</td>\n",
              "      <td>-0.995863</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.999973</td>\n",
              "      <td>-0.993834</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>0.440079</td>\n",
              "      <td>-0.404427</td>\n",
              "      <td>-0.761847</td>\n",
              "      <td>-0.118559</td>\n",
              "      <td>0.177899</td>\n",
              "      <td>0.100699</td>\n",
              "      <td>0.808529</td>\n",
              "      <td>-0.849230</td>\n",
              "      <td>0.180610</td>\n",
              "      <td>-0.042271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039785</td>\n",
              "      <td>-0.011809</td>\n",
              "      <td>-0.028916</td>\n",
              "      <td>-0.996194</td>\n",
              "      <td>-0.988569</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.996994</td>\n",
              "      <td>-0.988526</td>\n",
              "      <td>-0.993135</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.752778</td>\n",
              "      <td>-0.722186</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.990389</td>\n",
              "      <td>-0.999978</td>\n",
              "      <td>-0.999783</td>\n",
              "      <td>-0.999815</td>\n",
              "      <td>-0.996949</td>\n",
              "      <td>-0.989437</td>\n",
              "      <td>-0.992440</td>\n",
              "      <td>-0.715103</td>\n",
              "      <td>-0.860988</td>\n",
              "      <td>-0.916429</td>\n",
              "      <td>0.062816</td>\n",
              "      <td>0.082940</td>\n",
              "      <td>0.200566</td>\n",
              "      <td>-0.378262</td>\n",
              "      <td>0.090063</td>\n",
              "      <td>-0.209264</td>\n",
              "      <td>0.316530</td>\n",
              "      <td>-0.090862</td>\n",
              "      <td>0.396383</td>\n",
              "      <td>-0.353643</td>\n",
              "      <td>0.503754</td>\n",
              "      <td>-0.490389</td>\n",
              "      <td>-0.304759</td>\n",
              "      <td>-0.362708</td>\n",
              "      <td>0.506602</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999894</td>\n",
              "      <td>-0.988427</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.680038</td>\n",
              "      <td>-0.702305</td>\n",
              "      <td>-0.907781</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.987827</td>\n",
              "      <td>-0.987057</td>\n",
              "      <td>-0.987801</td>\n",
              "      <td>-0.996334</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.999876</td>\n",
              "      <td>-0.989153</td>\n",
              "      <td>-0.720891</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.043398</td>\n",
              "      <td>-0.257142</td>\n",
              "      <td>-0.516341</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.995417</td>\n",
              "      <td>-0.995951</td>\n",
              "      <td>-0.995346</td>\n",
              "      <td>-0.995728</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995305</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>-0.138373</td>\n",
              "      <td>-0.491604</td>\n",
              "      <td>-0.036788</td>\n",
              "      <td>-0.012892</td>\n",
              "      <td>0.640011</td>\n",
              "      <td>-0.485366</td>\n",
              "      <td>-0.848947</td>\n",
              "      <td>0.181907</td>\n",
              "      <td>-0.040826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038758</td>\n",
              "      <td>-0.002289</td>\n",
              "      <td>-0.023863</td>\n",
              "      <td>-0.998241</td>\n",
              "      <td>-0.986774</td>\n",
              "      <td>-0.993115</td>\n",
              "      <td>-0.998216</td>\n",
              "      <td>-0.986479</td>\n",
              "      <td>-0.993825</td>\n",
              "      <td>-0.801982</td>\n",
              "      <td>-0.746505</td>\n",
              "      <td>-0.717858</td>\n",
              "      <td>0.838581</td>\n",
              "      <td>0.705854</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.995057</td>\n",
              "      <td>-0.999992</td>\n",
              "      <td>-0.999882</td>\n",
              "      <td>-0.999908</td>\n",
              "      <td>-0.997772</td>\n",
              "      <td>-0.987726</td>\n",
              "      <td>-0.995109</td>\n",
              "      <td>-0.836774</td>\n",
              "      <td>-0.589200</td>\n",
              "      <td>-0.773771</td>\n",
              "      <td>0.312105</td>\n",
              "      <td>-0.095254</td>\n",
              "      <td>0.194399</td>\n",
              "      <td>-0.007998</td>\n",
              "      <td>0.266740</td>\n",
              "      <td>-0.318965</td>\n",
              "      <td>0.409731</td>\n",
              "      <td>-0.224589</td>\n",
              "      <td>0.520354</td>\n",
              "      <td>-0.319167</td>\n",
              "      <td>0.234376</td>\n",
              "      <td>-0.102650</td>\n",
              "      <td>-0.154974</td>\n",
              "      <td>-0.189796</td>\n",
              "      <td>0.598515</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999941</td>\n",
              "      <td>-0.994542</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.560592</td>\n",
              "      <td>-0.529957</td>\n",
              "      <td>-0.857124</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.989051</td>\n",
              "      <td>-0.987932</td>\n",
              "      <td>-0.992145</td>\n",
              "      <td>-0.998404</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.999902</td>\n",
              "      <td>-0.989339</td>\n",
              "      <td>-0.763372</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.270529</td>\n",
              "      <td>-0.539596</td>\n",
              "      <td>-0.833661</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.995645</td>\n",
              "      <td>-0.995508</td>\n",
              "      <td>-0.995683</td>\n",
              "      <td>-0.997414</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995566</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.137735</td>\n",
              "      <td>-0.366214</td>\n",
              "      <td>-0.702490</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>0.122542</td>\n",
              "      <td>0.693578</td>\n",
              "      <td>-0.615971</td>\n",
              "      <td>-0.848164</td>\n",
              "      <td>0.185124</td>\n",
              "      <td>-0.037080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7762</th>\n",
              "      <td>0.048048</td>\n",
              "      <td>-0.042445</td>\n",
              "      <td>-0.065884</td>\n",
              "      <td>-0.195448</td>\n",
              "      <td>-0.278326</td>\n",
              "      <td>-0.219954</td>\n",
              "      <td>-0.282233</td>\n",
              "      <td>-0.305861</td>\n",
              "      <td>-0.357803</td>\n",
              "      <td>0.267874</td>\n",
              "      <td>-0.209017</td>\n",
              "      <td>-0.071229</td>\n",
              "      <td>0.358185</td>\n",
              "      <td>0.210893</td>\n",
              "      <td>0.153409</td>\n",
              "      <td>-0.288219</td>\n",
              "      <td>-0.703984</td>\n",
              "      <td>-0.823789</td>\n",
              "      <td>-0.806079</td>\n",
              "      <td>-0.500917</td>\n",
              "      <td>-0.444521</td>\n",
              "      <td>-0.480595</td>\n",
              "      <td>-0.085674</td>\n",
              "      <td>0.063228</td>\n",
              "      <td>-0.129545</td>\n",
              "      <td>-0.553916</td>\n",
              "      <td>0.387004</td>\n",
              "      <td>-0.041522</td>\n",
              "      <td>-0.159446</td>\n",
              "      <td>-0.069030</td>\n",
              "      <td>0.028946</td>\n",
              "      <td>-0.053502</td>\n",
              "      <td>0.338292</td>\n",
              "      <td>-0.220301</td>\n",
              "      <td>0.181078</td>\n",
              "      <td>-0.107963</td>\n",
              "      <td>0.132397</td>\n",
              "      <td>-0.210953</td>\n",
              "      <td>-0.251623</td>\n",
              "      <td>-0.285560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.732994</td>\n",
              "      <td>-0.303834</td>\n",
              "      <td>0.354983</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.062939</td>\n",
              "      <td>-0.077457</td>\n",
              "      <td>-0.425200</td>\n",
              "      <td>-0.332753</td>\n",
              "      <td>-0.129722</td>\n",
              "      <td>-0.146246</td>\n",
              "      <td>-0.309831</td>\n",
              "      <td>-0.995294</td>\n",
              "      <td>-0.332753</td>\n",
              "      <td>-0.605727</td>\n",
              "      <td>-0.292613</td>\n",
              "      <td>0.577573</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.368534</td>\n",
              "      <td>-0.197418</td>\n",
              "      <td>-0.556747</td>\n",
              "      <td>-0.681100</td>\n",
              "      <td>-0.724107</td>\n",
              "      <td>-0.647607</td>\n",
              "      <td>-0.799516</td>\n",
              "      <td>-0.925237</td>\n",
              "      <td>-0.681100</td>\n",
              "      <td>-0.951092</td>\n",
              "      <td>-0.599138</td>\n",
              "      <td>0.310836</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.008381</td>\n",
              "      <td>-0.596760</td>\n",
              "      <td>-0.879026</td>\n",
              "      <td>-0.190437</td>\n",
              "      <td>0.829718</td>\n",
              "      <td>0.206972</td>\n",
              "      <td>-0.425619</td>\n",
              "      <td>-0.792292</td>\n",
              "      <td>0.238580</td>\n",
              "      <td>0.056020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7763</th>\n",
              "      <td>0.037639</td>\n",
              "      <td>0.006430</td>\n",
              "      <td>-0.044345</td>\n",
              "      <td>-0.235372</td>\n",
              "      <td>-0.302680</td>\n",
              "      <td>-0.232843</td>\n",
              "      <td>-0.322483</td>\n",
              "      <td>-0.354464</td>\n",
              "      <td>-0.345592</td>\n",
              "      <td>0.181271</td>\n",
              "      <td>-0.209017</td>\n",
              "      <td>-0.032557</td>\n",
              "      <td>0.365442</td>\n",
              "      <td>0.227092</td>\n",
              "      <td>0.153409</td>\n",
              "      <td>-0.318111</td>\n",
              "      <td>-0.732559</td>\n",
              "      <td>-0.837484</td>\n",
              "      <td>-0.814302</td>\n",
              "      <td>-0.519880</td>\n",
              "      <td>-0.520277</td>\n",
              "      <td>-0.484334</td>\n",
              "      <td>-0.099061</td>\n",
              "      <td>0.206285</td>\n",
              "      <td>-0.100579</td>\n",
              "      <td>-0.355994</td>\n",
              "      <td>0.147814</td>\n",
              "      <td>0.208128</td>\n",
              "      <td>-0.262731</td>\n",
              "      <td>0.052048</td>\n",
              "      <td>-0.117448</td>\n",
              "      <td>0.075208</td>\n",
              "      <td>0.289009</td>\n",
              "      <td>-0.168158</td>\n",
              "      <td>0.044478</td>\n",
              "      <td>0.242653</td>\n",
              "      <td>-0.223244</td>\n",
              "      <td>-0.197696</td>\n",
              "      <td>-0.225904</td>\n",
              "      <td>-0.276714</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775856</td>\n",
              "      <td>-0.374212</td>\n",
              "      <td>0.361739</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.189792</td>\n",
              "      <td>-0.152674</td>\n",
              "      <td>-0.507979</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>-0.187109</td>\n",
              "      <td>-0.226351</td>\n",
              "      <td>-0.199654</td>\n",
              "      <td>-0.919361</td>\n",
              "      <td>-0.357992</td>\n",
              "      <td>-0.649987</td>\n",
              "      <td>-0.427590</td>\n",
              "      <td>0.620646</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.292100</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.283893</td>\n",
              "      <td>-0.682759</td>\n",
              "      <td>-0.771343</td>\n",
              "      <td>-0.727237</td>\n",
              "      <td>-0.779415</td>\n",
              "      <td>-0.761876</td>\n",
              "      <td>-0.682759</td>\n",
              "      <td>-0.957032</td>\n",
              "      <td>-0.670128</td>\n",
              "      <td>0.207930</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.209452</td>\n",
              "      <td>-0.404418</td>\n",
              "      <td>-0.684496</td>\n",
              "      <td>0.064907</td>\n",
              "      <td>0.875679</td>\n",
              "      <td>-0.879033</td>\n",
              "      <td>0.400219</td>\n",
              "      <td>-0.772288</td>\n",
              "      <td>0.252653</td>\n",
              "      <td>0.056252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7764</th>\n",
              "      <td>0.037451</td>\n",
              "      <td>-0.002724</td>\n",
              "      <td>0.021009</td>\n",
              "      <td>-0.218281</td>\n",
              "      <td>-0.378082</td>\n",
              "      <td>-0.076950</td>\n",
              "      <td>-0.304446</td>\n",
              "      <td>-0.400661</td>\n",
              "      <td>-0.193071</td>\n",
              "      <td>0.113141</td>\n",
              "      <td>-0.334533</td>\n",
              "      <td>0.042977</td>\n",
              "      <td>0.349585</td>\n",
              "      <td>0.227092</td>\n",
              "      <td>0.151363</td>\n",
              "      <td>-0.282999</td>\n",
              "      <td>-0.720539</td>\n",
              "      <td>-0.870521</td>\n",
              "      <td>-0.731586</td>\n",
              "      <td>-0.488447</td>\n",
              "      <td>-0.500856</td>\n",
              "      <td>-0.329875</td>\n",
              "      <td>-0.102890</td>\n",
              "      <td>0.189941</td>\n",
              "      <td>0.092430</td>\n",
              "      <td>-0.370954</td>\n",
              "      <td>0.191859</td>\n",
              "      <td>0.082682</td>\n",
              "      <td>-0.117559</td>\n",
              "      <td>0.016680</td>\n",
              "      <td>-0.085444</td>\n",
              "      <td>0.146797</td>\n",
              "      <td>0.141790</td>\n",
              "      <td>-0.215770</td>\n",
              "      <td>0.115667</td>\n",
              "      <td>0.044672</td>\n",
              "      <td>0.004797</td>\n",
              "      <td>-0.225947</td>\n",
              "      <td>-0.184732</td>\n",
              "      <td>-0.200530</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.801702</td>\n",
              "      <td>-0.490072</td>\n",
              "      <td>0.189903</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.010553</td>\n",
              "      <td>0.330996</td>\n",
              "      <td>0.084875</td>\n",
              "      <td>-0.351948</td>\n",
              "      <td>-0.032286</td>\n",
              "      <td>-0.209511</td>\n",
              "      <td>0.076073</td>\n",
              "      <td>-0.973172</td>\n",
              "      <td>-0.351948</td>\n",
              "      <td>-0.545002</td>\n",
              "      <td>-0.241801</td>\n",
              "      <td>0.584816</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.315084</td>\n",
              "      <td>0.468934</td>\n",
              "      <td>0.302568</td>\n",
              "      <td>-0.685855</td>\n",
              "      <td>-0.726528</td>\n",
              "      <td>-0.725174</td>\n",
              "      <td>-0.709332</td>\n",
              "      <td>-0.692579</td>\n",
              "      <td>-0.685855</td>\n",
              "      <td>-0.952309</td>\n",
              "      <td>-0.696440</td>\n",
              "      <td>0.158936</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.237003</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>-0.317314</td>\n",
              "      <td>0.052806</td>\n",
              "      <td>-0.266724</td>\n",
              "      <td>0.864404</td>\n",
              "      <td>0.701169</td>\n",
              "      <td>-0.779566</td>\n",
              "      <td>0.249121</td>\n",
              "      <td>0.047071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7765</th>\n",
              "      <td>0.044011</td>\n",
              "      <td>-0.004536</td>\n",
              "      <td>-0.051242</td>\n",
              "      <td>-0.219202</td>\n",
              "      <td>-0.383350</td>\n",
              "      <td>-0.081035</td>\n",
              "      <td>-0.310419</td>\n",
              "      <td>-0.380233</td>\n",
              "      <td>-0.201007</td>\n",
              "      <td>0.166671</td>\n",
              "      <td>-0.369637</td>\n",
              "      <td>0.042977</td>\n",
              "      <td>0.325946</td>\n",
              "      <td>0.261879</td>\n",
              "      <td>0.151363</td>\n",
              "      <td>-0.274477</td>\n",
              "      <td>-0.721170</td>\n",
              "      <td>-0.872676</td>\n",
              "      <td>-0.734725</td>\n",
              "      <td>-0.488072</td>\n",
              "      <td>-0.464520</td>\n",
              "      <td>-0.377506</td>\n",
              "      <td>-0.112676</td>\n",
              "      <td>0.162452</td>\n",
              "      <td>-0.031156</td>\n",
              "      <td>-0.468350</td>\n",
              "      <td>0.274676</td>\n",
              "      <td>0.035400</td>\n",
              "      <td>-0.140051</td>\n",
              "      <td>-0.244395</td>\n",
              "      <td>0.124330</td>\n",
              "      <td>0.131594</td>\n",
              "      <td>-0.033104</td>\n",
              "      <td>-0.231405</td>\n",
              "      <td>0.165104</td>\n",
              "      <td>-0.133763</td>\n",
              "      <td>0.224279</td>\n",
              "      <td>-0.256875</td>\n",
              "      <td>-0.231141</td>\n",
              "      <td>-0.191979</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.826288</td>\n",
              "      <td>-0.560079</td>\n",
              "      <td>0.240644</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.106041</td>\n",
              "      <td>0.037511</td>\n",
              "      <td>-0.304283</td>\n",
              "      <td>-0.415004</td>\n",
              "      <td>0.039203</td>\n",
              "      <td>-0.187961</td>\n",
              "      <td>0.028693</td>\n",
              "      <td>-0.960898</td>\n",
              "      <td>-0.415004</td>\n",
              "      <td>-0.510548</td>\n",
              "      <td>-0.513218</td>\n",
              "      <td>0.445207</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.402999</td>\n",
              "      <td>0.285400</td>\n",
              "      <td>-0.050802</td>\n",
              "      <td>-0.712134</td>\n",
              "      <td>-0.689573</td>\n",
              "      <td>-0.702416</td>\n",
              "      <td>-0.694869</td>\n",
              "      <td>-0.886150</td>\n",
              "      <td>-0.712134</td>\n",
              "      <td>-0.951972</td>\n",
              "      <td>-0.760114</td>\n",
              "      <td>0.210070</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.069366</td>\n",
              "      <td>0.037919</td>\n",
              "      <td>-0.356579</td>\n",
              "      <td>-0.101360</td>\n",
              "      <td>0.700740</td>\n",
              "      <td>0.936674</td>\n",
              "      <td>-0.589479</td>\n",
              "      <td>-0.785603</td>\n",
              "      <td>0.246409</td>\n",
              "      <td>0.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7766</th>\n",
              "      <td>0.068954</td>\n",
              "      <td>0.001810</td>\n",
              "      <td>-0.080323</td>\n",
              "      <td>-0.269336</td>\n",
              "      <td>-0.366553</td>\n",
              "      <td>-0.147294</td>\n",
              "      <td>-0.377332</td>\n",
              "      <td>-0.360597</td>\n",
              "      <td>-0.255505</td>\n",
              "      <td>0.321881</td>\n",
              "      <td>-0.367421</td>\n",
              "      <td>-0.120546</td>\n",
              "      <td>0.325946</td>\n",
              "      <td>0.261879</td>\n",
              "      <td>0.184966</td>\n",
              "      <td>-0.308610</td>\n",
              "      <td>-0.754659</td>\n",
              "      <td>-0.865698</td>\n",
              "      <td>-0.767352</td>\n",
              "      <td>-0.626939</td>\n",
              "      <td>-0.408592</td>\n",
              "      <td>-0.365944</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.243558</td>\n",
              "      <td>-0.145688</td>\n",
              "      <td>-0.436416</td>\n",
              "      <td>0.352467</td>\n",
              "      <td>-0.174894</td>\n",
              "      <td>0.047222</td>\n",
              "      <td>-0.405392</td>\n",
              "      <td>0.302699</td>\n",
              "      <td>-0.084086</td>\n",
              "      <td>0.157683</td>\n",
              "      <td>-0.203440</td>\n",
              "      <td>0.102233</td>\n",
              "      <td>0.024406</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>-0.265536</td>\n",
              "      <td>-0.291159</td>\n",
              "      <td>-0.202375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.759096</td>\n",
              "      <td>-0.434947</td>\n",
              "      <td>0.298694</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.238125</td>\n",
              "      <td>-0.322863</td>\n",
              "      <td>-0.766821</td>\n",
              "      <td>-0.330780</td>\n",
              "      <td>-0.105997</td>\n",
              "      <td>-0.124597</td>\n",
              "      <td>-0.161681</td>\n",
              "      <td>-0.787729</td>\n",
              "      <td>-0.330780</td>\n",
              "      <td>-0.589429</td>\n",
              "      <td>-0.290657</td>\n",
              "      <td>0.436453</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.380803</td>\n",
              "      <td>-0.083239</td>\n",
              "      <td>-0.393915</td>\n",
              "      <td>-0.715591</td>\n",
              "      <td>-0.745278</td>\n",
              "      <td>-0.697598</td>\n",
              "      <td>-0.783636</td>\n",
              "      <td>-0.758682</td>\n",
              "      <td>-0.715591</td>\n",
              "      <td>-0.959988</td>\n",
              "      <td>-0.677251</td>\n",
              "      <td>0.202026</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.002496</td>\n",
              "      <td>-0.400831</td>\n",
              "      <td>-0.742972</td>\n",
              "      <td>-0.280088</td>\n",
              "      <td>-0.007739</td>\n",
              "      <td>-0.056088</td>\n",
              "      <td>-0.616956</td>\n",
              "      <td>-0.783693</td>\n",
              "      <td>0.246785</td>\n",
              "      <td>0.042981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7415 rows × 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      (tBodyAcc-Mean-1,)  ...  (tZAxisAcc-AngleWRTGravity-1,)\n",
              "0               0.043580  ...                       -0.051718\n",
              "1               0.039480  ...                       -0.047436\n",
              "2               0.039978  ...                       -0.042271\n",
              "3               0.039785  ...                       -0.040826\n",
              "4               0.038758  ...                       -0.037080\n",
              "...                  ...  ...                             ...\n",
              "7762            0.048048  ...                        0.056020\n",
              "7763            0.037639  ...                        0.056252\n",
              "7764            0.037451  ...                        0.047071\n",
              "7765            0.044011  ...                        0.031700\n",
              "7766            0.068954  ...                        0.042981\n",
              "\n",
              "[7415 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ign_pOr8MX_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# new_train_D = scaler.fit_transform(train_csv, train_L)\n",
        "# new_test_D = scaler.transform(test_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAuZpX2_OE_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미 돼있는 dataset\n",
        "import more_itertools as mit\n",
        "windowed_train_D =train_csv#mit.windowed(new_train_D, n= 128, step = 128/2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WSUcrXpO_Do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c9e41c0-7f48-4736-f685-46b219694f1e"
      },
      "source": [
        "np.array(train_csv).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7415, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LQc1r-lMu1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_D = torch.FloatTensor(np.array(windowed_train_D))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnqrDii-R2mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_L = torch.LongTensor(np.array(train_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob3UILuUMsCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#186\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_D, train_L), batch_size = 192, shuffle= True, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4XzO5VP68CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_CNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTM_CNN, self).__init__()\n",
        "    self.lstm1 = torch.nn.LSTM(561, 32, 2)\n",
        "\n",
        "    self.conv1 = torch.nn.Sequential(torch.nn.Conv1d(32, 64,kernel_size = 5,stride = 2) ,torch.nn.MaxPool1d(2, stride = 2),\n",
        "                                     torch.nn.ReLU())\n",
        "    self.conv2 = torch.nn.Sequential( torch.nn.Conv1d(64, 128, 3, 1))\n",
        "    self.gap = torch.nn.AvgPool1d(1)\n",
        "    self.bn = torch.nn.BatchNorm1d(128)\n",
        "    self.l1 = torch.nn.Linear(30, 7)\n",
        "    self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, _ = self.lstm1(x)\n",
        "    #print('lstm1', out.shape)\n",
        "    out = out.permute(0, 2, 1)\n",
        "    #print(out.shape)\n",
        "    out = out.reshape(1,32,-1)\n",
        "    out = self.conv1(out)\n",
        "    #print('conv1', out.shape)\n",
        "    out = out.reshape(1,64,-1)\n",
        "    out = self.conv2(out)\n",
        "    #print('conv2', out.shape)\n",
        "    out = self.gap(out)\n",
        "    #print('gap', out.shape)\n",
        "    out = self.bn(out)\n",
        "    out = out.reshape(-1,30)\n",
        "    #print('batchnormal', out.shape)\n",
        "    out= self.l1(out)\n",
        "    #out =softmax(out)\n",
        "    #print('linear', out.shape)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6F4468EjozB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPjkg2doAyWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM_CNN().to(device)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTo7Ov5HA1JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Vwg0YoA8ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "a294b37f-66c5-4411-83e6-9ba136aa1e0c"
      },
      "source": [
        "running_loss = 0\n",
        "for e in range(200):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    x, y= data\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1,1,561).to(device)\n",
        "    y = y.flatten().to(device)\n",
        "    optimizer.zero_grad()\n",
        "    h = model(x)\n",
        "    loss = criterion(h, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  if e % 10 ==0:\n",
        "    print('[%d] loss : %.3f' %(e, running_loss/100))\n",
        "    running_loss =0\n",
        "print('fin')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] loss : 0.747\n",
            "[10] loss : 6.826\n",
            "[20] loss : 6.788\n",
            "[30] loss : 6.783\n",
            "[40] loss : 6.783\n",
            "[50] loss : 6.592\n",
            "[60] loss : 4.502\n",
            "[70] loss : 2.438\n",
            "[80] loss : 1.625\n",
            "[90] loss : 1.034\n",
            "[100] loss : 0.648\n",
            "[110] loss : 0.477\n",
            "[120] loss : 0.373\n",
            "[130] loss : 0.315\n",
            "[140] loss : 0.274\n",
            "[150] loss : 0.245\n",
            "[160] loss : 0.231\n",
            "[170] loss : 0.215\n",
            "[180] loss : 0.193\n",
            "[190] loss : 0.189\n",
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a727wd9xoAjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './file.pt'\n",
        "torch.save({\n",
        "            'epoch': 200,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "\n",
        "            }, PATH)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzfQGpyRqK2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7045bec0-29fa-4ee3-942e-9d7c0d379c56"
      },
      "source": [
        "np.array(test_csv).shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3162, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sM50MC9B9Mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D = torch.FloatTensor(np.array(test_csv))\n",
        "test_L = torch.LongTensor(np.array(test_y))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZttvhgqB18h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_D,test_L),                                                                         batch_size=192,\n",
        "                                         shuffle=False ,drop_last = True)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBoxyQMUhvoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f5ac41b-e699-40ce-cf1c-16ccc75a91f4"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for data in test_loader:\n",
        "    x, y = data\n",
        "    x = x.view(-1,1,561).to(device)\n",
        "    y= y.to(device)\n",
        "    \n",
        "    pred = model(x)\n",
        "    \n",
        "    _, predicted= torch.max(pred.data, 1)\n",
        "    total += y.size(0)\n",
        "    \n",
        "    correct += (predicted ==y.reshape(-1,)).sum(0).item()\n",
        "print('acc:', 100 * correct/total) "
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 89.47916666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}